{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyPI project classification based on package description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an experimental notebook with the goal of exploring different methods to extend [project2vec](https://developers.redhat.com/articles/2021/10/06/find-and-compare-python-libraries-project2vec).\n",
    "\n",
    "The data used for this project consists in information about ~70 000 Python packages aggregated from PyPI using [Selinon](https://github.com/thoth-station/selinon-worker) and is available under ``s3://DH-DEV-DATA/data/thoth/selinon/pypi_project/ProjectInfo/`` on Ceph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file describes a different package hosted on PyPI, providing metadata about the project in the `info` field. We are interested in the following subfields:\n",
    "- `classifiers`\n",
    "- `keywords`\n",
    "- `description`\n",
    "\n",
    "The classifiers of a project consist in a hierchical labels, with their [official list](https://pypi.org/classifiers/) described on the PyPI website. They allow to classify a project according to different categories and scopes, for example by language and version, operating system or topic. In the case of the `selinon` package, the classifiers are the following:\n",
    "\n",
    "```\n",
    "      \"Development Status :: 4 - Beta\",\n",
    "      \"Intended Audience :: Developers\",\n",
    "      \"License :: OSI Approved :: BSD License\",\n",
    "      \"Operating System :: OS Independent\",\n",
    "      \"Programming Language :: Python :: 3\",\n",
    "      \"Programming Language :: Python :: 3.4\",\n",
    "      \"Programming Language :: Python :: 3.5\",\n",
    "      \"Programming Language :: Python :: 3.6\",\n",
    "      \"Programming Language :: Python :: Implementation :: CPython\",\n",
    "      \"Programming Language :: Python :: Implementation :: PyPy\",\n",
    "      \"Topic :: System :: Distributed Computing\"\n",
    "```\n",
    "\n",
    "The keywords consist in a few words written in free text format (often separated by a whitespace or a coma) describing the package in a non-hierchical way. The keywords chosen to describe `selinon` are:\n",
    "\n",
    "``selinon celery yaml flow distributed-computing``\n",
    "\n",
    "Finally, the description is the text describing the project as seen in the PyPI pakage page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of a raw content dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create datasets of descriptions from those PyPI projects and link each project and its description respectively to its trove classifiers and keywords from PyPI.\n",
    "The dataset should contain the following information:\n",
    "\n",
    "``Project name | Project description | Project PyPI classifiers or Project PyPI keywords``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 17:33:37,285 [345774] WARNING  py.warnings: /home/mcostant/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "\n",
      "2022-03-04 17:33:37,287 [345774] WARNING  py.warnings: /home/mcostant/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\n",
      "2022-03-04 17:33:37,289 [345774] WARNING  py.warnings: /home/mcostant/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "\n",
      "2022-03-04 17:33:37,290 [345774] WARNING  py.warnings: /home/mcostant/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import PrettyPrinter\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sys\n",
    "from typing import Dict\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "DATASETS_SAVING_PATH = \"../datasets/\"\n",
    "NUMBER_OF_PROJECTS = 1000\n",
    "WORD_LENGTH_THRESHOLD = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling and saving the datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the projects descriptions by removing punctuation is necessary for text preprocessing purposes and to avoid any conflicts when storing data in CSV format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_description(description: str, threshold: int) -> str:\n",
    "    \"\"\"Normalize the description and remove special characters, non-English characters and words longer than a threshold.\"\"\"\n",
    "    symbols = \"!\\\"#$%&()*+-/:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for symbol in symbols:\n",
    "        description = description.replace(symbol, \" \")\n",
    "    description = \" \".join([word.strip().lower() for word in description.split(\" \") if word != \"\"])\n",
    "\n",
    "    words_list = description.split(\" \")\n",
    "    for word in words_list:\n",
    "        if len(word) >= threshold:\n",
    "            words_list.remove(word)\n",
    "    formatted_description = \" \".join(words_list).encode(\"ascii\", \"ignore\").decode()\n",
    "\n",
    "    return formatted_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_keywords(keywords: str, threshold: int) -> str:\n",
    "    \"\"\"Format free text PyPI keywords of the projects.\"\"\"\n",
    "    keywords = str(keywords)\n",
    "    if \",\" in keywords:\n",
    "        return format_description(keywords.replace(\",\", \" \"), threshold)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we need only projects containing a full description, we filter those with an empty or unknown one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description_is_valid(description: str) -> bool:\n",
    "    \"\"\"Verify if a description is present and valid.\"\"\"\n",
    "    if description in [None, \"\", \" \"] or description.startswith((\"Unknown\", \"unknown\", \"UNKNOWN\", \"\\n\")):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projects_with_descriptors_dataset(descriptors: str, words_length_threshold: int) -> Dict[str, list]:\n",
    "    \"\"\"Retrieve projects with PyPI classifiers or keywords from data aggregated with Selinon.\"\"\"\n",
    "    projects_with_descriptors_dataset = {}\n",
    "    for root, dirs, files in os.walk(os.path.join(DATA_PATH)):\n",
    "        for file in files:\n",
    "            with open(os.path.join(DATA_PATH, file), \"r\") as json_file:\n",
    "                file_content = json.loads(json_file.read())\n",
    "            \n",
    "                # if descriptors == \"classifiers\":\n",
    "                #     if description_is_valid(file_content[\"info\"][\"description\"]) and file_content[\"info\"][\"classifiers\"] != []:\n",
    "                #         project_description = format_description(file_content[\"info\"][\"description\"], words_length_threshold)\n",
    "                #         projects_with_descriptors_dataset[file] = [project_description, file_content[\"info\"][\"classifiers\"]]\n",
    "\n",
    "                if descriptors == \"keywords\":\n",
    "                    if description_is_valid(file_content[\"info\"][\"description\"]) and file_content[\"info\"][\"keywords\"] not in [\"\", None]:\n",
    "                        project_description = format_description(file_content[\"info\"][\"description\"], words_length_threshold)\n",
    "                        projects_with_descriptors_dataset[file] = [project_description, format_keywords(file_content[\"info\"][\"keywords\"], words_length_threshold)]\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid descriptors name specified\")\n",
    "\n",
    "    return projects_with_descriptors_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the project, we create a subsample of the datasets by selecting randomly a limited number of packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_with_keywords_dataset = get_projects_with_descriptors_dataset(\"keywords\", WORD_LENGTH_THRESHOLD)\n",
    "# projects_with_classifiers_dataset = get_projects_with_descriptors_dataset(\"classifiers\", WORD_LENGTH_THRESHOLD)\n",
    "\n",
    "random_keys = list(set(list(projects_with_keywords_dataset.keys())).intersection(set(list(projects_with_keywords_dataset.keys()))))\n",
    "\n",
    "random.shuffle(random_keys)\n",
    "random_keys = random_keys[:min(len(random_keys)-1, NUMBER_OF_PROJECTS)]\n",
    "\n",
    "with open(os.path.join(DATASETS_SAVING_PATH, f\"projects_with_keywords_dataset_{NUMBER_OF_PROJECTS}.csv\"), \"w\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for project_name in random_keys:\n",
    "        writer.writerow([project_name, projects_with_keywords_dataset[project_name][0], projects_with_keywords_dataset[project_name][1]])\n",
    "\n",
    "# with open(os.path.join(DATASETS_SAVING_PATH, f\"projects_with_classifiers_dataset_{NUMBER_OF_PROJECTS}.csv\"), \"w\") as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     for project_name in random_keys:\n",
    "#         writer.writerow([project_name, projects_with_classifiers_dataset[project_name][0], \",\".join(projects_with_classifiers_dataset[project_name][1])])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now built two datasets containing each project's name and description, followed by corresponding classifiers or keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token ranking using TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step consists in building a dataset that contains tokens of the description for each package ranked by importance based on the [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) tokens ranking method. \n",
    "\n",
    "TF-IDF (for Term Frequency - Inverse Document Frequency) is a statistical method to find the most important terms of a document from a document corpus, i.e. a set of documents. The technique relies on an analysis of the frequency of terms in tokenized and pre-processed documents, where the most frequent terms across documents of the corpus are penalized to highlight the terms appearing more frequently in the document, which allows to identify the topic of the analyzed text. The corpus of documents considered in this analysis is the set of text descriptions from PyPI Python packages which are described with at least one keyword on the PyPI index. \n",
    "\n",
    "A ranking of tokens with TF-IDF can be used to identify the topic of a package which has not been classified yet by computing a similarity measure between its vectorized version with TF-IDF and specific keywords. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the descriptions text preprocessing is to filter them in order to extract only relevant words (removing stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mcostant/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_dataset(dataset_name: str) -> Dict[str, list]:\n",
    "    \"\"\"Remove stop words and put tokens in lowercase.\"\"\"\n",
    "    preprocessed_dataset = {}\n",
    "    stopwords_complete_list = stopwords.words('english') + [stopword.capitalize() for stopword in stopwords.words('english')]\n",
    "\n",
    "    with open(os.path.join(DATASETS_SAVING_PATH, dataset_name), \"r\") as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        for row in reader:\n",
    "            preprocessed_description = list(filter(str.isalnum, row[1].split(\" \")))\n",
    "            preprocessed_description = [word.lower() for word in preprocessed_description if word not in stopwords_complete_list]\n",
    "            preprocessed_dataset[row[0]] = [preprocessed_description, row[2].split(\",\")]\n",
    "\n",
    "    return preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increasing field size limit to avoid size-related errors:\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a dataset containing only the project names and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_projects_with_classifiers_dataset = preprocess_dataset(f\"projects_with_classifiers_dataset_{NUMBER_OF_PROJECTS}.csv\")\n",
    "\n",
    "# Print the dataset:\n",
    "\n",
    "# pp = PrettyPrinter(indent=2)\n",
    "# pp.pprint(preprocessed_projects_with_classifiers_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_projects_with_keywords_dataset = preprocess_dataset(f\"projects_with_keywords_dataset_{NUMBER_OF_PROJECTS}.csv\")\n",
    "\n",
    "# Print the dataset:\n",
    "\n",
    "# pp = PrettyPrinter(indent=2)\n",
    "# pp.pprint(preprocessed_projects_with_keywords_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_projects_with_keywords_dataset_ordered = OrderedDict(sorted(preprocessed_projects_with_keywords_dataset.items()))\n",
    "\n",
    "corpus_keywords = [\" \".join(description[0]) for package_name, description in preprocessed_projects_with_keywords_dataset_ordered.items()]\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "tf_idf_keywords = vectorizer.fit_transform(corpus_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a first overview of the results we get from the TF-IDF token ranking by comparing the last obtained rankings for the first 10 packages to the corresponding project descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package name:  42cc-pystyle\n",
      "Description:  42cc pystyle flake8 plugins for 42 coffee cups style checks 0.0.6 fixed flake8 warnings 0.0.5 fixed package layout declaration 0.0.4 fixed nosetests 0.0.3 moved code to a subfolder 0.0.2 added manifest.in 0.0.1 tests should have docstrings tests for the module could be run via nosetests or python setup.py nosetests\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "nosetests    0.469464\n",
      "flake8       0.363550\n",
      "fixed        0.337214\n",
      "42cc         0.225004\n",
      "pystyle      0.225004\n",
      "cups         0.225004\n",
      "subfolder    0.203389\n",
      "coffee       0.190746\n",
      "declaration  0.185939\n",
      "tests        0.182429\n",
      "42           0.178102\n",
      "warnings     0.169131\n",
      "docstrings   0.164325\n",
      "layout       0.151681\n",
      "moved        0.145021\n",
      "checks       0.137587\n",
      "plugins      0.136656\n",
      "could        0.115972\n",
      "style        0.108452\n",
      "added        0.095075\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  73-unlockitems\n",
      "Description:  introduction this product is special for unlocking web dav locked item in a plone portal. need simplejson if python version is less than 2.6 release 0.3 no need simplejson any more code is more clear and speed changelog 0.1dev unreleased initial release 0.2 unreleased add browserview in plone control panel 0.3 released remove jquery used javascript and python code is more clear and speed make only one search in catalog\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "simplejson   0.368875\n",
      "clear        0.302049\n",
      "speed        0.299356\n",
      "unreleased   0.291903\n",
      "unlocking    0.228300\n",
      "dav          0.228300\n",
      "plone        0.215017\n",
      "browserview  0.206369\n",
      "locked       0.199308\n",
      "need         0.160905\n",
      "panel        0.160589\n",
      "catalog      0.160589\n",
      "release      0.159156\n",
      "jquery       0.155447\n",
      "javascript   0.141580\n",
      "less         0.141580\n",
      "item         0.136849\n",
      "special      0.134317\n",
      "released     0.129789\n",
      "product      0.122870\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  a10-horizon\n",
      "Description:  a10 networks openstack horizon dashboard a10 networks openstack horizon dashboard for thunder, vthunder and ax series appliances supported releases openstack icehouse, juno, kilo, liberty, mitaka lbaas versions v1, v2 acos versions acos 2 axapi 2.1 acos 2.7.2 , acos 4 axapi 3.0 acos 4.0.1 ga working but not available for support openstack git master a10 github repos a10 horizon https github.com a10networks a10 horizon a10 horizon dashboard repo. a10 neutron lbaas https github.com a10networks a10 neutron lbaas main a10 lbaas driver repo. middleware sitting between the openstack driver and our api client, mapping openstack constructs to a10's axapi. acos client https github.com a10networks acos client axapi client used by a10's openstack driver a10 openstack lbaas https github.com a10networks a10 openstack lbaas openstack lbaas driver, identical to the files that are currently merged into neutron lbaas. pypi package 'a10 openstack lbaas'. a10 openstack lbaas, havana branch https github.com a10networks a10 openstack lbaas tree havana openstack lbaas driver, for the havana release. pypi package 'a10 openstack lbaas havana'. a10networks ci project config https github.com a10networks ci project config a10 networks openstack third party ci setup scripts installation steps step 1 make sure you have horizon installed. this dashboard will need to be installed on all of your horizon nodes if you are running horizon in an ha environment. step 2 the latest supported version of a10 horizon is available via standard pypi repositories and the current development version is available on github. installation from pypi sh sudo pip install a10 horizon installation from cloned git repository. download the dashboard from https github.com a10networks a10 horizon sh sudo pip install git https github.com a10networks a10 horizon.git sh git clone https github.com a10networks a10 horizon.git cd a10 horizon sudo pip install e . configuration horizon provides a plugin architecture for adding external panels. to enable the a10 networks horizon ui dashboard, simply copy the files from a10 horizon enabled hooks to the local enabled directory in your horizon openstack dashboard directory. these paths can be auto discovered by typing the following commands a10 horizon path sh python c import a10 horizon print a10 horizon. path 0 horizon dashboard path sh python c import openstack dashboard print openstack dashboard. path 0 restart necessary services a10 horizon has static resources that must be collected by horizon. following the installation of a10 horizon, execute the following command in the directory where you have installed horizon sh . manage.py collectstatic . manage.py compress restart horizon after configuration updates exact command may vary depending on openstack packaging. sh service apache2 restart examples a10 community feel free to fork, submit pull requests, or join us on freenode irc, channel a10 openstack. serious support escalations and formal feature requests must still go through standard a10 processes. contributing 1. fork it 2. create your feature branch git checkout b my new feature 3. commit your changes git commit am 'add some feature' 4. push to the branch git push origin my new feature 5. create new pull request\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "a10          0.658621\n",
      "horizon      0.455848\n",
      "openstack    0.383323\n",
      "a10networks  0.219540\n",
      "lbaas        0.219540\n",
      "acos         0.153678\n",
      "dashboard    0.134138\n",
      "sh           0.095304\n",
      "networks     0.067069\n",
      "axapi        0.065862\n",
      "neutron      0.065862\n",
      "havana       0.065862\n",
      "git          0.060350\n",
      "feature      0.045829\n",
      "driver       0.041774\n",
      "restart      0.040844\n",
      "https        0.040281\n",
      "ci           0.038073\n",
      "path         0.035271\n",
      "sudo         0.032540\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  a2pcej\n",
      "Description:  a2pcej code climate issue count coverage status a2pcej , convert alphabet to phonetic code in english and japanease. this module convert each alphabet letters to phonetic code, and also convert each alphabet letterts to katakana. functions conv al letters, delimiter ' ', upper sign ' caps ', num false letters is string. .. code python def conv al letters, delimiter ' ', sign ' caps ', num false return unicode conv ak letters, delimiter '', upper sign '', num false letters is string. .. code python def conv ak letters, delimiter '', sign '', num false return unicode simple example of usage as below... on python3.5 first of all, import module. .. code python import module. from a2pcej import convert 'examples' to ponetic code in english. .. code python conv al 'examples' 'echo xray alfa mike papa lima echo sierra' convert 'examples' to ponetic code in japanese katakana. .. code python conv ak 'examples' non alphabet letters are not convert default . upper case lattters has caps or  sign default . .. code python conv al 'examples002' 'echo caps xray alfa mike papa lima echo sierra 0 0 2' conv ak 'examples002' you can change delimiter and upper case letters sign. .. code python conv al 'examples003', delimiter ', ', sign ' capital ' 'echo capital , xray, alfa, mike, papa, lima, echo, sierra, 0, 0, 3' conv ak 'examples003', delimiter '', sign '  ' '  if you would like to convert numbers to phonetic code, set num true . .. code python conv al 'examples004', num true 'echo caps xray alfa mike papa lima echo sierra zero zero four' conv ak 'examples004', num true .. code climate image https codeclimate.com github kacchan822 a2pcej badges gpa.svg target https codeclimate.com github kacchan822 a2pcej .. issue count image https codeclimate.com github kacchan822 a2pcej badges issue count.svg target https codeclimate.com github kacchan822 a2pcej .. coverage status image https coveralls.io repos github kacchan822 a2pcej badge.svg branch master target https coveralls.io github kacchan822 a2pcej branch master\n",
      "Highest ranked keywords:\n",
      "\n",
      "              TF-IDF\n",
      "conv        0.486017\n",
      "a2pcej      0.364513\n",
      "kacchan822  0.243008\n",
      "ak          0.243008\n",
      "delimiter   0.240344\n",
      "caps        0.202507\n",
      "num         0.201806\n",
      "al          0.192354\n",
      "letters     0.191128\n",
      "sign        0.191122\n",
      "convert     0.174572\n",
      "alphabet    0.162006\n",
      "code        0.140637\n",
      "upper       0.130880\n",
      "papa        0.121504\n",
      "phonetic    0.121504\n",
      "lima        0.121504\n",
      "alfa        0.121504\n",
      "xray        0.114677\n",
      "mike        0.103005\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aaa2-1-1\n",
      "Description:   python2 pip install roc2.1.2 roc txtroc  python from roc import roc roc.roc truth , test , result , roc ps result roc'd python work result' conroc pre file ,titlestr  python from roc import conroc conroc.conroc pre file , image roc ps image'd python work image' txt2xml txt file python from transform import txt2xml txt2xml.txt2xml txt file , xml file xml file  transform txt2xml txttxt file roc roc iou x1,y1,x2,y2 ,gtframe x1,y1,x2,y2  read xmin,ymin,xmax,ymax analyze 0.5 conroc conroc\n",
      "Highest ranked keywords:\n",
      "\n",
      "             TF-IDF\n",
      "roc        0.704234\n",
      "conroc     0.403335\n",
      "txt2xml    0.302501\n",
      "file       0.214719\n",
      "ps         0.182295\n",
      "txt        0.159630\n",
      "transform  0.147282\n",
      "xml        0.125981\n",
      "pre        0.121673\n",
      "python     0.107523\n",
      "result     0.102300\n",
      "txttxt     0.100834\n",
      "txtroc     0.100834\n",
      "iou        0.100834\n",
      "import     0.094151\n",
      "truth      0.083327\n",
      "work       0.082335\n",
      "analyze    0.078343\n",
      "python2    0.078343\n",
      "read       0.042936\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aacgmv2\n",
      "Description:  overview docs version doi this is a python wrapper for the aacgm v2 c library http aacgm.html , which allows converting between geographic and magnetic coordinates. the currently included version of the c library is 2.5. the package is free software mit license . when referencing this package, please cite both the package doi and the aacgm v2 journal article shepherd, s. g. 2014 , altitudeadjusted corrected geomagnetic coordinates definition and functional approximations, journal of geophysical research space physics, 119, 75017521, doi 10.1002 2014ja020264. quick start install requires numpy and logging pip install aacgmv2 convert between aacgm and geographic coordinates import aacgmv2 import datetime as dt import numpy as np np.set printoptions formatter 'float kind' lambda x ' .4f '.format x geo to aacgm, single numbers dtime dt.datetime 2013, 11, 3 np.array aacgmv2.get aacgm coord 60, 15, 300, dtime array 57.4698, 93.6300, 1.4822 aacgm to geo, mix arrays numbers aacgmv2.convert latlon arr 90, 90 , 0, 0, dtime, code a2g array 82.9666, 74.3385 , array 84.6652, 125.8401 , array 14.1244, 12.8771 convert between aacgm and mlt import aacgmv2 import datetime as dt import numpy as np np.set printoptions formatter 'float kind' lambda x ' .4f '.format x mlt to aacgm dtime dt.datetime 2013, 11, 3, 0, 0, 0 aacgmv2.convert mlt 1.4822189, 12 , dtime, m2a true array 93.6300, 108.6033 if you don't know or use python, you can also use the command line. see details in the full documentation. documentation https aacgmv2.readthedocs.org http aacgm.html badges .. list table stub columns 1 docs docs tests travis appveyor requires landscape codeclimate scrutinizer codacy package version supported versions wheel supported implementations .. docs image https readthedocs.org projects aacgmv2 badge version stable style flat target https readthedocs.org projects aacgmv2 alt documentation status .. travis image https travis ci.org aburrell aacgmv2.svg branch master alt travis ci build status target https travis ci.org aburrell aacgmv2 .. appveyor image https ci.appveyor.com api projects status github aburrell aacgmv2 branch master svg true alt appveyor build status target https ci.appveyor.com project aburrell aacgmv2 .. requires image https requires.io github aburrell aacgmv2 requirements.svg branch master alt requirements status target https requires.io github aburrell aacgmv2 requirements branch master .. coveralls image https coveralls.io repos aburrell aacgmv2 badge.svg branch master service github alt coverage status target https coveralls.io github aburrell aacgmv2 .. codecov image https codecov.io github aburrell aacgmv2 coverage.svg branch master alt coverage status target https codecov.io github aburrell aacgmv2 .. landscape image https landscape.io github aburrell aacgmv2 master landscape.svg style flat target https landscape.io github aburrell aacgmv2 master alt code quality status .. codacy image https api.codacy.com project badge grade target https www.codacy.com app aburrell aacgmv2 utm source github.com amp utm medium referral amp utm content aburrell aacgmv2 amp utm campaign badge grade alt codacy code quality status .. codeclimate image https codeclimate.com github aburrell aacgmv2 badges gpa.svg target https codeclimate.com github aburrell aacgmv2 alt codeclimate quality status .. version image https img.shields.io pypi v aacgmv2.svg style flat alt pypi package latest release target https pypi.python.org pypi aacgmv2 .. downloads image https img.shields.io pypi dm aacgmv2.svg style flat alt pypi package monthly downloads target https pypi.python.org pypi aacgmv2 .. wheel image https img.shields.io pypi wheel aacgmv2.svg style flat alt pypi wheel target https pypi.python.org pypi aacgmv2 .. supported versions image https img.shields.io pypi pyversions aacgmv2.svg style flat alt supported versions target https pypi.python.org pypi aacgmv2 .. supported implementations image https img.shields.io pypi implementation aacgmv2.svg style flat alt supported implementations target https pypi.python.org pypi aacgmv2 .. scrutinizer image https img.shields.io scrutinizer g aburrell aacgmv2 master.svg style flat alt scrutinizer status target https scrutinizer ci.com g aburrell aacgmv2 .. doi image https zenodo.org badge 42864636.svg target https zenodo.org badge latestdoi 42864636 changelog 2.5.1 2018 10 19 commented out debug statement in c code updated environment variable warning to output to stderr instead of stdout added templates for pull requests, issues, and a code of conduct 2.5.0 2018 08 08 updated c code and coefficients to version 2.5. changes in python code reflect changes in c code includes going back to using environment variables instead of strings for coefficient file locations added decorators to some of the test functions specified appveyor visual studio version, since it was defaulting to 2010 and that version doesn't work with python 3 2.4.2 2018 05 21 fixed bug in convert mlt that caused all time inputs to occur at 00 00 00 ut fixed year of last two updates in changelog 2.4.1 2018 04 04 fix bug in installation that caused files to be placed in the wrong directory added doi 2.4.0 2018 03 21 update to use aacgm v2.4, which includes changes to the inverse mlt and dipole tilt functions and some minor bug fixes updated file structure updated methods, retaining old methods in deprecated module added testing for python 3.6 updated dependencies, removing support for python 3.3 tested on mac osx updated comments to include units for input and output 2.0.0 2016 11 03 change method of calculating mlt, see documentation of convert mlt for details 1.0.13 2015 10 30 correctly convert output of subsol to geodetic coordinates the error in mlt mlon conversion was not large, typically two decimal places and below 1.0.12 2015 10 26 return nan in forbidden region instead of throwing exception 1.0.11 2015 10 26 fix bug in subsolar mlt conversion 1.0.10 2015 10 08 no code changes, debugged automatic build upload process and needed new version numbers along the way 1.0.0 2015 10 07 initial release\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "aacgmv2      0.647916\n",
      "aburrell     0.431944\n",
      "aacgm        0.191975\n",
      "mlt          0.191975\n",
      "https        0.161439\n",
      "alt          0.139518\n",
      "target       0.117864\n",
      "flat         0.114346\n",
      "scrutinizer  0.113242\n",
      "image        0.110201\n",
      "style        0.092532\n",
      "github       0.090067\n",
      "pypi         0.089413\n",
      "status       0.088523\n",
      "doi          0.086480\n",
      "array        0.078664\n",
      "updated      0.078589\n",
      "appveyor     0.075979\n",
      "convert      0.073881\n",
      "dtime        0.071991\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aadbook\n",
      "Description:  aadbook access your azure ad contacts from the command line. about aadbook is a fork of goobook https pypi.org project goobook focusing on making it possible to use your azure ad contacts from the command line and from muas such as mutt. installation instructions there is a number of ways to install python software. using pip using a source tarball using source directly from gitorius from a distribution specific repository pip or easy install this is the recommended way to install aadbook for most users that don't have it available in their distribution. when installing this way you will not need to download anything manually. install like this pip install aadbook source installation download the source tarball, uncompress it, then run the install command tar xzvf aadbook .tar.gz cd aadbook sudo python . setup.py install configure for most users it will be enough to to run aadbook authenticate and follow the instructions. to get access too more settings you can create a configuration file aadbook config template .aadbookkrc it will look like this or at the start of a line makes it a comment. default the following are optional, defaults are shown this file is written by the azure ad library, and should be kept secure, it's like a password to your ad contacts. auth db filename .aadbook auth.json cache filename .aadbook cache cache expiry hours 24 proxy settings if you use a proxy you need to set the https proxy environment variable. mutt if you want to use aadbook from mutt. set in your .muttrc file set query command aadbook query ' s' to query address book. usage to query your contacts aadbook query query the cache is updated automatically according to the configuration but you can also force an update aadbook reload for more commands see aadbook h and aadbook command h changelog 0.1.2 2018 11 01 switch to requests 2.20.0 0.1.1 2018 10 21 fixed a bug where an exception thrown at startup when automatically refreshing auth tokens could make the authenticate command fail, leaving the user with no option other than wiping out aadbook caches 0.1.0 2018 10 09 implement automatic fuzzy finding by replacing each in the search query string with . 0.0.3 2018 10 01 fix a bug where internal credentials were not properly updated after tokens were updated using the refreshtoken throwing an error on the first aadbook query ... invocation 0.0.2 2018 09 16 the authenticate command now always initiates a full authentication workflow, irrespective of any cached token start up time has improved thanks the the internal token now being refreshed only when expired 0.0.1 2018 09 08 project inception\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "aadbook       0.790120\n",
      "query         0.222212\n",
      "ad            0.146289\n",
      "2018          0.145858\n",
      "azure         0.125591\n",
      "command       0.122493\n",
      "contacts      0.119685\n",
      "authenticate  0.117266\n",
      "cache         0.116214\n",
      "proxy         0.098915\n",
      "goobook       0.098765\n",
      "updated       0.080863\n",
      "install       0.077831\n",
      "09            0.075746\n",
      "tokens        0.071186\n",
      "source        0.068853\n",
      "auth          0.063140\n",
      "internal      0.061698\n",
      "10            0.059640\n",
      "token         0.058462\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aaltopoiju\n",
      "Description:  unofficial parser for aaltopoiju.fi this is screen scraper for aaltopoiju.fi website. please check terms and conditions before using. installation pip install aaltopoiju\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "aaltopoiju    0.455823\n",
      "scraper       0.455823\n",
      "unofficial    0.386422\n",
      "screen        0.313605\n",
      "parser        0.296268\n",
      "conditions    0.275013\n",
      "terms         0.263495\n",
      "check         0.192607\n",
      "please        0.165223\n",
      "installation  0.122074\n",
      "pip           0.118793\n",
      "install       0.102630\n",
      "00            0.000000\n",
      "operators     0.000000\n",
      "operator      0.000000\n",
      "operations    0.000000\n",
      "operation     0.000000\n",
      "operational   0.000000\n",
      "opinions      0.000000\n",
      "operating     0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  abakus-status-checks\n",
      "Description:  abakus status checks .. image https ci.frigg.io eirsyl abakus status checks.svg target https ci.frigg.io eirsyl abakus status checks last alt build status .. image https ci.frigg.io eirsyl abakus status checks coverage.svg target https ci.frigg.io eirsyl abakus status checks last alt coverage status this package is used together with sensu . checks is managed with puppet and reported to our devops channel on slack. supported checks cpu percent load create a new check create a new file in the abakus checks checks directory import abakus and use this as a base for your check. give the check a name, decription and options name 'load' description 'trigger errors based on load threshold. load is divided by core count.' options click.option ' warning', default '2,1.5,1', type str , click.option ' critical', default '3,2,1.5', type str , implement the run method. call self.ok, self.warning, self.critical with a message based on the result. register the check in abakus checks cli.py. import the check in the check import block and register the check. from .checks import load register check load.loadcheck you can use the tests.test case.clitestcase to test the check. this testcase has a .invoke method you can use to call the check. class loadchecktestcase clitestcase mock.patch 'os.getloadavg', return value 0, 0, 0 def test load ok self, mock loadavg result self.invoke 'load', ' warning '3.2.1 '' self.assertequals result.exit code, 0 .. sensu https sensuapp.org\n",
      "Highest ranked keywords:\n",
      "\n",
      "                     TF-IDF\n",
      "abakus             0.622270\n",
      "checks             0.428073\n",
      "eirsyl             0.311135\n",
      "load               0.218758\n",
      "check              0.197204\n",
      "status             0.182598\n",
      "sensu              0.155568\n",
      "register           0.134892\n",
      "import             0.096838\n",
      "str                0.094484\n",
      "last               0.082969\n",
      "https              0.079287\n",
      "decription         0.077784\n",
      "clitestcase        0.077784\n",
      "loadavg            0.077784\n",
      "loadchecktestcase  0.077784\n",
      "call               0.076036\n",
      "options            0.068025\n",
      "puppet             0.067906\n",
      "devops             0.067906\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  abci\n",
      "Description:  .. image https travis ci.org davebryson py abci.svg branch master target https https travis ci.org davebryson py abci .. image https codecov.io gh davebryson py abci branch master graph badge.svg target https codecov.io gh davebryson py abci .. image https img.shields.io pypi v abci.svg target https pypi.python.org pypi abci build blockchain applications in python for tendermint version supports abci v0.15.0 and tendermint v0.26.0 installation requires python 3.6.5 pip install abci or python setup.py install generating protobuf you only need to mess with the protobuf stuff if you're developing on this code base, not to create apps. if you just want to create apps, jump to getting started a note on protobuf. you'll notice 2 additional directories github and protobuf . the github dir is the protobuf generated code used by abci . it adds proper python path via init and preserves all the import statements used by tendermint for the various protobuf files spread across their codebase. the protobuf directory is the source .proto files. to build the protobuf files 1. install protoc so it's available as a command from a terminal 2. run the genproto.py script getting started 1. extend the baseapplication class 2. implement the tendermint abci callbacks see https github.com tendermint abci 3. run it see the example app counter.py application under the examples directory here https github.com davebryson py abci blob master examples counter.py\n",
      "Highest ranked keywords:\n",
      "\n",
      "                   TF-IDF\n",
      "abci             0.655392\n",
      "protobuf         0.432995\n",
      "davebryson       0.327696\n",
      "tendermint       0.327696\n",
      "py               0.157950\n",
      "https            0.120250\n",
      "gh               0.073728\n",
      "started          0.068992\n",
      "getting          0.067288\n",
      "protoc           0.065539\n",
      "baseapplication  0.061856\n",
      "mess             0.061856\n",
      "target           0.060357\n",
      "blockchain       0.059243\n",
      "jump             0.059243\n",
      "master           0.058754\n",
      "preserves        0.057217\n",
      "callbacks        0.057217\n",
      "spread           0.057217\n",
      "image            0.056433\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  abipy\n",
      "Description:  abipy is a python library to analyze the results produced by abinit https www.abinit.org , an open source program for the ab initio calculations of the physical properties of materials within density functional theory and many body perturbation theory. abipy also provides tools to generate input files and workflows to automate ab initio calculations and typical convergence studies. abipy is interfaced with pymatgen http www.pymatgen.org allowing users to benefit from the different tools and python objects available in the pymatgen ecosystem. abipy can be used in conjunction with matplotlib http matplotlib.org , pandas http pandas.pydata.org , ipython https ipython.org index.html and jupyter http jupyter.org thus providing a powerful and user friendly environment for data analysis and visualization. check out the list of plotting scripts available in our doc gallery examples index . to learn more about the integration between jupyter and abipy, visit our collection of notebooks http nbviewer.ipython.org github abinit abipy blob master abipy examples notebooks index.ipynb and the abipy lessons http nbviewer.ipython.org github abinit abipy blob master abipy examples notebooks lessons index.ipynb . the latest development version is always available from https github.com abinit abipy\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "abipy         0.759277\n",
      "abinit        0.303711\n",
      "notebooks     0.180302\n",
      "lessons       0.151855\n",
      "initio        0.151855\n",
      "pymatgen      0.151855\n",
      "ab            0.137268\n",
      "calculations  0.122680\n",
      "http          0.110334\n",
      "jupyter       0.109451\n",
      "examples      0.093666\n",
      "available     0.079686\n",
      "interfaced    0.075928\n",
      "perturbation  0.075928\n",
      "blob          0.072456\n",
      "conjunction   0.071661\n",
      "tools         0.070605\n",
      "convergence   0.068634\n",
      "plotting      0.064367\n",
      "physical      0.064367\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  abjad-ext-rmakers\n",
      "Description:  abjad ext rmakers abjad rhythm maker extension package. 3.0 alpha.\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "abjad        0.710668\n",
      "rhythm       0.355334\n",
      "rmakers      0.355334\n",
      "maker        0.355334\n",
      "ext          0.276077\n",
      "extension    0.199867\n",
      "operates     0.000000\n",
      "operations   0.000000\n",
      "operational  0.000000\n",
      "operation    0.000000\n",
      "operating    0.000000\n",
      "operated     0.000000\n",
      "operate      0.000000\n",
      "operand      0.000000\n",
      "operaciones  0.000000\n",
      "opera        0.000000\n",
      "openvenues   0.000000\n",
      "opensuse     0.000000\n",
      "openstack    0.000000\n",
      "operator     0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  acclaim-badges\n",
      "Description:  acclaim badges pypi badge travis badge codecov badge doc badge pyversions badge license badge issue badges from acclaim upon edx course completion. acclaim badges for edx overview adds a djangoapp to edx which provides a ui and api backend into acclaim. once installed, edx adminstrators will be able to add acclaim auth tokens and select badges to be issued upon course completion. this app then listens for course complete events, and issues badges if the student obtains a passing score. install 1. install acclaim badges using pip pip install acclaim badges 2. add acclaim badges to your installed apps setting for edx lms like this installed apps ... 'acclaim badges', note this file is usually located at edx platform lms envs common.py 3. include the acclaim badges urlconf in your project urls.py like this urlpatterns url r' acclaim ', include 'acclaim badges.urls' , 4. the authorization token field is encypted. create a aes 256 keyset using keyzar mkdir fieldkeys keyczart create location fieldkeys purpose crypt keyczart addkey location fieldkeys status primary size 256 5. add keyset location to edx platform lms envs common.py encrypted fields keydir ' path to fieldkeys' 6. run . manage.py lms syncdb settings aws to create the acclaim badges lms app. usage the following useful urls are made available after installation acclaim tokens acclaim badge courses 1 add acclaim organization and authorization token using acclaim tokens 2 define a mapping between badge and course by accessing acclaim badge courses note when defining a mapping, the dropdown will populate with badge templates if the acclaim api call is successful valid token and orgainzation combination are used . documentation the full documentation is at https acclaim badges.readthedocs.org. license the code in this repository is licensed under the agpl 3.0 unless otherwise noted. please see license.txt for details. how to contribute contributions are very welcome. please read how to contribute https github.com edx edx platform blob master contributing.rst for details. even though they were written with edx platform in mind, the guidelines should be followed for open edx code in general. pr description template should be automatically applied if you are sending pr from github interface otherwise you can find it it at pull request template.md https github.com edx acclaim badges blob master .github pull request template.md issue report template should be automatically applied if you are sending it from github ui as well otherwise you can find it at issue template.md https github.com edx acclaim badges blob master .github issue template.md reporting security issues please do not report security issues in public. please email security edx.org. getting help have a question about this repository, or about open edx in general please refer to this list of resources if you need any assistance. .. list of resources https open.edx.org getting help .. pypi badge image https img.shields.io pypi v acclaim badges.svg target https pypi.python.org pypi acclaim badges alt pypi .. travis badge image https travis ci.org edx acclaim badges.svg branch master target https travis ci.org edx acclaim badges alt travis .. codecov badge image http codecov.io github edx acclaim badges coverage.svg branch master target http codecov.io github edx acclaim badges branch master alt codecov .. doc badge image https readthedocs.org projects acclaim badges badge version latest target http acclaim badges.readthedocs.io en latest alt documentation .. pyversions badge image https img.shields.io pypi pyversions acclaim badges.svg target https pypi.python.org pypi acclaim badges alt supported python versions .. license badge image https img.shields.io github license edx acclaim badges.svg target https github.com edx acclaim badges blob master license.txt alt license change log .. all enhancements and patches to acclaim badges will be documented in this file. it adheres to the structure of http keepachangelog.com , but in restructuredtext instead of markdown for ease of incorporation into sphinx documentation and the pypi description . this project adheres to semantic versioning http semver.org . .. there should always be an unreleased section for changes pending release. unreleased 0.1.0 2017 05 10 added first release on pypi.\n",
      "Highest ranked keywords:\n",
      "\n",
      "             TF-IDF\n",
      "acclaim    0.748892\n",
      "edx        0.468058\n",
      "badges     0.267550\n",
      "badge      0.151295\n",
      "lms        0.110439\n",
      "course     0.070366\n",
      "fieldkeys  0.070209\n",
      "https      0.066794\n",
      "platform   0.059846\n",
      "alt        0.054426\n",
      "pypi       0.053661\n",
      "tokens     0.050603\n",
      "master     0.048953\n",
      "keyczart   0.046806\n",
      "keyset     0.046806\n",
      "blob       0.044666\n",
      "security   0.044530\n",
      "codecov    0.044530\n",
      "adheres    0.044176\n",
      "target     0.043105\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  acid-senza-templates\n",
      "Description:  senza template for automatic deployment of postgresql instances this package provides an external template for the stups senza tool https github.com zalando stups senza , allowing rapid deployment of postgresql nodes on aws. it's designed to work together with an external tool that runs senza with all necessary parameters and deploy db instances automatically, therefore, the template is a non interactive one. compared to the postgresapp template included with senza it adds the following actions nat gateways are detected based on the customer dns zone. correct etcd endpoints in the current account are detected for a specific region. non interactive mode is the default one, all parameters can be supplied with environment variables v option during senza init . pg hba.conf is configured by default to reject non ssl connections. standby and superuser passwords are automatically generated. all passwords and scalyr keys are encrypted. zmon2 group is automatically picked from the current account. ebs is always used. installation .. code block bash sudo pip3 install upgrade senza.templates.acid usage .. code block bash senza init t base v param name deployment.yaml below is the list of parameters supported by the template team name the name of the team to deploy the template used as part of the dns name for the resulting instance . team region aws region of the team to deploy the template by default, eu west 1 and eu central 1 are supported . team gateway zone the dns zone the application runs at, to look for the nat gateways. add replica loadbalancer whether to add a separate load balancer to serve requests for the replica default false . instance type aws ec2 instance type to deploy the db on default t2.medium . volume size initial size of the db ebs volume in gbs default 10 . volume type aws type of the ebs volume default gp2 . volume iops number of the io operations per second for the provision io ebs volumes. snapshot id id of the existing ebs snapshot to initialize the new database from. scalyr account key key to the scalyr account to log the database activity. pgpassword admin password to the admin account. postgresql conf a json dictionary of the key value parameters for the postgresql. examples initialization .. code block bash senza init t base v team name foo v 'team region eu west 1' v 'team gateway zone foo.example.com' v 'hosted zone db.example.com' v instance type m3.medium' v 'postgresql conf ' shared buffers 1gb ' deploy.yaml deployment .. code block bash senza create deploy.yaml bar the steps above result in the deployment of the new postgresql cluster consisting of 3 t2.medium instances, available under the name of bar.db.example.com and accessible to the application running in the account associated with the dns zone foo.example.com . they only work in the aws environment configured for stups and senza. senza it a powerful tool developed by zalando to deploy applications on aws. if you are not familiar with senza based deployments, please, refer to the stups documentation http stups.readthedocs.io en latest . license apache 2.0 releasing .. code block bash . release.sh new version\n",
      "Highest ranked keywords:\n",
      "\n",
      "              TF-IDF\n",
      "senza       0.532362\n",
      "ebs         0.228385\n",
      "zone        0.199970\n",
      "team        0.195752\n",
      "stups       0.193586\n",
      "template    0.179088\n",
      "volume      0.170214\n",
      "deploy      0.164763\n",
      "dns         0.159976\n",
      "postgresql  0.147850\n",
      "scalyr      0.145190\n",
      "deployment  0.130502\n",
      "eu          0.126752\n",
      "aws         0.113214\n",
      "account     0.107770\n",
      "bash        0.106102\n",
      "parameters  0.101893\n",
      "default     0.099080\n",
      "region      0.097876\n",
      "block       0.097416\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  acidfile\n",
      "Description:  acidfile acidfile module provides the acidfile object. this object can be used as a regular file object but instead of write one copy of the data, it will write several copies to disk in an acid manner. this algorithm was explained by elvis pftzenreuter in his blog post achieving acid transactions with common files . latest stable version can be found on pypi . .. image https travis ci.org nilp0inter acidfile.png branch develop target https travis ci.org nilp0inter acidfile .. image https pypip.in v acidfile badge.png target https pypi.python.org pypi acidfile alt latest pypi version .. image https pypip.in d acidfile badge.png target https pypi.python.org pypi acidfile alt number of pypi downloads acidfile is compatible with python 2.6, 2.7, 3.2, 3.3, 3.4 and pypy contribute .. image http api.flattr.com button flattr badge large.png target https flattr.com submit auto user id nilp0inter url https github.com nilp0inter acidfile title acidfile language tags github category software alt flattr this git repo installation latest version can be installed via pip .. code block bash pip install upgrade acidfile running the tests clone this repository and install the develop requirements. .. code block bash git clone https github.com nilp0inter acidfile.git cd acidfile pip install r requirements develop.txt python setup.py develop tox usage examples basic usage .. code block python from acidfile import acidfile myfile acidfile ' tmp myfile.txt', 'w' myfile.write b'some important data.' myfile.close at the close invocation two copies will be written to disk myfile.txt.0 and below myfile.txt.1 . each one will have an creation timestamp and a hmac signature. .. code block python myfile acidfile ' tmp myfile.txt', 'r' print myfile.read 'some important data.' myfile.close if any of the files is damaged due to turning off without proper shutdown or disk failure, manipulation, etc. it will be detected by the internal hmac and the other's file data would be used instead. .. note if you want to read an acidfile , never pass the full path of the real file, instead use the file name that you use in the creation step.  acidfile ' tmp myfile.txt.0', 'r'  acidfile ' tmp myfile.txt.1', 'r'  acidfile ' tmp myfile.txt', 'r' context manager acidfile can and should be used as a regular context manager .. code block python with acidfile ' tmp myfile.txt', 'w' as myfile ... myfile.write b'some important data.' number of copies the number of inner copies of the data can be configured through the copies parameter. checksum key the key used for compute and check the internal hmac signature can be setted by the key parameter. it's recommended to change that key in order to protect against fraud, making more difficult for a tamperer to put a fake file in place of the legitimate one. .. pypi https pypi.python.org pypi acidfile .. elvis pftzenreuter epx epx.com.br .. achieving acid transactions with common files http epx.com.br artigos arqtrans en.php .. this is your project news file which will contain the release notes. .. example http www.python.org download releases 2.6 news.txt .. the content of this file, along with readme.rst, will appear in your .. project's pypi page. news 1.2.1 using io.open in setup.py to read readme and news. this fix some problems installing the package. python 3.4 support. 1.2.0 python 2.6 support. added python 3.2 and pypy to tox tests. added flattr button d fixed flake8 and pylint warnings. 1.1.0 python 3 support. changed testing framework to behave because python 3 support. using tox for multiple python version testing. 1.0.0 first stable release. documentation. 0.0.1 initial development.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "acidfile      0.851095\n",
      "nilp0inter    0.177311\n",
      "tmp           0.153358\n",
      "copies        0.126213\n",
      "myfile        0.106387\n",
      "flattr        0.106387\n",
      "acid          0.100409\n",
      "hmac          0.092877\n",
      "python        0.083192\n",
      "pypi          0.081313\n",
      "disk          0.075728\n",
      "https         0.072295\n",
      "block         0.071381\n",
      "elvis         0.070925\n",
      "achieving     0.070925\n",
      "pftzenreuter  0.070925\n",
      "tox           0.070377\n",
      "important     0.062974\n",
      "transactions  0.061918\n",
      "key           0.061197\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  acoular\n",
      "Description:  .. readme.rst acoular acoular is a python module for acoustic beamforming that is distributed under the new bsd license. it is aimed at applications in acoustic testing. multichannel data recorded by a microphone array can be processed and analyzed in order to generate mappings of sound source distributions. the maps acoustic photographs can then be used to locate sources of interest and to characterize them using their spectra. features covers several beamforming algorithms different advanced deconvolution algorithms both time domain and frequency domain operation included 3d mapping possible application for stationary and for moving targets supports both scripting and graphical user interface efficient intelligent caching, parallel computing with numba easily extendible and well documented dependencies acoular runs under linux, windows and macos, a python 3.6, 3.5, 3.4 or 2.7 installation is needed with the latest numpy, scipy, traits, traitsui, scikit learn, pytables, numba, pyqt packages available.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "acoular        0.400849\n",
      "acoustic       0.362342\n",
      "beamforming    0.267233\n",
      "algorithms     0.192610\n",
      "domain         0.164549\n",
      "multichannel   0.133616\n",
      "deconvolution  0.133616\n",
      "characterize   0.133616\n",
      "photographs    0.133616\n",
      "microphone     0.133616\n",
      "intelligent    0.126108\n",
      "stationary     0.126108\n",
      "extendible     0.126108\n",
      "aimed          0.120781\n",
      "locate         0.120781\n",
      "numba          0.120781\n",
      "covers         0.120781\n",
      "analyzed       0.120781\n",
      "scripting      0.116649\n",
      "pyqt           0.113273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  actionable-agile-extract\n",
      "Description:  jira cycle data extract utility this utility helps extract data from jira for processing with the actionableagile analytics tool https www.actionableagile.com analytics tools , as well as ad hoc analysis using excel. it will produce a csv file with one row for each jira issue matching a set of filter criteria, containing basic information about the issue as well as the date the issue entered each step in the main cycle workflow. this data can be used to produce a cumulative flow diagram, a cycle time scatterplot, a cycle time histogram, and other analytics based on cycle time. installation install python 2.7 and pip. see http pip.readthedocs.org en stable installing . install using pip pip install actionable agile extract if you get errors, try to install numpy and pandas separately first pip install numpy pandas pip install actionable agile extract configuration write a yaml configuration file like so, calling it e.g. config.yaml how to connect to jira connection domain https myserver.atlassian.net username myusername if missing, you will be prompted at runtime password secret if missing, you will be prompted at runtime what to search for criteria project abc jira project key to search issue types which issue types to include story defect valid resolutions which resolution statuses to include unresolved is always included done closed jql labels spike additional filter as raw jql, optional describe the workflow. each step can be mapped to either a single jira status, or a list of statuses that will be treated as equivalent workflow open open analysis ip analysis in progress analysis done analysis done development ip development in progress development done development done test ip test in progress test done test done done closed done map field names to additional attributes to extract attributes components component s priority priority release fix version s the sections for connection , criteria and workflow are required. under conection , only domain is required. if not specified, the script will prompt for both or either of username and password when run. under criteria , all fields are technically optional, but you should specify at least some of them to avoid an unbounded query. under workflow , at least two steps are required. specify the steps in order. you may either specify a single workflow value or a list as shown for done above , in which case multiple jira statuses will be collapsed into a single state for analytics purposes. the file, and values for things like workflow statuses and attributes, are case insensitive. when specifying attributes, use the name of the field as rendered on screen in jira , not its id as you might do in jql , so e.g. use component s not components . the attributes type issue type , status and resolution are always included. when specifying fields like component s or fix version s that may have lists of values, only the first value set will be used. running run the binary with jira cycle extract config.yaml data.csv this will extract a csv file called data.csv with cycle data based on the configuration in config.yaml . use the v option to print more information during the extract process.\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "jira         0.440164\n",
      "cycle        0.312976\n",
      "done         0.286014\n",
      "extract      0.257810\n",
      "statuses     0.195628\n",
      "analytics    0.183467\n",
      "workflow     0.180622\n",
      "analysis     0.159158\n",
      "issue        0.146432\n",
      "criteria     0.131129\n",
      "component    0.115537\n",
      "progress     0.115537\n",
      "actionable   0.108209\n",
      "attributes   0.102948\n",
      "agile        0.102128\n",
      "ip           0.101396\n",
      "jql          0.097814\n",
      "resolution   0.091734\n",
      "prompted     0.087419\n",
      "development  0.086724\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  activation\n",
      "Description:  activations .. image https img.shields.io pypi v activation.svg target https pypi.python.org pypi activation .. image https img.shields.io travis deybvagm activation.svg target https travis ci.org deybvagm activation .. image https readthedocs.org projects activation badge version latest target https en latest badge latest alt documentation status activation function for machine learning. this package only computes the sigmoid activation function on an scalar or a numpy array free software mit license documentation https features todo credits this package was created with cookiecutter and the audreyr cookiecutter pypackage project template. .. cookiecutter https github.com audreyr cookiecutter .. audreyr cookiecutter pypackage https github.com audreyr cookiecutter pypackage history 0.1.0 2018 03 10 first release on pypi.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "activation     0.540141\n",
      "cookiecutter   0.478530\n",
      "audreyr        0.319020\n",
      "deybvagm       0.247484\n",
      "pypackage      0.241283\n",
      "https          0.227039\n",
      "activations    0.123742\n",
      "sigmoid        0.123742\n",
      "latest         0.122411\n",
      "target         0.113958\n",
      "scalar         0.111855\n",
      "function       0.111309\n",
      "computes       0.108028\n",
      "image          0.106549\n",
      "badge          0.094114\n",
      "array          0.081128\n",
      "package        0.076087\n",
      "travis         0.075286\n",
      "numpy          0.075155\n",
      "documentation  0.073954\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  active-redis\n",
      "Description:  example from active redis import activeredis, activeredismodel, uuidgenerator class movie activeredismodel stored attrs 'title', 'year', 'author' def init self, uuid, title, year, author self.uuid uuid self.title, self.year, self.author title, year, author if name ' main ' activeredis.config 'connexion' 'db' 3 , 'namespace prefix' 'mycinema' assert movie.delete all assert 0, movie.count topgun movie uuidgenerator.generate , 'topgun', 1987, 'tony s.' assert topgun.save titanic movie uuidgenerator.generate , 'titanic', 1997, 'james c.' assert titanic.save topgun.update attr 'title', 'top gun' assert 'top gun', movie.find topgun.uuid .title assert 2, movie.count assert 2, len movie.find all m movie.find topgun.uuid m.delete assert 1, movie.count assert 1, len movie.find all\n",
      "Highest ranked keywords:\n",
      "\n",
      "                    TF-IDF\n",
      "assert            0.821565\n",
      "movie             0.347500\n",
      "len               0.188890\n",
      "uuidgenerator     0.132682\n",
      "activeredismodel  0.132682\n",
      "topgun            0.132682\n",
      "author            0.128347\n",
      "attr              0.125227\n",
      "titanic           0.125227\n",
      "attrs             0.115833\n",
      "uuid              0.109646\n",
      "redis             0.091285\n",
      "active            0.083509\n",
      "stored            0.076699\n",
      "init              0.072772\n",
      "main              0.063098\n",
      "def               0.060564\n",
      "class             0.054042\n",
      "name              0.044046\n",
      "example           0.042483\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  active-sqlalchemy\n",
      "Description:  active sqlalchemy a framework agnostic wrapper for sqlalchemy that makes it really easy to use by implementing a simple active record like api, while it still uses the db.session underneath copyright  2014 2015 by mardix . license mit, see license for more details.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "sqlalchemy    0.436516\n",
      "active        0.385972\n",
      "mardix        0.306622\n",
      "underneath    0.289392\n",
      "agnostic      0.259938\n",
      "implementing  0.210955\n",
      "record        0.204725\n",
      "license       0.193565\n",
      "really        0.191546\n",
      "framework     0.178271\n",
      "2014          0.164270\n",
      "wrapper       0.163531\n",
      "2015          0.160017\n",
      "still         0.160017\n",
      "makes         0.154343\n",
      "copyright     0.152046\n",
      "uses          0.126697\n",
      "easy          0.126390\n",
      "simple        0.113558\n",
      "like          0.105924\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-ads1x15\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython ads1x15 badge version latest target https projects ads1x15 en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https adafru.it discord alt discord .. image https travis ci.org adafruit adafruit circuitpython ads1x15.svg branch master target https travis ci.org adafruit adafruit circuitpython ads1x15 alt build status support for the ads1x15 series of analog to digital converters. available in 12 bit ads1015 and 16 bit ads1115 versions. installation dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice please ensure all dependencies are available on the circuitpython filesystem. this can be most easily achieved by downloading and installing the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle on your device. installing from pypi on supported gnu linux systems like the raspberry pi, you can install the driver locally from pypi https pypi.org project adafruit circuitpython ads1x15 . to install for current user .. code block shell pip3 install adafruit circuitpython ads1x15 to install system wide this may be required in some cases .. code block shell sudo pip3 install adafruit circuitpython ads1x15 to install in a virtual environment in your current project .. code block shell mkdir project name cd project name python3 m venv .env source .env bin activate pip3 install adafruit circuitpython ads1x15 usage example single ended .. code block python import time import board import busio import adafruit ads1x15.ads1015 as ads from adafruit ads1x15.analog in import analogin create the i2c bus i2c busio.i2c board.scl, board.sda create the adc object using the i2c bus ads ads.ads1015 i2c create single ended input on channel 0 chan analogin ads, ads.p0 create differential input between channel 0 and 1 chan analogin ads, ads.p0, ads.p1 print 5 t 5 .format 'raw', 'v' while true print 5 t 5.3f .format chan.value, chan.voltage time.sleep 0.5 contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython circuitpython ads1x15 blob master code of conduct.md before contributing to help this project stay welcoming. building locally to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython ads1x15 library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.574849\n",
      "circuitpython  0.496460\n",
      "ads1x15        0.367084\n",
      "shell          0.155242\n",
      "build          0.143619\n",
      "block          0.133000\n",
      "i2c            0.121340\n",
      "analogin       0.110125\n",
      "sphinx         0.108645\n",
      "code           0.107856\n",
      "install        0.090915\n",
      "https          0.089802\n",
      "locally        0.089787\n",
      "virtual        0.081331\n",
      "activate       0.078665\n",
      "bus            0.078388\n",
      "discord        0.075766\n",
      "venv           0.074238\n",
      "driver         0.069848\n",
      "ended          0.069291\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-as726x\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython as726x badge version latest target https projects as726x en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.org adafruit adafruit circuitpython as726x.svg branch master target https travis ci.org adafruit adafruit circuitpython as726x alt build status driver for the as726x spectral sensors installation and dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice register https github.com adafruit adafruit circuitpython register please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . installing from pypi on supported gnu linux systems like the raspberry pi, you can install the driver locally from pypi https pypi.org project adafruit circuitpython as726x . to install for current user .. code block shell pip3 install adafruit circuitpython as726x to install system wide this may be required in some cases .. code block shell sudo pip3 install adafruit circuitpython as726x to install in a virtual environment in your current project .. code block shell mkdir project name cd project name python3 m venv .env source .env bin activate pip3 install adafruit circuitpython as726x contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython as726x blob master code of conduct.md before contributing to help this project stay welcoming. building locally zip release files to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython as726x library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.596250\n",
      "circuitpython  0.514943\n",
      "as726x         0.380749\n",
      "shell          0.161021\n",
      "build          0.148966\n",
      "block          0.122624\n",
      "sphinx         0.112689\n",
      "code           0.101701\n",
      "https          0.100907\n",
      "driver         0.096597\n",
      "install        0.094300\n",
      "locally        0.093129\n",
      "virtual        0.084359\n",
      "activate       0.081593\n",
      "venv           0.077002\n",
      "bin            0.069519\n",
      "pip3           0.068915\n",
      "environment    0.065532\n",
      "project        0.061951\n",
      "python3        0.058171\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-bno055\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython bno055 badge version latest target https projects bno055 en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https adafru.it discord alt discord .. image https travis ci.org adafruit adafruit circuitpython bno055.svg branch master target https travis ci.org adafruit adafruit circuitpython bno055 alt build status dependencies this driver depends on the register https github.com adafruit adafruit circuitpython register and bus device https github.com adafruit adafruit circuitpython busdevice libraries. please ensure they are also available on the circuitpython filesystem. this is easily achieved by downloading a library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage notes of course, you must import the library to use it .. code python import adafruit bno055 this driver takes an instantiated and active i2c object from the busio or the bitbangio library as an argument to its constructor. the way to create an i2c object depends on the board you are using. for boards with labeled scl and sda pins, you can .. code python from busio import i2c from board import sda, scl i2c i2c scl, sda once you have the i2c object, you can create the sensor object .. code python sensor adafruit bno055.bno055 i2c and then you can start reading the measurements .. code python print sensor.temperature print sensor.euler print sensor.gravity contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython bno055 blob master code of conduct.md before contributing to help this project stay welcoming. building locally to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython bno055 library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.576994\n",
      "circuitpython  0.441231\n",
      "bno055         0.286093\n",
      "i2c            0.275826\n",
      "build          0.186554\n",
      "sphinx         0.141124\n",
      "code           0.140099\n",
      "shell          0.126032\n",
      "https          0.106927\n",
      "discord        0.098416\n",
      "block          0.095978\n",
      "driver         0.090728\n",
      "sda            0.090006\n",
      "scl            0.090006\n",
      "locally        0.087471\n",
      "library        0.085923\n",
      "busio          0.080845\n",
      "virtual        0.079234\n",
      "activate       0.076636\n",
      "sensor         0.075486\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-crickit\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython crickit badge version latest target https projects crickit en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.org adafruit adafruit circuitpython crickit.svg branch master target https travis ci.org adafruit adafruit circuitpython crickit alt build status this convenience library makes coding for the crickit robotics boards simpler and shorter. dependencies this driver depends on adafruit seesaw library https github.com adafruit adafruit circuitpython seesaw adafruit motor library https github.com adafruit adafruit circuitpython motor please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage example this examples shows how to control all the devices supported by the library. in most cases you just need a couple of imports. .. code block python this is a mock example showing typical usage of the library for each kind of device. from adafruit crickit import crickit add this import if using stepper motors. it will expose constants saying how to step stepper.forward, stepper.backward, etc. from adafruit motor import stepper set servo 1 to 90 degrees crickit.servo 1.angle 90 change servo settings. crickit.servo 1.actuation range 135 crickit.servo 1.set pulse width range min pulse 850, max pulse 2100 you can assign a device to a variable to get a shorter name. servo 2 crickit.servo 2 servo 2.throttle 0 run a continous servo on servo 2 backwards at half speed. crickit.continuous servo 2.throttle 0.5 run the motor on motor 1 terminals at half speed. crickit.dc motor 1.throttle 0.5 set drive 1 terminal to 3 4 strength. crickit.drive 1.fraction 0.75 if crickit.touch 1.value print touched terminal touch 1 a single stepper motor uses up all the motor terminals. crickit.stepper motor.onestep direction stepper.forward you can also use the drive terminals for a stepper motor crickit.drive stepper motor.onestep direction stepper.backward note on cpx crickit, neopixel pin is normally connected to a1, not to seesaw, so this part of the demo cannot control the neopixel terminal. strip or ring of 8 neopixels crickit.init neopixel 8 crickit.neopixel.fill 100, 100, 100 contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython crickit blob master code of conduct.md before contributing to help this project stay welcoming. building locally zip release files to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython crickit library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.548022\n",
      "circuitpython  0.356214\n",
      "motor          0.326985\n",
      "crickit        0.307958\n",
      "servo          0.269463\n",
      "stepper        0.192474\n",
      "build          0.150608\n",
      "neopixel       0.115484\n",
      "sphinx         0.113932\n",
      "pulse          0.108995\n",
      "shell          0.101748\n",
      "library        0.097114\n",
      "block          0.092982\n",
      "https          0.086325\n",
      "code           0.082258\n",
      "terminals      0.076990\n",
      "seesaw         0.076990\n",
      "locally        0.070617\n",
      "direction      0.069594\n",
      "drive          0.067213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-ds1307\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython ds1307 badge version latest target https projects ds1307 en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.com adafruit adafruit circuitpython ds1307.svg branch master target https travis ci.com adafruit adafruit circuitpython ds1307 alt build status this is a great battery backed real time clock rtc that allows your microcontroller project to keep track of time even if it is reprogrammed, or if the power is lost. perfect for datalogging, clock building, time stamping, timers and alarms, etc. the ds1307 is the most popular rtc but it requires 5v power to work. the ds1307 is simple and inexpensive but not a high precision device. it may lose or gain up to two seconds a day. for a high precision, temperature compensated alternative, please check out the ds3231 precision rtc https www.adafruit.com products 3013 . if you do not need a ds1307, or you need a 3.3v power logic capable rtc please check out our affordable pcf8523 rtc breakout https www.adafruit.com products 3295 . .. image .. docs static 3296 00.jpg alt ds1307 dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice register https github.com adafruit adafruit circuitpython register please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage notes of course, you must import the library to use it .. code python import busio import adafruit ds1307 import time all the adafruit rtc libraries take an instantiated and active i2c object from the busio library as an argument to their constructor. the way to create an i2c object depends on the board you are using. for boards with labeled scl and sda pins, you can .. code python from board import you can also use pins defined by the onboard microcontroller through the microcontroller.pin module. now, to initialize the i2c bus .. code python myi2c busio.i2c scl, sda once you have created the i2c interface object, you can use it to instantiate the rtc object .. code python rtc adafruit ds1307.ds1307 myi2c to set the time, you need to set datetime to a time.struct time object .. code python rtc.datetime time.struct time 2017,1,9,15,6,0,0,9, 1 after the rtc is set, you retrieve the time by reading the datetime attribute and access the standard attributes of a struct time such as tm year , tm hour and tm min . .. code python t rtc.datetime print t print t.tm hour, t.tm min contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython ds1307 blob master code of conduct.md before contributing to help this project stay welcoming. building locally to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython ds1307 library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                   TF-IDF\n",
      "adafruit         0.553931\n",
      "circuitpython    0.395665\n",
      "rtc              0.333513\n",
      "ds1307           0.333513\n",
      "build            0.144983\n",
      "code             0.128676\n",
      "time             0.123399\n",
      "i2c              0.122493\n",
      "sphinx           0.109677\n",
      "https            0.105764\n",
      "tm               0.104924\n",
      "shell            0.097948\n",
      "power            0.078199\n",
      "block            0.074591\n",
      "microcontroller  0.074114\n",
      "myi2c            0.074114\n",
      "sda              0.069949\n",
      "locally          0.067980\n",
      "object           0.066862\n",
      "library          0.066776\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-fxas21002c\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython fxas21002c badge version latest target https projects fxas21002c en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.org adafruit adafruit circuitpython fxas21002c.svg branch master target https travis ci.org adafruit adafruit circuitpython fxas21002c alt build status circuitpython module for the nxp fxas21002c gyroscope. dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage example see examples simpletest.py for an example of the usage. contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython fxas21002c blob master code of conduct.md before contributing to help this project stay welcoming. building locally to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython fxac21002c library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.592500\n",
      "circuitpython  0.555469\n",
      "fxas21002c     0.260119\n",
      "build          0.203540\n",
      "sphinx         0.153974\n",
      "shell          0.137508\n",
      "https          0.116664\n",
      "block          0.104717\n",
      "code           0.097272\n",
      "locally        0.095436\n",
      "virtual        0.086448\n",
      "activate       0.083614\n",
      "html           0.077392\n",
      "tools          0.072565\n",
      "discord        0.071584\n",
      "bin            0.071240\n",
      "venv           0.070141\n",
      "dependencies   0.069004\n",
      "bundle         0.068216\n",
      "environment    0.067154\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-htu21d\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython htu21d badge version latest target https projects htu21d en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.org adafruit adafruit circuitpython htu21d.svg branch master target https travis ci.org adafruit adafruit circuitpython htu21d alt build status this driver enables you to use the adafruit htu21d f temperature and humidity breakout with circuitpyton. dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage example .. code python import time import board import busio from adafruit htu21d import htu21d create library object using our bus i2c port i2c busio.i2c board.scl, board.sda sensor htu21d i2c while true print ntemperature 0.1f c sensor.temperature print humidity 0.1f sensor.relative humidity time.sleep 2 contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython htu21d blob master code of conduct.md before contributing to help this project stay welcoming. building locally zip release files to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython htu21d library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.590495\n",
      "circuitpython  0.459274\n",
      "htu21d         0.414782\n",
      "build          0.180312\n",
      "sphinx         0.136402\n",
      "humidity       0.124979\n",
      "shell          0.121815\n",
      "i2c            0.114256\n",
      "https          0.103350\n",
      "code           0.098481\n",
      "block          0.092767\n",
      "driver         0.087693\n",
      "locally        0.084545\n",
      "virtual        0.076583\n",
      "activate       0.074072\n",
      "html           0.068560\n",
      "library        0.066438\n",
      "bus            0.065611\n",
      "tools          0.064284\n",
      "discord        0.063415\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-ina219\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython ina219 badge version latest target https projects ina219 en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.org adafruit adafruit circuitpython ina219.svg branch master target https travis ci.org adafruit adafruit circuitpython ina219 alt build status circuitpython driver for the ina219 current sensor https www.adafruit.com product 904 . dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage example see example https github.com adafruit adafruit circuitpython ina219 blob master examples ina219 simpletest.py contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython ina219 blob master code of conduct.md before contributing to help this project stay welcoming. building locally to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython ina219 library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.594997\n",
      "circuitpython  0.528886\n",
      "ina219         0.371506\n",
      "build          0.181687\n",
      "sphinx         0.137442\n",
      "https          0.123072\n",
      "shell          0.122744\n",
      "block          0.093474\n",
      "driver         0.088361\n",
      "code           0.086828\n",
      "locally        0.085189\n",
      "virtual        0.077167\n",
      "activate       0.074637\n",
      "html           0.069082\n",
      "tools          0.064774\n",
      "discord        0.063899\n",
      "bin            0.063592\n",
      "venv           0.062611\n",
      "dependencies   0.061596\n",
      "bundle         0.060892\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-lis3dh\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython lis3dh badge version latest target https projects lis3dh en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.org adafruit adafruit circuitpython lis3dh.svg branch master target https travis ci.org adafruit adafruit circuitpython lis3dh alt build status adafruit circuitpython module for the lis3dh accelerometer. note this module is made to work with circuitpython and not micropython apis. usage example see the guide at https learn.adafruit.com circuitpython hardware lis3dh accelerometer dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython lis3dh blob master code of conduct.md before contributing to help this project stay welcoming. building locally to build this library locally you'll need to install the circuitpython travis build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install r requirements.txt once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython lis3dh library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.586809\n",
      "circuitpython  0.552291\n",
      "lis3dh         0.339453\n",
      "build          0.172479\n",
      "sphinx         0.143524\n",
      "shell          0.128176\n",
      "https          0.118633\n",
      "block          0.097611\n",
      "code           0.090670\n",
      "locally        0.088959\n",
      "virtual        0.080582\n",
      "activate       0.077940\n",
      "html           0.072140\n",
      "discord        0.066727\n",
      "bin            0.066406\n",
      "venv           0.065381\n",
      "dependencies   0.064321\n",
      "bundle         0.063586\n",
      "environment    0.062597\n",
      "driver         0.061514\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-max9744\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython max9744 badge version latest target https projects max9744 en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.org adafruit adafruit circuitpython max9744.svg branch master target https travis ci.org adafruit adafruit circuitpython max9744 alt build status circuitpython module for the max9744 20w class d amplifier. dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage example see examples max9744 simpletest.py for a demo of the usage. contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython max9744 blob master code of conduct.md before contributing to help this project stay welcoming. building locally to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython max9744 library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.536318\n",
      "circuitpython  0.536318\n",
      "max9744        0.376727\n",
      "build          0.210560\n",
      "sphinx         0.159284\n",
      "shell          0.142250\n",
      "https          0.109716\n",
      "block          0.108329\n",
      "code           0.100626\n",
      "locally        0.098727\n",
      "virtual        0.089430\n",
      "activate       0.086498\n",
      "html           0.080061\n",
      "tools          0.075068\n",
      "discord        0.074053\n",
      "bin            0.073697\n",
      "venv           0.072560\n",
      "dependencies   0.071384\n",
      "bundle         0.070569\n",
      "environment    0.069471\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-miniqr\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython miniqr badge version latest target https projects miniqr en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.org adafruit adafruit circuitpython miniqr.svg branch master target https travis ci.org adafruit adafruit circuitpython miniqr alt build status a non hardware dependant miniature qr generator library. all native python dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage example .. code block python import adafruit miniqr qr adafruit miniqr.qrcode qr.add data b'https www.adafruit.com' qr.make print qr.matrix contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython miniqr blob master code of conduct.md before contributing to help this project stay welcoming. building locally zip release files to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython miniqr library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.601665\n",
      "circuitpython  0.488853\n",
      "miniqr         0.316971\n",
      "build          0.206688\n",
      "sphinx         0.156355\n",
      "shell          0.139635\n",
      "block          0.127604\n",
      "code           0.112887\n",
      "https          0.107698\n",
      "locally        0.096912\n",
      "qr             0.095507\n",
      "virtual        0.087785\n",
      "activate       0.084907\n",
      "html           0.078589\n",
      "tools          0.073687\n",
      "discord        0.072692\n",
      "bin            0.072342\n",
      "venv           0.071226\n",
      "dependencies   0.070072\n",
      "bundle         0.069271\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-motor\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython motor badge version latest target https projects motor en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.com adafruit adafruit circuitpython motor.svg branch master target https travis ci.com adafruit adafruit circuitpython motor alt build status this helper library provides higher level objects to control motors and servos based on one or more pwm outputs. the pwm inputs can be any object that have a 16 bit duty cycle attribute. its assumed that the frequency has already been configured appropriately. typically 50hz for servos and 1600hz for motors. dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . installing from pypi on supported gnu linux systems like the raspberry pi, you can install the driver locally from pypi https pypi.org project adafruit circuitpython motor . to install for current user .. code block shell pip3 install adafruit circuitpython motor to install system wide this may be required in some cases .. code block shell sudo pip3 install adafruit circuitpython motor to install in a virtual environment in your current project .. code block shell mkdir project name cd project name python3 m venv .env source .env bin activate pip3 install adafruit circuitpython motor contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython motor blob master code of conduct.md before contributing to help this project stay welcoming. building locally to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython motor library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.544597\n",
      "circuitpython  0.514342\n",
      "motor          0.361046\n",
      "shell          0.179755\n",
      "build          0.166297\n",
      "block          0.136890\n",
      "sphinx         0.125800\n",
      "code           0.113533\n",
      "install        0.105271\n",
      "locally        0.103964\n",
      "https          0.095317\n",
      "virtual        0.094174\n",
      "activate       0.091086\n",
      "venv           0.085961\n",
      "pwm            0.085009\n",
      "servos         0.085009\n",
      "driver         0.080877\n",
      "bin            0.077607\n",
      "pip3           0.076933\n",
      "environment    0.073156\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-mprls\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython mprls badge version latest target https projects mprls en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.org adafruit adafruit circuitpython mprls.svg branch master target https travis ci.org adafruit adafruit circuitpython mprls alt build status circuitpython library to support honeywell mprls digital pressure sensors. dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage example .. code block python import time import board import busio import adafruit mprls i2c busio.i2c board.scl, board.sda  simplest use, connect to default over i2c mpr adafruit mprls.mprls i2c, psi min 0, psi max 25 while true  print mpr.pressure,  time.sleep 1 contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython mprls blob master code of conduct.md before contributing to help this project stay welcoming. building locally zip release files to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython mprls library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.606862\n",
      "circuitpython  0.505718\n",
      "mprls          0.331550\n",
      "build          0.185310\n",
      "sphinx         0.140183\n",
      "shell          0.125192\n",
      "block          0.114406\n",
      "https          0.106215\n",
      "code           0.101211\n",
      "psi            0.094729\n",
      "locally        0.086888\n",
      "virtual        0.078705\n",
      "i2c            0.078282\n",
      "activate       0.076125\n",
      "html           0.070460\n",
      "library        0.068280\n",
      "tools          0.066066\n",
      "discord        0.065173\n",
      "bin            0.064860\n",
      "venv           0.063859\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-pcd8544\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython pcd8544 badge version latest target https projects pcd8544 en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.com adafruit adafruit circuitpython pcd8544.svg branch master target https travis ci.com adafruit adafruit circuitpython pcd8544 alt build status a display control library for nokia pcd8544 monochrome displays dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . installing from pypi on supported gnu linux systems like the raspberry pi, you can install the driver locally from pypi https pypi.org project adafruit circuitpython pcd8544 . to install for current user .. code block shell pip3 install adafruit circuitpython pcd8544 to install system wide this may be required in some cases .. code block shell sudo pip3 install adafruit circuitpython pcd8544 to install in a virtual environment in your current project .. code block shell mkdir project name cd project name python3 m venv .env source .env bin activate pip3 install adafruit circuitpython pcd8544 usage example see examples folder for demos of pixels, lines, and text contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython pcd8544 blob master code of conduct.md before contributing to help this project stay welcoming. building locally zip release files to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython pcd8544 library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.568609\n",
      "circuitpython  0.511748\n",
      "pcd8544        0.399408\n",
      "shell          0.168912\n",
      "build          0.156266\n",
      "block          0.128633\n",
      "sphinx         0.118212\n",
      "code           0.106685\n",
      "install        0.098921\n",
      "https          0.097710\n",
      "locally        0.097693\n",
      "virtual        0.088493\n",
      "activate       0.085592\n",
      "venv           0.080776\n",
      "driver         0.075998\n",
      "bin            0.072926\n",
      "pip3           0.072293\n",
      "environment    0.068743\n",
      "project        0.064987\n",
      "python3        0.061021\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-rfm69\n",
      "Description:  introduction .. image https readthedocs.org projects adafruit circuitpython rfm69 badge version latest target https projects rfm69 en latest alt documentation status .. image https img.shields.io discord 327254708534116352.svg target https discord.gg nbqh6qu alt discord .. image https travis ci.com adafruit adafruit circuitpython rfm69.svg branch master target https travis ci.com adafruit adafruit circuitpython rfm69 alt build status circuitpython rfm69 packet radio module. this supports basic radiohead compatible sending and receiving of packets with rfm69 series radios 433 915mhz . .. note this does not support advanced radiohead features like guaranteed delivery only 'raw' packets are currently supported. .. warning this is not for lora radios .. note this is a 'best effort' at receiving data using pure python code there is not interrupt support so you might lose packets if they're sent too quickly for the board to process them. you will have the most luck using this in simple low bandwidth scenarios like sending and receiving a 60 byte packet at a time don't try to receive many kilobytes of data at a time dependencies this driver depends on adafruit circuitpython https github.com adafruit circuitpython bus device https github.com adafruit adafruit circuitpython busdevice please ensure all dependencies are available on the circuitpython filesystem. this is easily achieved by downloading the adafruit library and driver bundle https github.com adafruit adafruit circuitpython bundle . usage example see examples rfm69 simpletest.py for a simple demo of the usage. note the default baudrate for the spi is 5000000 5mhz . the maximum setting is 10mhz but transmission errors have been observed expecially when using breakout boards. for breakout boards or other configurations where the boards are separated, it may be necessary to reduce the baudrate for reliable data transmission. the baud rate may be specified as an keyword parameter when initializing the board. to set it to 1000000 use .. code block python initialze rfm radio rfm9x adafruit rfm9x.rfm9x spi, cs, reset, radio freq mhz,baudrate 1000000 contributing contributions are welcome please read our code of conduct https github.com adafruit adafruit circuitpython rfm69 blob master code of conduct.md before contributing to help this project stay welcoming. building locally to build this library locally you'll need to install the circuitpython build tools https github.com adafruit circuitpython build tools package. .. code block shell python3 m venv .env source .env bin activate pip install circuitpython build tools once installed, make sure you are in the virtual environment .. code block shell source .env bin activate then run the build .. code block shell circuitpython build bundles filename prefix adafruit circuitpython rfm69 library location . sphinx documentation sphinx is used to build the documentation based on rst files and comments in the code. first, install dependencies feel free to reuse the virtual environment from above .. code block shell python3 m venv .env source .env bin activate pip install sphinx sphinx rtd theme now, once you have the virtual environment activated .. code block shell cd docs sphinx build e w b html . build html this will output the documentation to docs build html . open the index.html in your browser to view them. it will also due to w error out on any warning like travis will. this is a good way to locally verify it will pass.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "adafruit       0.533578\n",
      "circuitpython  0.470804\n",
      "rfm69          0.352754\n",
      "build          0.172516\n",
      "sphinx         0.130505\n",
      "shell          0.116549\n",
      "radio          0.115485\n",
      "packets        0.109316\n",
      "block          0.106507\n",
      "code           0.106001\n",
      "receiving      0.104709\n",
      "https          0.098882\n",
      "radios         0.088189\n",
      "radiohead      0.088189\n",
      "1000000        0.088189\n",
      "baudrate       0.083233\n",
      "locally        0.080889\n",
      "packet         0.079717\n",
      "breakout       0.079717\n",
      "boards         0.074761\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adapted-logger\n",
      "Description:  adapted logger a helper log library based on default logging module permetting a custom format of logs to be redirected to logstash elasticsearch kibana. custom usage how to install install adapted logger using easy setup or pip pip install adapted logger how to use from logger.adapted logger import adaptedlogger logger adaptedlogger project name , 127.0.0.1 specify project name and ip address of current server log logger.get logger log.info this is an info message log.debug this is a debug message log.warn this is a warning message log.error this is an error message results 2015 10 27 17 06 50,176 project name info 127.0.0.1 this is an info message 2015 10 27 17 06 55,552 project name debug 127.0.0.1 this is a debug message 2015 10 27 17 07 00,863 project name warning 127.0.0.1 this is a warning message 2015 10 27 17 07 05,360 project name error 127.0.0.1 this is an error message redirect logs to console instantiate adaptedlogger object adapted log adaptedlogger retail crm server , 127.0.0.1 redirect logs to console default behavior adapted log.redirect to console get logger object logger adapted log.get logger logger.debug testing debug message logger.info testing info message logger.warn testing warn message logger.error testing error message redirect logs to file instantiate adaptedlogger object adapted log adaptedlogger retail crm server , 127.0.0.1 redirect logs to file adapted log.redirect to file path logfile.log get logger object logger adapted log.get logger logger.debug testing debug message logger.info testing info message logger.warn testing warn message logger.error testing error message custom adapter this adds the possibility to configure your logger within a config file like config.yml, inside config folder you should specify your configuration in yaml format. formatters simpleformater format ' asctime s name s levelname s message s' datefmt ' y m d h m s's here we specify time, package name, level name, and the message, right now there is no injection of the ip address handlers console class logging.streamhandler formatter simpleformater level debug stream ext sys.stdout file class logging.filehandler formatter simpleformater level warning filename filename or path.log here we specify handlers, in this exemple we use 2 handlers console and file. loggers clogger level debug handlers console flogger level warning handlers file and finally we create 2 loggers for console and file handlers. to inject ip address into context, we have created customadapter class that create an adapter and inject ip in the process. usage logging config yaml.load open 'config config.yml', 'r' dictconfig logging config logger 1 logging.getlogger project name.application name1 logger 1 customadapter logger 1, 'ip' ip logger 2 logging.getlogger project name.application name2 logger 2 customadapter logger 2, 'ip' ip right now, we can call logger 1.warning 'this is a warning message' logger 2.error 'this is an error message\n",
      "Highest ranked keywords:\n",
      "\n",
      "                  TF-IDF\n",
      "logger          0.590582\n",
      "message         0.340461\n",
      "adapted         0.281460\n",
      "adaptedlogger   0.237053\n",
      "debug           0.164729\n",
      "console         0.161741\n",
      "testing         0.159099\n",
      "ip              0.148086\n",
      "logs            0.134506\n",
      "warning         0.125314\n",
      "simpleformater  0.118527\n",
      "customadapter   0.118527\n",
      "redirect        0.117039\n",
      "handlers        0.115416\n",
      "error           0.106618\n",
      "project         0.102855\n",
      "level           0.101408\n",
      "info            0.100208\n",
      "name            0.091809\n",
      "27              0.090839\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adaptfilt\n",
      "Description:  adaptfilt   adaptfilt is an adaptive filtering module for python. it includes simple, procedural implementations of the following filtering algorithms   least mean squares lms including traditional and leaky filtering normalized least mean squares nlms including traditional and leaky filtering with recursively updated input energy affine projection ap including traditional and leaky filtering  the algorithms are implemented using numpy for computational efficiency. further optimization have also been done, but this is very limited and only on the most computationally intensive parts of the source code. future implementation of the following algorithms is currently planned   recursive least squares rls  steepest descent sd   authors jesper wramberg mathias tausen version 0.2 pypi https pypi.python.org pypi adaptfilt github https github.com wramberg adaptfilt license mit  installation  to install from pypi using pip simply run   sudo pip install adaptfilt  alternatively, the module can also be downloaded at https pypi.python.org pypi adaptfilt or  https github.com wramberg adaptfilt. the latter is also used for issue tracking. note that adaptfilt requires numpy to be installed tested using version 1.9.0 .  usage  once installed, the module should be available for import by calling   import adaptfilt  following the reference sections, examples are provided to show the modules functionality.  function reference  in this section, the functions provided by adaptfilt are described. the descriptions correspond with excerpts from the function docstrings and are only included here for your convenience.  y, e, w lms u, d, m, step, leak 0., initcoeffs none, n none, returncoeffs false   perform least mean squares lms adaptive filtering on u to minimize error given by e d y, where y is the output of the adaptive filter.  parameters u array like one dimensional filter input. d array like one dimensional desired signal, i.e., the output of the unknown fir system which the adaptive filter should identify. must have length  len u , or n m 1 if number of iterations are limited via the n parameter . m int desired number of filter taps desired filter order 1 , must be non negative. step float step size of the algorithm, must be non negative.  optional parameters leak float leakage factor, must be equal to or greater than zero and smaller than one. when greater than zero a leaky lms filter is used. defaults to 0, i.e., no leakage. initcoeffs array like initial filter coefficients to use. should match desired number of filter taps, defaults to zeros. n int number of iterations, must be less than or equal to len u m 1 default . returncoeffs boolean if true, will return all filter coefficients for every iteration in an n x m matrix. does not include the initial coefficients. if false, only the latest coefficients in a vector of length m is returned. defaults to false.  returns y numpy.array output values of lms filter, array of length n. e numpy.array error signal, i.e, d y. array of length n. w numpy.array final filter coefficients in array of length m if returncoeffs is false. nxm array containing all filter coefficients for all iterations otherwise.  raises typeerror if number of filter taps m is not type integer, number of iterations n is not type integer, or leakage leak is not type float int. valueerror if number of iterations n is greater than len u m, number of filter taps m is negative, or if step size or leakage is outside specified range.  y, e, w nlmsru u, d, m, step, eps 0.001, leak 0, initcoeffs none, n none, returncoeffs false   same as nlms but updates input energy recursively for faster computation. note that this can cause instability due to rounding errors.  y, e, w nlms u, d, m, step, eps 0.001, leak 0, initcoeffs none, n none, returncoeffs false   perform normalized least mean squares nlms adaptive filtering on u to minimize error given by e d y, where y is the output of the adaptive filter.  parameters u array like one dimensional filter input. d array like one dimensional desired signal, i.e., the output of the unknown fir system which the adaptive filter should identify. must have length  len u , or n m 1 if number of iterations are limited via the n parameter . m int desired number of filter taps desired filter order 1 , must be non negative. step float step size of the algorithm, must be non negative.  optional parameters eps float regularization factor to avoid numerical issues when power of input is close to zero. defaults to 0.001. must be non negative. leak float leakage factor, must be equal to or greater than zero and smaller than one. when greater than zero a leaky lms filter is used. defaults to 0, i.e., no leakage. initcoeffs array like initial filter coefficients to use. should match desired number of filter taps, defaults to zeros. n int number of iterations to run. must be less than or equal to len u m 1. defaults to len u m 1. returncoeffs boolean if true, will return all filter coefficients for every iteration in an n x m matrix. does not include the initial coefficients. if false, only the latest coefficients in a vector of length m is returned. defaults to false.  returns y numpy.array output values of lms filter, array of length n. e numpy.array error signal, i.e, d y. array of length n. w numpy.array final filter coefficients in array of length m if returncoeffs is false. nxm array containing all filter coefficients for all iterations otherwise.  raises typeerror if number of filter taps m is not type integer, number of iterations n is not type integer, or leakage leak is not type float int. valueerror if number of iterations n is greater than len u m, number of filter taps m is negative, or if step size or leakage is outside specified range.   y, e, w ap u, d, m, step, k, eps 0.001, leak 0, initcoeffs none, n none, returncoeffs false   perform affine projection ap adaptive filtering on u to minimize error given by e d y, where y is the output of the adaptive filter.  parameters u array like one dimensional filter input. d array like one dimensional desired signal, i.e., the output of the unknown fir system which the adaptive filter should identify. must have length  len u , or n m 1 if number of iterations are limited via the n parameter . m int desired number of filter taps desired filter order 1 , must be non negative. step float step size of the algorithm, must be non negative. k int projection order, must be integer larger than zero.  optional parameters eps float regularization factor to avoid numerical issues when power of input is close to zero. defaults to 0.001. must be non negative. leak float leakage factor, must be equal to or greater than zero and smaller than one. when greater than zero a leaky lms filter is used. defaults to 0, i.e., no leakage. initcoeffs array like initial filter coefficients to use. should match desired number of filter taps, defaults to zeros. n int number of iterations to run. must be less than or equal to len u m 1. defaults to len u m 1. returncoeffs boolean if true, will return all filter coefficients for every iteration in an n x m matrix. does not include the initial coefficients. if false, only the latest coefficients in a vector of length m is returned. defaults to false.  returns y numpy.array output values of lms filter, array of length n. e numpy.array error signal, i.e, d y. array of length n. w numpy.array final filter coefficients in array of length m if returncoeffs is false. nxm array containing all filter coefficients for all iterations otherwise.  raises typeerror if number of filter taps m is not type integer, number of iterations n is not type integer, or leakage leak is not type float int. valueerror if number of iterations n is greater than len u m, number of filter taps m is negative, or if step size or leakage is outside specified range.   helper function reference  mswe mswe w, v   calculate mean squared weight error between estimated and true filter coefficients, in respect to iterations.  parameters v array like true coefficients used to generate desired signal, must be a one dimensional array. w array like estimated coefficients from adaptive filtering algorithm. must be an n x m matrix where n is the number of iterations, and m is the number of filter coefficients.  returns mswe numpy.array one dimensional array containing the mean squared weight error for every iteration.  raises typeerror if inputs have wrong dimensions  note to use this function with the adaptive filter functions set the optional parameter returncoeffs to true. this will return a coefficient matrix w corresponding with the input parameter w.   examples  the following examples illustrate the use of the adaptfilt module. note that the matplotlib.pyplot module is required to run them.   acoustic echo cancellation     acoustic echo cancellation in white background noise with nlms.  consider a scenario where two individuals, john and emily, are talking over the internet. john is using his loudspeakers, which means emily can hear herself through john's microphone. the speech signal that emily hears, is a distorted version of her own. this is caused by the acoustic path from john's loudspeakers to his microphone. this path includes attenuated echoes, etc.  now for the problem   emily wishes to cancel the echo she hears from john's microphone. emily only knows the speech signal she sends to him, call that u n , and the speech signal she receives from him, call that d n . to successfully remove her own echo from d n , she must approximate the acoustic path from john's loudspeakers to his microphone. this path can be approximated by a fir filter, which means an adaptive nlms fir filter can be used to identify it. the model which emily uses to design this filter looks like this   u n    adaptive filter john's room   y n  d n  e n v n   as seen, the signal that is sent to john is also used as input to the adaptive nlms filter. the output of the filter, y n , is subtracted from the signal received from john, which results in an error signal e n d n y n . by feeding the error signal back to the adaptive filter, it can minimize the error by approximating the impulse response that is the fir filter coefficients of john's room. note that so far john's speech signal v n has not been taken into account. if john speaks, the error should equal his speech, that is, e n  should equal v n . for this simple example, however, we assume john is quiet and v n is equal to white gaussian background noise with zero mean.  in the following example we keep the impulse response of john's room constant. this is not required, however, since the advantage of adaptive filters, is that they can be used to track changes in the impulse response.   import numpy as np import matplotlib.pyplot as plt import adaptfilt as adf  get u n this is available on github or pypi in the examples folder u np.load 'speech.npy'   generate received signal d n using randomly chosen coefficients coeffs np.concatenate 0.8 , np.zeros 8 , 0.7 , np.zeros 9 , 0.5 , np.zeros 11 , 0.3 , np.zeros 3 , 0.1 , np.zeros 20 , 0.05   d np.convolve u, coeffs   add background noise v np.random.randn len d np.sqrt 5000  d v  apply adaptive filter m 100 number of filter taps in adaptive filter step 0.1 step size y, e, w adf.nlms u, d, m, step, returncoeffs true   calculate mean square weight error mswe adf.mswe w, coeffs   plot speech signals plt.figure  plt.title speech signals  plt.plot u, label emily's speech signal, u n  plt.plot d, label speech signal from john, d n  plt.grid  plt.legend  plt.xlabel 'samples'   plot error signal note how the measurement noise affects the error plt.figure  plt.title 'error signal e n '  plt.plot e  plt.grid  plt.xlabel 'samples'   plot mean squared weight error note that the measurement noise causes the error the increase at some points when emily isn't speaking plt.figure  plt.title 'mean squared weight error'  plt.plot mswe  plt.grid  plt.xlabel 'samples'   plot final coefficients versus real coefficients plt.figure  plt.title 'real coefficients vs. estimated coefficients'  plt.plot w 1 , 'g', label 'estimated coefficients'  plt.plot coeffs, 'b ', label 'real coefficients'  plt.grid  plt.legend  plt.xlabel 'samples'   plt.show   .. image https wramberg adaptfilt master examples echocancel input.png .. image https wramberg adaptfilt master examples echocancel error.png .. image https wramberg adaptfilt master examples echocancel mswe.png .. image https wramberg adaptfilt master examples echocancel coeffs.png   convergence comparison     convergence comparison of different adaptive filtering algorithms with different step sizes in white gaussian noise.   import numpy as np import matplotlib.pyplot as plt import adaptfilt as adf  generating input and desired signal n 3000 coeffs np.concatenate 4, 3.2 , np.zeros 20 , 0.7 , np.zeros 33 , 0.1  u np.random.randn n  d np.convolve u, coeffs   perform filtering m 60 no. of taps to estimate mu1 0.0008 step size 1 in lms mu2 0.0004 step size 1 in lms beta1 0.08 step size 2 in nlms and ap beta2 0.04 step size 2 in nlms and ap k 3 projection order 1 in ap  lms y lms1, e lms1, w lms1 adf.lms u, d, m, mu1, returncoeffs true  y lms2, e lms2, w lms2 adf.lms u, d, m, mu2, returncoeffs true  mswe lms1 adf.mswe w lms1, coeffs  mswe lms2 adf.mswe w lms2, coeffs   nlms y nlms1, e nlms1, w nlms1 adf.nlms u, d, m, beta1, returncoeffs true  y nlms2, e nlms2, w nlms2 adf.nlms u, d, m, beta2, returncoeffs true  mswe nlms1 adf.mswe w nlms1, coeffs  mswe nlms2 adf.mswe w nlms2, coeffs   ap y ap1, e ap1, w ap1 adf.ap u, d, m, beta1, k, returncoeffs true  y ap2, e ap2, w ap2 adf.ap u, d, m, beta2, k, returncoeffs true  mswe ap1 adf.mswe w ap1, coeffs  mswe ap2 adf.mswe w ap2, coeffs   plot results plt.figure  plt.title 'convergence comparison of different adaptive filtering algorithms'  plt.plot mswe lms1, 'b', label 'lms with stepsize .4f' mu1  plt.plot mswe lms2, 'b ', label 'lms with stepsize .4f' mu2  plt.plot mswe nlms1, 'g', label 'nlms with stepsize .2f' beta1  plt.plot mswe nlms2, 'g ', label 'nlms with stepsize .2f' beta2  plt.plot mswe ap1, 'r', label 'ap with stepsize .2f' beta1  plt.plot mswe ap2, 'r ', label 'ap with stepsize .2f' beta2  plt.legend  plt.grid  plt.xlabel 'iterations'  plt.ylabel 'mean squared weight error'  plt.show   .. image https wramberg adaptfilt master examples convergence result.png  release history  0.2  included nlms filtering function with recursive updates of input energy. included acoustic echo cancellation example  0.1  initial module with lms, nlms and ap filtering functions.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "filter        0.357909\n",
      "coefficients  0.259776\n",
      "adaptive      0.247968\n",
      "returncoeffs  0.235131\n",
      "adaptfilt     0.222068\n",
      "mswe          0.222068\n",
      "array         0.205542\n",
      "iterations    0.159656\n",
      "filtering     0.155035\n",
      "number        0.149412\n",
      "lms           0.147946\n",
      "nlms          0.143691\n",
      "taps          0.143691\n",
      "coeffs        0.143691\n",
      "length        0.128464\n",
      "leak          0.123288\n",
      "step          0.122232\n",
      "must          0.121627\n",
      "desired       0.120978\n",
      "leakage       0.117566\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adb3\n",
      "Description:  this repository contains a pure python implementation of the android adb and fastboot protocols, using libusb1 for usb communications. this is a complete replacement and rearchitecture of the android project's adb and fastboot code available at https github.com android platform system core tree master adb this code is mainly targeted to users that need to communicate with android devices in an automated fashion, such as in automated testing. it does not have a daemon between the client and the device, and therefore does not support multiple simultaneous commands to the same device. it does support any number of devices and never communicates with a device that it wasn't intended to, unlike the android project's adb.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                  TF-IDF\n",
      "android         0.564421\n",
      "adb             0.435874\n",
      "fastboot        0.290583\n",
      "devices         0.206841\n",
      "automated       0.204399\n",
      "libusb1         0.145291\n",
      "simultaneous    0.145291\n",
      "rearchitecture  0.145291\n",
      "targeted        0.137127\n",
      "usb             0.131334\n",
      "communicates    0.131334\n",
      "unlike          0.126841\n",
      "communicate     0.120066\n",
      "mainly          0.110965\n",
      "support         0.106980\n",
      "therefore       0.104720\n",
      "replacement     0.099960\n",
      "daemon          0.098927\n",
      "never           0.096113\n",
      "intended        0.095256\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  addok\n",
      "Description:  addok search engine for address. only address. addok will index your address data and provide an http api for full text search. it is extensible with plugins http addok.readthedocs.io en latest plugins , for example for geocoding csv files. used in production by france administration, with around 26 millions addresses. in those servers, full france data is imported in about 15 min and it scales to around 2000 searches per second. check the documentation http addok.readthedocs.org en latest and a demo http adresse.data.gouv.fr map with french data. powered by python and redis. build status https travis ci.org addok addok.svg branch master https travis ci.org addok addok requirements status https requires.io github addok addok requirements.svg branch master https requires.io github addok addok requirements branch master pypi version https img.shields.io pypi v addok.svg https pypi.python.org pypi addok coverage status https coveralls.io repos addok addok badge.svg branch master service github https coveralls.io github addok addok branch master\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "addok         0.913926\n",
      "france        0.130561\n",
      "branch        0.114229\n",
      "https         0.112806\n",
      "master        0.103343\n",
      "github        0.094401\n",
      "plugins       0.084017\n",
      "around        0.081885\n",
      "status        0.069587\n",
      "full          0.067613\n",
      "http          0.067006\n",
      "geocoding     0.065280\n",
      "millions      0.065280\n",
      "requirements  0.060489\n",
      "pypi          0.059473\n",
      "2000          0.057158\n",
      "scales        0.055878\n",
      "searches      0.055878\n",
      "french        0.053739\n",
      "powered       0.052826\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  addok-csv\n",
      "Description:  addok plugin add csv geocoding endpoints install pip install addok csv api warning this plugin will not work when running addok serve , you need either gunicorn or uwsgi see falcon multipart issue https github.com yohanboniface falcon multipart issues 1 . this plugin adds the following endpoints search csv batch geocode a csv file. parameters data the csv file to be processed columns multiple the columns, ordered, to be used for geocoding if no column is given, all columns will be used encoding optional encoding of the file you can also specify a charset in the file mimetype , such as 'utf 8' or 'iso 8859 1' default to 'utf 8 sig' delimiter optional csv delimiter , or if not given, we try to guess with bom if true, and if the encoding if utf 8, the returned csv will contain a bom for excel users lat and lon parameters optionals , like filters, can be used to define columns names that contain latitude and longitude values, for adding a preference center in the geocoding of each row examples http f post http localhost 7878 search csv columns 'voie' columns 'ville' data path to file.csv http f post http localhost 7878 search csv columns 'rue' postcode 'code postal' data path to file.csv reverse csv batch reverse geocode a csv file. parameters data the csv file to be processed must contain columns latitude or lat and longitude or lon or lng encoding optional encoding of the file you can also specify a charset in the file mimetype , such as 'utf 8' or 'iso 8859 1' default to 'utf 8 sig' delimiter optional csv delimiter , or if not given, we try to guess any filter can be passed as key value querystring, where key is the filter name and value is the column name containing the filter value for each row. for example, if there is a column code insee and we want to use it for citycode filtering, we would pass citycode code insee as query string parameter. config csv encoding default encoding to open csv files default 'utf 8 sig'\n",
      "Highest ranked keywords:\n",
      "\n",
      "             TF-IDF\n",
      "csv        0.584151\n",
      "columns    0.272604\n",
      "encoding   0.270324\n",
      "delimiter  0.203175\n",
      "addok      0.169648\n",
      "geocoding  0.169648\n",
      "geocode    0.119833\n",
      "citycode   0.119833\n",
      "falcon     0.119833\n",
      "insee      0.119833\n",
      "7878       0.119833\n",
      "column     0.117847\n",
      "bom        0.113099\n",
      "8859       0.113099\n",
      "file       0.109361\n",
      "lat        0.108321\n",
      "mimetype   0.108321\n",
      "multipart  0.108321\n",
      "charset    0.108321\n",
      "lon        0.108321\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  addr-detector\n",
      "Description:  address detector how to detect if a user query might be an address and requires to launch a map answer. project modules the project implements 3 classifiers, using an a la scikit template. the first classifier is a simple scorer classifier, based on the parsing result of the address parser libpostal https github.com openvenues libpostal according to how the parser manage to work, and which fields are parsed, we make a score and decide if an address or not. the second classifier is based on the fasttext classifier trained on address data. the fasttext makes an embedding of the differents address it sees and therefore when a new address is submitted if it's in a close spaceto what have been learned. the classifier is pre trained, and the fasttext zip model is store within the package. the third classifier is a voting classifier combining the results of the two previous classifiers. project dependencies installation of postal before you install postal , make sure you have the following prerequisites sudo apt get install curl autoconf automake libtool pkg config then to install the c library git clone https github.com openvenues libpostal cd libpostal . bootstrap.sh . configure datadir ...some dir with a few gb of space... make sudo make install on linux it's probably a good idea to run sudo ldconfig installation of fasttext in order to build fasttext , use the following git clone https github.com facebookresearch fasttext.git cd fasttext make history 0.1.0 2017 10 25 first release on pypi.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                    TF-IDF\n",
      "fasttext          0.491697\n",
      "classifier        0.429258\n",
      "libpostal         0.327798\n",
      "address           0.317743\n",
      "postal            0.163899\n",
      "openvenues        0.163899\n",
      "make              0.141046\n",
      "sudo              0.121464\n",
      "parser            0.106528\n",
      "autoconf          0.081950\n",
      "facebookresearch  0.081950\n",
      "voting            0.081950\n",
      "scorer            0.081950\n",
      "spaceto           0.081950\n",
      "project           0.080003\n",
      "ldconfig          0.077345\n",
      "automake          0.077345\n",
      "libtool           0.077345\n",
      "trained           0.077345\n",
      "differents        0.077345\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  addressify\n",
      "Description:  addressify python client .. image https travis ci.org snowball one addressify.svg target https travis ci.org snowball one addressify this is a simply python client for the addressify.com.au api. addressify is a cloud based web api that allows web site, web application and desktop application developers to easily implement free address verification, validation, checking, parsing and autocomplete for australia in their applications. .. addressify.com.au http www.addressify.com.au installation since the python addressify client has not yet been released to pypi, you will need to install it from git. this can still be done using pip pip install git https github.com snowball one addressify.git usage quickstart the addressify python client currently covers all the available api calls of addressify.com.au . e.g. .. code block python from addressify import client client client your api key results client.auto complete '109 175 sturt street, south' api calls available client.auto complete gets a list of addresses that begin with the given term. arguments term required the start of an address. state optional the state to search for addresses in. 'nsw', 'act', 'vic', 'qld', 'sa', 'wa', 'nt', 'tas' postcode optional the postcode to search for addresses in. max results optional the maximum number of results to return minumum 1, maximum 20, default 10 . example response 1 george st, tahmoor nsw 2573 , 1 george st, telarah nsw 2320 , 1 george st, temora nsw 2666 , 1 george st, tenterfield nsw 2372 , 1 george st, the rocks nsw 2000 client.address line auto complete gets a list of address lines that begin with the given term. arguments term required the start of an address line. state optional the state to search for addresses in. 'nsw', 'act', 'vic', 'qld', 'sa', 'wa', 'nt', 'tas' postcode optional the postcode to search for addresses in. max results optional the maximum number of results to return minumum 1, maximum 20, default 10 . example response 1 geordie st , 1 georgann st , 1 george ave , 1 george cl , 1 george cres client.suburb auto complete gets a list of suburbs that begin with the given term. arguments term required the start of a suburb name state optional the state to search for addresses in. 'nsw', 'act', 'vic', 'qld', 'sa', 'wa', 'nt', 'tas' postcode optional the postcode to search for addresses in. max results optional the maximum number of results to return minumum 1, maximum 20, default 10 . example response suffolk park , sugarloaf , summer hill , summer hill creek , summer island client.suburb state postcode auto complete gets a list of suburbs and postcodes where the suburb begins with the given term. arguments term required the start of a suburb name. state optional the state to search for addresses in. 'nsw', 'act', 'vic', 'qld', 'sa', 'wa', 'nt', 'tas' postcode optional the postcode to search for addresses in. max results optional the maximum number of results to return minumum 1, maximum 20, default 10 . example response summer hill, nsw 2130 , summer hill, nsw 2421 , summer hill creek, nsw 2800 , summer island, nsw 2440 , summerhill, tas 7250 client.suburbs for postcode gets a list of suburbs for the given postcode. arguments postcode required the postcode. example response barangaroo, nsw 2000 , dawes point, nsw 2000 , haymarket, nsw 2000 , millers point, nsw 2000 , sydney, nsw 2000 , sydney south, nsw 2000 , the rocks, nsw 2000 client.state for postcode gets the state in which the given postcode is located. arguments postcode required the postcode. example response nsw client.parse address parses the given address into it's individual address fields. arguments address line required the address to parse. example response number 680 , street george , street type st , suburb sydney , street suffix none, state nsw , street line 680 george st , unit type none unit number none, postcode 2000 client.get similar gets a list of valid addresses that are similar to the given term, can be used to match invalid addresses to valid addresses. arguments address line required the address to find similar addresses for max results optional the maximum number of results to return minumum 1, maximum 10, default 10 . example response 1 george st, sydney nsw 2000 client.validate checks whether the given address is valid. please note that validation is only performed on the street, suburb, state and postcode. street and unit numbers are not checked for validity. arguments address line required the address to validate. example response true client.daily call count gets the current daily api call count for your account. this counter will reset at midnight aest. when this counter reaches the daily api call limit for your account type all other addressify api calls will fail until the counter resets. will return 1 if the api key does not exist. example response 1000\n",
      "Highest ranked keywords:\n",
      "\n",
      "              TF-IDF\n",
      "nsw         0.485035\n",
      "postcode    0.361405\n",
      "george      0.265030\n",
      "2000        0.210960\n",
      "addresses   0.208582\n",
      "state       0.184824\n",
      "address     0.183821\n",
      "addressify  0.178697\n",
      "maximum     0.168874\n",
      "summer      0.168656\n",
      "response    0.153023\n",
      "optional    0.145915\n",
      "results     0.141894\n",
      "gets        0.133894\n",
      "street      0.120468\n",
      "minumum     0.120468\n",
      "arguments   0.111900\n",
      "given       0.110742\n",
      "search      0.104005\n",
      "suburb      0.102113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  ade\n",
      "Description:  performs the differential evolution de algorithm asynchronously. with a multiprocess evaluation function running on a multicore cpu or cluster, ade can get the de processing done several times faster than standard single threaded de. it does this without departing in any way from the numeric operations performed by the classic storn and price algorithm with either a randomly chosen candidate or the best available candidate. you get a substantial multiprocessing speed up and the well understood, time tested behavior of the classic de rand 1 bin or de best 1 bin algorithm. you can pick which one to use. the underlying numeric recipe is not altered at all, but everything runs a lot faster. the ade package also does simple and smart population initialization, informative progress reporting, adaptation of the vector differential scaling factor f based on how much each generation is improving, and automatic termination after a reasonable level of convergence to the best solution. for a tutorial and usage examples, see the project page at edsuom.com . .. project page http edsuom.com ade.html\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "de            0.340968\n",
      "ade           0.260034\n",
      "best          0.243663\n",
      "differential  0.235055\n",
      "numeric       0.227013\n",
      "classic       0.210075\n",
      "algorithm     0.166239\n",
      "storn         0.130017\n",
      "multicore     0.130017\n",
      "departing     0.130017\n",
      "termination   0.122711\n",
      "rand          0.122711\n",
      "informative   0.122711\n",
      "adaptation    0.122711\n",
      "threaded      0.122711\n",
      "page          0.122059\n",
      "bin           0.118695\n",
      "convergence   0.117527\n",
      "multiprocess  0.117527\n",
      "population    0.117527\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adipy\n",
      "Description:  adipy, automatic differentiation for python adipy is a fast, pure python automatic differentiation ad library. this package provides the following functionality arbitrary order univariate differentiation first order multivariate differentiation univariate taylor polynomial function generator jacobian matrix generator compatible linear algebra routines installation to install adipy , simply do one of the following in a terminal window administrative priviledges may be required download the tarball, unzip, then run python setup.py install in the unzipped directory. run easy install upgrade adipy run pip install upgrade adipy where to start to start, we use the simple import from adipy import this imports the necessary constructors and elementary functions sin, exp, sqrt, etc. as well as np which is the root numpy module. now, we can construct ad objects using either ad ... or adn ... . for multivariate operations, it is recommended to construct them all at once using the ad ... function, but this is not required. the syntax is only a little more complicated if they are initialized separately. univariate examples here are some examples of univariate operations a single, first order differentiable object x ad 1.5 y x 2 print y output is ad 2.25, array 3.0 what is dy dx print y.d 1 output is 3.0 z x sin x 2 print z output is ad 1.1671097953318819, array 2.0487081053644052 what is dz dx print z.d 1 output is 2.0487081053644052 a single, fourth order differentiable object x adn 1.5, 4 y x 2 print y output is ad 2.25, array 3., 2., 0., 0. what is the second derivative of y with respect to x print y.d 2 output is 2.0 z x sin x 2 print z output is ad 1.1671097953318819, array 2.04870811, 16.15755076, 20.34396265, 194.11618384 what is the fourth derivative of z with respect to x print z.d 4 output is 194.116183837 as can be seen in the examples, when an ad object is printed out, you see two sets of numbers. the first is the nominal value, or the zero th derivative. the next set of values are the 1st through the nth order derivatives, evaluated at the nominal value. multivariate examples for multivariate sessions, things look a little bit different and can only handle first derivatives for the time being , but behave similarly x ad np.array 1, 2.1, 0.25 y x 2 print y output is ad array 1. , 4.41 , 0.0625 , array 2. , 0. , 0. , 0. , 4.2, 0. , 0. , 0. , 0.5 this essentially just performed the 2 operator on each object individually, so we can see the derivatives for each array index and how they are not dependent on each other. using standard indexing operations, we can access the individual elements of an ad multivariate object print x 0 output is ad 1, array 1., 0., 0. what if we want to use more than one ad object in calculations let's see what happens z x 0 sin x 1 x 2 print z output is ad 0.50121300467379792, array 0.501213 , 0.21633099, 1.81718028 the result here shows both the nominal value for z, but also the partial derivatives for each of the x values. thus, dz dx 0 0.501213, etc. jacobian if we have multiple outputs, like y 0 2 y 0 x 0 x 1 x 2 y 1 x 2 x 0 we can use the jacobian function to summarize the partial derivatives for each index of y print jacobian y output is 8.4 4. 33.6 5.54517744 0. 16. just as before, we can extract the first partial derivatives print z.d 1 output is 0.501213 0.21633099 1.81718028 for the object y, we can't yet use the d ... function yet, because it is technically a list at this point. however, we can convert it to a single, multivariate ad object using the unite function, then we'll have access to the d ... function. the jacobian function's result is the same in both cases y unite y print y.d 1 output is 8.4 4. 33.6 5.54517744 0. 16. print jacobian y output is 8.4 4. 33.6 5.54517744 0. 16. like was mentioned before, multivariate sessions can initialize individual independent ad objects, though not quite as conveniently as before, using the following syntax x ad 1, np.array 1, 0, 0 y ad 2.1, np.array 0, 1, 0 z ad 0.25, np.array 0, 0, 1 this allows all the partial derivatives to be tracked, noted at the respective unitary index at initialization. conversely to singular construction, we can break out the individual elements, if desired x, y, z ad np.array 1, 2.1, 0.25 and the results are the same. univariate taylor series approximation for univariate functions, we can use the taylorfunc function to generate an callable function that allows approximation to some specifiable order x adn 1.5, 6 a sixth order ad object z x sin x 2 fz taylorfunc z, at x.nom the at keyword designates the point that the series is expanded about, which will likely always be at the nominal value of the original independent ad object e.g., x.nom . now, we can use fz whenever we need to approximate x sin x 2 , but know that the farther it is evaluated from x.nom , the more error there will be in the approximation. if matplotlib is installed, we can see the difference in the order of the approximating taylor polynomials import matplotlib.pyplot as plt xad adn 1.5, i for i in xrange 1, 7 a list of ith order ad objects def z x return x sin x 2 x np.linspace 0.75, 2.25 plt.plot x, z x , label 'actual function' for i in xrange len xad fz taylorfunc z xad i , at xad i .nom plt.plot x, fz x , label 'order d taylor' i 1 plt.legend loc 0 plt.show .. image https raw.github.com tisimst adipy master taylorfunc example.png notice that at x 1.5, all the approximations are perfectly accurate as we would expect and error increases as the approximation moves farther from that point, but less so with the increase in the order of the approximation. linear algebra several linear algebra routines are available that are ad compatible decompositions cholesky chol qr qr lu lu linear system solvers general solver, with support for multiple outputs solve least squares solver lstsq matrix inverse inv matrix norms frobenius norm, or 2 norm norm these require a separate import import adipy.linalg , then they can be using something like adipy.linalg.solve ... . see the source code for relevant documentation and examples. if you are familiar with numpy's versions, you will find these easy to use. support please contact the author with any questions, comments, or good examples of how you've used adipy license this package is distributed under the bsd license. it is free for public and commercial use and may be copied royalty free, provided the author is given credit. .. author mailto tisimst gmail.com\n",
      "Highest ranked keywords:\n",
      "\n",
      "                   TF-IDF\n",
      "ad               0.579931\n",
      "adipy            0.210826\n",
      "multivariate     0.210826\n",
      "output           0.204987\n",
      "print            0.190894\n",
      "jacobian         0.180708\n",
      "univariate       0.180708\n",
      "array            0.177714\n",
      "sin              0.170553\n",
      "derivatives      0.157760\n",
      "object           0.135855\n",
      "order            0.131697\n",
      "taylorfunc       0.120472\n",
      "adn              0.120472\n",
      "fz               0.120472\n",
      "nominal          0.120472\n",
      "differentiation  0.120472\n",
      "xad              0.108899\n",
      "linear           0.095360\n",
      "approximation    0.090354\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  admin-tools-zinnia\n",
      "Description:  admin tools zinnia admin tools zinnia is package providing new dashboard modules related to your zinnia application for django admin tools . .. zinnia http django blog zinnia.com .. django admin tools http pypi.python.org pypi django admin tools\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "zinnia       0.635233\n",
      "admin        0.503626\n",
      "django       0.369327\n",
      "tools        0.369187\n",
      "dashboard    0.121288\n",
      "blog         0.107057\n",
      "related      0.094004\n",
      "providing    0.090777\n",
      "modules      0.085866\n",
      "application  0.077897\n",
      "http         0.076923\n",
      "new          0.055456\n",
      "package      0.048825\n",
      "pypi         0.045517\n",
      "operator     0.000000\n",
      "operations   0.000000\n",
      "operational  0.000000\n",
      "00           0.000000\n",
      "operating    0.000000\n",
      "operation    0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adminbot\n",
      "Description:  adminbot adminbot is a python package to set up a telegram bot to admin a server. more information in the github repository https github.com dih5 adminbot .\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "adminbot     0.845620\n",
      "dih5         0.281873\n",
      "telegram     0.254796\n",
      "bot          0.211879\n",
      "admin        0.178780\n",
      "repository   0.131887\n",
      "information  0.116755\n",
      "github       0.096177\n",
      "set          0.094853\n",
      "package      0.086660\n",
      "python       0.060114\n",
      "https        0.057464\n",
      "operator     0.000000\n",
      "operations   0.000000\n",
      "operational  0.000000\n",
      "operation    0.000000\n",
      "00           0.000000\n",
      "operating    0.000000\n",
      "operators    0.000000\n",
      "operated     0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adminkit\n",
      "Description:  adminkit is a tool to manage the configuration of systems via a high level description using roles. the tool belongs to the same familly as cfengine, puppet or chef.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "familly        0.404148\n",
      "adminkit       0.404148\n",
      "tool           0.362490\n",
      "puppet         0.352826\n",
      "belongs        0.333981\n",
      "systems        0.237774\n",
      "high           0.236356\n",
      "manage         0.214587\n",
      "level          0.207466\n",
      "description    0.186166\n",
      "configuration  0.169062\n",
      "via            0.168226\n",
      "using          0.113445\n",
      "operations     0.000000\n",
      "operational    0.000000\n",
      "operation      0.000000\n",
      "operating      0.000000\n",
      "optimisation   0.000000\n",
      "operates       0.000000\n",
      "operated       0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adp-userinfo\n",
      "Description:  adp client library to get the logged in user's info\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "adp          0.673630\n",
      "logged       0.473839\n",
      "info         0.341712\n",
      "client       0.313203\n",
      "library      0.242775\n",
      "get          0.218852\n",
      "operates     0.000000\n",
      "operating    0.000000\n",
      "operated     0.000000\n",
      "operation    0.000000\n",
      "opklaringen  0.000000\n",
      "operational  0.000000\n",
      "operations   0.000000\n",
      "operator     0.000000\n",
      "operators    0.000000\n",
      "operate      0.000000\n",
      "opinionated  0.000000\n",
      "opinions     0.000000\n",
      "operand      0.000000\n",
      "00           0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  adversarials\n",
      "Description:  simple gan this is my attempt to make a wrapper class for a gan in keras which can be used to abstract the whole architecture process. build status https travis ci.org deven96 simple gan.svg branch master https travis ci.com deven96 simple gan simple gan simple gan overview overview flow chart flow chart installation installation example example credits credits contribution contribution license mit license mit overview alt text assets mnist gan.png gan network using the mnist dataset flow chart setting up a generative adversarial network involves having a discriminator and a generator working in tandem, with the ultimate goal being that the generator can come up with samples that are indistinguishable from valid samples by the discriminator. alt text assets flow.jpg high level flowchart installation bash pip install adversarials example python import numpy as np from keras.datasets import mnist from adversarials.core import log from adversarials import simplegan if name ' main ' x train, , , mnist.load data rescale 1 to 1 x train x train.astype np.float32 127.5 127.5 x train np.expand dims x train, axis 3 log.info 'x train.shape '.format x train.shape gan simplegan save to dir . assets images , save interval 20 gan.train x train, epochs 40 credits understanding generative adversarial networks https towardsdatascience.com understanding generative adversarial networks 4dafc963f2ef noaki shibuya github keras gan https github.com osh kerasgan simple gan https github.com daymos simple keras gan blob master gan.py contribution you are very welcome to modify and use them in your own projects. please keep a link to the original repository https github.com deven96 simple gan . if you have made a fork with substantial modifications that you feel may be useful, then please open a new issue on github https github.com deven96 simple gan issues with a link and short description. license mit this project is opened under the mit 2.0 license https github.com deven96 simple gan blob master license which allows very broad use for both academic and commercial purposes. a few of the images used for demonstration purposes may be under copyright. these images are included under the fair usage laws.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "gan            0.699855\n",
      "deven96        0.269175\n",
      "simple         0.199379\n",
      "generative     0.161505\n",
      "adversarial    0.161505\n",
      "mnist          0.152429\n",
      "keras          0.145990\n",
      "chart          0.136915\n",
      "flow           0.119609\n",
      "assets         0.116406\n",
      "contribution   0.116406\n",
      "adversarials   0.107670\n",
      "simplegan      0.107670\n",
      "mit            0.104513\n",
      "understanding  0.097327\n",
      "images         0.089014\n",
      "https          0.087800\n",
      "overview       0.087735\n",
      "license        0.084963\n",
      "train          0.083654\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aeneas\n",
      "Description:  aeneas aeneas is a python c library and a set of tools to automagically synchronize audio and text aka forced alignment . version 1.7.3 date 2017 03 15 developed by readbeyond http www.readbeyond.it lead developer alberto pettarin http www.albertopettarin.it license the gnu affero general public license version 3 agpl v3 contact aeneas readbeyond.it quick links home http www.readbeyond.it aeneas github https github.com readbeyond aeneas pypi https pypi.python.org pypi aeneas docs http www.readbeyond.it aeneas docs tutorial http www.readbeyond.it aeneas docs clitutorial.html benchmark https readbeyond.github.io aeneas benchmark mailing list https groups.google.com d forum aeneas forced alignment web app http aeneasweb.org goal aeneas automatically generates a synchronization map between a list of text fragments and an audio file containing the narration of the text. in computer science this task is known as automatically computing a forced alignment . for example, given this text file https readbeyond aeneas master aeneas tests res container job assets p001.xhtml and this audio file https readbeyond aeneas master aeneas tests res container job assets p001.mp3 , aeneas determines, for each fragment, the corresponding time interval in the audio file 1 00 00 00.000, 00 00 02.640 from fairest creatures we desire increase, 00 00 02.640, 00 00 05.880 that thereby beauty's rose might never die, 00 00 05.880, 00 00 09.240 but as the riper should by time decease, 00 00 09.240, 00 00 11.920 his tender heir might bear his memory 00 00 11.920, 00 00 15.280 but thou contracted to thine own bright eyes, 00 00 15.280, 00 00 18.800 feed'st thy light's flame with self substantial fuel, 00 00 18.800, 00 00 22.760 making a famine where abundance lies, 00 00 22.760, 00 00 25.680 thy self thy foe, to thy sweet self too cruel 00 00 25.680, 00 00 31.240 thou that art now the world's fresh ornament, 00 00 31.240, 00 00 34.400 and only herald to the gaudy spring, 00 00 34.400, 00 00 36.920 within thine own bud buriest thy content, 00 00 36.920, 00 00 40.640 and tender churl mak'st waste in niggarding 00 00 40.640, 00 00 43.640 pity the world, or else this glutton be, 00 00 43.640, 00 00 48.080 to eat the world's due, by the grave and thee. 00 00 48.080, 00 00 53.240 .. figure wiki align.png alt waveform with aligned labels, detail waveform with aligned labels, detail this synchronization map can be output to file in several formats, depending on its application research audacity aud , elan eaf , textgrid digital publishing smil for epub 3 closed captioning subrip srt , subviewer sbv sub , ttml, webvtt vtt web json further processing csv, ssv, tsv, txt, xml. system requirements, supported platforms and installation system requirements 1. a reasonably recent machine recommended 4 gb ram, 2 ghz 64bit cpu 2. python https python.org 2.7 linux, os x, windows or 3.5 or later linux, os x 3. ffmpeg https www.ffmpeg.org 4. espeak http espeak.sourceforge.net 5. python packages beautifulsoup4 , lxml , and numpy 6. python headers to compile the python c c extensions optional but strongly recommended 7. a shell supporting utf 8 optional but strongly recommended supported platforms aeneas has been developed and tested on debian 64bit , with python 2.7 and python 3.5 , which are the only supported platforms at the moment. nevertheless, aeneas has been confirmed to work on other linux distributions, mac os x, and windows. see the platforms file https github.com readbeyond aeneas blob master wiki platforms.md for details. if installing aeneas natively on your os proves difficult, you are strongly encouraged to use aeneas vagrant https github.com readbeyond aeneas vagrant , which provides aeneas inside a virtualized debian image running under virtualbox https www.virtualbox.org and vagrant http www.vagrantup.com , which can be installed on any modern os linux, mac os x, windows . installation all in one installers are available for mac os x and windows, and a bash script for deb based linux distributions debian, ubuntu is provided in this repository. it is also possible to download a virtualbox vagrant virtual machine. please see the install file https github.com readbeyond aeneas blob master wiki install.md for detailed, step by step installation procedures for different operating systems. the generic os independent procedure is simple 1. install python https python.org 2.7.x preferred , ffmpeg https www.ffmpeg.org , and espeak http espeak.sourceforge.net 2. make sure the following executables can be called from your shell espeak , ffmpeg , ffprobe , pip , and python 3. first install numpy with pip and then aeneas this order is important .. code bash pip install numpy pip install aeneas 4. to check whether you installed aeneas correctly, run bash python m aeneas.diagnostics usage 1. run without arguments to get the usage message .. code bash python m aeneas.tools.execute task python m aeneas.tools.execute job you can also get a list of live examples that you can immediately run on your machine thanks to the included files .. code bash python m aeneas.tools.execute task examples python m aeneas.tools.execute task examples all 2. to compute a synchronization map map.json for a pair audio.mp3 , text.txt in plain http www.readbeyond.it aeneas docs textfile.html text format , you can run .. code bash python m aeneas.tools.execute task audio.mp3 text.txt task language eng os task file format json is text type plain map.json the command has been split into lines with for visual clarity in production you can have the entire command on a single line and or you can use shell variables. to compute a synchronization map map.smil for a pair audio.mp3 , page.xhtml http www.readbeyond.it aeneas docs textfile.html containing fragments marked by id attributes like f001 , you can run bash python m aeneas.tools.execute task audio.mp3 page.xhtml task language eng os task file format smil os task file smil audio ref audio.mp3 os task file smil page ref page.xhtml is text type unparsed is text unparsed id regex f 0 9 is text unparsed id sort numeric map.smil as you can see, the third argument the configuration string specifies the parameters controlling the i o formats and the processing options for the task. consult the documentation http www.readbeyond.it aeneas docs for details. 3. if you have several tasks to process, you can create a job container to batch process them .. code bash python m aeneas.tools.execute job job.zip output directory file job.zip should contain a config.txt or config.xml configuration file, providing aeneas with all the information needed to parse the input assets and format the output sync map files. consult the documentation http www.readbeyond.it aeneas docs for details. the documentation http www.readbeyond.it aeneas docs contains a highly suggested tutorial http www.readbeyond.it aeneas docs clitutorial.html which explains how to use the built in command line tools. documentation and support documentation http www.readbeyond.it aeneas docs command line tools tutorial http www.readbeyond.it aeneas docs clitutorial.html library tutorial http www.readbeyond.it aeneas docs libtutorial.html old, verbose tutorial a practical introduction to the aeneas package http www.albertopettarin.it blog 2015 05 21 a practical introduction to the aeneas package.html mailing list https groups.google.com d forum aeneas forced alignment changelog http www.readbeyond.it aeneas docs changelog.html high level description of how aeneas works howitworks https github.com readbeyond aeneas blob master wiki howitworks.md development history history https github.com readbeyond aeneas blob master wiki history.md testing testing https github.com readbeyond aeneas blob master wiki testing.md benchmark suite https readbeyond.github.io aeneas benchmark supported features input text files in parsed , plain , subtitles , or unparsed xml format multilevel input text files in mplain and munparsed xml format text extraction from xml e.g., xhtml files using id and class attributes arbitrary text fragment granularity single word, subphrase, phrase, paragraph, etc. input audio file formats all those readable by ffmpeg output sync map formats aud, csv, eaf, json, smil, srt, ssv, sub, textgrid, tsv, ttml, txt, vtt, xml confirmed working on 38 languages afr, ara, bul, cat, cym, ces, dan, deu, ell, eng, epo, est, fas, fin, fra, gle, grc, hrv, hun, isl, ita, jpn, lat, lav, lit, nld, nor, ron, rus, pol, por, slk, spa, srp, swa, swe, tur, ukr mfcc and dtw computed via python c extensions to reduce the processing time several built in tts engine wrappers aws polly tts api, espeak default , espeak ng, festival, macos via say , nuance tts api default tts espeak called via a python c extension for fast audio synthesis possibility of running a custom, user provided tts engine python wrapper e.g., included example for speect batch processing of multiple audio text pairs download audio from a youtube video in multilevel mode, recursive alignment from paragraph to sentence to word level in multilevel mode, mfcc resolution, mfcc masking, dtw margin, and tts engine can be specified for each level independently robust against misspelled mispronounced words, local rearrangements of words, background noise sporadic spikes adjustable splitting times, including a max character second constraint for cc applications automated detection of audio head tail output an html file for fine tuning the sync map manually finetuneas project execution parameters tunable at runtime code suitable for web app deployment e.g., on demand cloud computing instances extensive test suite including 1,200 unit integration performance tests, that run and must pass before each release limitations and missing features audio should match the text large portions of spurious text or audio might produce a wrong sync map audio is assumed to be spoken not suitable for song captioning, ymmv for cc applications no protection against memory swapping be sure your amount of ram is adequate for the maximum duration of a single audio file e.g., 4 gb ram max 2h audio 16 gb ram max 10h audio open issues https github.com readbeyond aeneas issues a note on word level alignment a significant number of users runs aeneas to align audio and text at word level i.e., each fragment is a word . although aeneas was not designed with word level alignment in mind and the results might be inferior to asr based forced aligners https github.com pettarin forced alignment tools for languages with good asr models, aeneas offers some options to improve the quality of the alignment at word level multilevel text since v1.5.1 , mfcc nonspeech masking since v1.7.0, disabled by default , use better tts engines, like festival or aws nuance tts api since v1.5.0 . if you use the aeneas.tools.execute task command line tool, you can add presets word switch to enable mfcc nonspeech masking, for example .. code bash python m aeneas.tools.execute task example words presets word python m aeneas.tools.execute task example words multilevel presets word if you use aeneas as a library, just set the appropriate runtimeconfiguration parameters. please see the command line tutorial http www.readbeyond.it aeneas docs clitutorial.html for details. license aeneas is released under the terms of the gnu affero general public license version 3. see the license file https github.com readbeyond aeneas blob master license for details. licenses for third party code and files included in aeneas can be found in the licenses https github.com readbeyond aeneas blob master licenses readme.md directory. no copy rights were harmed in the making of this project. supporting and contributing sponsors july 2015 michele gianella https plus.google.com michelegianella about generously supported the development of the boundary adjustment code v1.0.4 august 2015 michele gianella https plus.google.com michelegianella about partially sponsored the port of the mfcc dtw code to c v1.1.0 september 2015 friends in west africa partially sponsored the development of the head tail detection code v1.2.0 october 2015 an anonymous donation sponsored the development of the youtube downloader option v1.3.0 april 2016 the fruch foundation kindly sponsored the development and documentation of v1.5.0 december 2016 the centro internazionale del libro parlato adriano sernagiotto http www.libroparlato.org feltre, italy partially sponsored the development of the v1.7 series supporting would you like supporting the development of aeneas i accept sponsorships to fix bugs, add new features, improve the quality and the performance of the code, port the code to other languages platforms, and improve the documentation. feel free to get in touch mailto aeneas readbeyond.it . contributing if you think you found a bug or you have a feature request, please use the github issue tracker https github.com readbeyond aeneas issues to submit it. if you want to ask a question about using aeneas , your best option consists in sending an email to the mailing list https groups.google.com d forum aeneas forced alignment . finally, code contributions are welcome please refer to the code contribution guide https github.com readbeyond aeneas blob master wiki contributing.md for details about the branch policies and the code style to follow. acknowledgments many thanks to nicola montecchio , who suggested using mfccs and dtw, and co developed the first experimental code for aligning audio and text. paolo bertasi , who developed the apis and web application for readbeyond sync, helped shaping the structure of this package for its asynchronous usage. chris hubbard prepared the files for packaging aeneas as a debian ubuntu .deb . daniel bair prepared the brew formula for installing aeneas and its dependencies on mac os x. daniel bair , chris hubbard , and richard margetts packaged the installers for mac os x and windows. firat ozdemir contributed the finetuneas html js code for fine tuning sync maps in the browser. willem van der walt contributed the code snippet to output a sync map in textgrid format. chris vaughn contributed the macos tts wrapper. all the mighty github contributors https github.com readbeyond aeneas graphs contributors , and the members of the google group https groups.google.com d forum aeneas forced alignment .\n",
      "Highest ranked keywords:\n",
      "\n",
      "              TF-IDF\n",
      "aeneas      0.725906\n",
      "00          0.454019\n",
      "readbeyond  0.186976\n",
      "audio       0.137689\n",
      "alignment   0.120984\n",
      "task        0.112332\n",
      "tts         0.098987\n",
      "os          0.098439\n",
      "text        0.086934\n",
      "forced      0.071084\n",
      "map         0.068103\n",
      "https       0.067266\n",
      "mfcc        0.065991\n",
      "espeak      0.065991\n",
      "word        0.063282\n",
      "docs        0.063166\n",
      "http        0.058602\n",
      "multilevel  0.054993\n",
      "thy         0.054993\n",
      "file        0.053533\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aerial\n",
      "Description:  aerial a python library for receiving unix style signals. build status coverage status package status .. build status image https api.travis ci.org chrisbrake aerial.svg branch master target https travis ci.org chrisbrake aerial .. coverage status image https coveralls.io repos github chrisbrake aerial badge.svg branch master target https coveralls.io github chrisbrake aerial branch master .. package status image https badge.fury.io py aerial.svg target https badge.fury.io py aerial .. quick start section marker this library is meant to be a simple way to deal with handling signals, while avoiding callbacks. install it with pip .. code block bash pip install aerial a simple use looks like this .. code block python import time import signal import aerial def main loop ... while not aerial.received signal.sigterm ... if aerial.received signal.sighup ... print 'got a sighup' ... time.sleep .5 ... print 'see you later' ... and try out the demo by running the module. .. code block bash python m aerial pid 10852 hello, send me a sigterm to exit, or a sighup for a trick in another terminal pid 10852 neat huh kill sighup 10852 pid 10852 see you later kill sigterm 10852\n",
      "Highest ranked keywords:\n",
      "\n",
      "              TF-IDF\n",
      "aerial      0.650403\n",
      "10852       0.406502\n",
      "chrisbrake  0.325201\n",
      "pid         0.189499\n",
      "status      0.163589\n",
      "sighup      0.162601\n",
      "sigterm     0.146981\n",
      "kill        0.137844\n",
      "https       0.099445\n",
      "block       0.098188\n",
      "huh         0.081300\n",
      "neat        0.081300\n",
      "branch      0.080560\n",
      "py          0.078374\n",
      "avoiding    0.076732\n",
      "import      0.075912\n",
      "target      0.074872\n",
      "coverage    0.073779\n",
      "trick       0.073490\n",
      "master      0.072883\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aeropy\n",
      "Description:  this software is developed as a universal aerospace engineering toolbox. this software is still under development and also includes third party codes. if you want to contribute please contact the author lukas mller.\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "aerospace    0.380619\n",
      "lukas        0.359231\n",
      "universal    0.322668\n",
      "engineering  0.307493\n",
      "software     0.295693\n",
      "party        0.247389\n",
      "third        0.234367\n",
      "contribute   0.222596\n",
      "developed    0.211891\n",
      "includes     0.206766\n",
      "still        0.198634\n",
      "contact      0.186696\n",
      "author       0.184091\n",
      "development  0.152524\n",
      "want         0.144442\n",
      "please       0.137964\n",
      "also         0.123657\n",
      "operational  0.000000\n",
      "operator     0.000000\n",
      "operators    0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  affinitic-caching\n",
      "Description:  introduction changelog 0.7.1 2016 06 03 testing layer that avoids caching gotcha 0.7 2016 06 03 enable disable caching via python or browser view gotcha 0.6.2 2016 05 25 add environment variable to set default cache lifetime jfroche fix dependencies storage jfroche 0.6.1 2015 09 22 use advanced dict to allow getattr on cached rowproxy refs 7577 schminitz 0.6 2014 10 22 allow to invalidate dependencies 0.5 2014 08 26 move memcache utility to overrides zcml delegate the namespace definition to a utility and cache the namespace calculation make sqlalchemy a soft dependency 0.4 2013 02 22 optimizes the caching functions. adds two decorators who clears the cache before or after a function. adds a function to clear a specific cache. adds a function to invalidate a specific key in the cache. 0.3 2013 02 13 change name from arsia.caching to affinitic.caching 0.2 2011 02 22 fix dependencies 0.1 2010 11 01 initial release\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "22            0.278806\n",
      "caching       0.262663\n",
      "gotcha        0.239770\n",
      "jfroche       0.239770\n",
      "cache         0.211597\n",
      "invalidate    0.209322\n",
      "adds          0.203369\n",
      "namespace     0.186289\n",
      "02            0.182442\n",
      "2016          0.180350\n",
      "dependencies  0.159015\n",
      "utility       0.136310\n",
      "2013          0.133480\n",
      "2014          0.128455\n",
      "06            0.124606\n",
      "03            0.123083\n",
      "delegate      0.119885\n",
      "rowproxy      0.119885\n",
      "schminitz     0.119885\n",
      "getattr       0.119885\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  afilnet\n",
      "Description:  afilnet cloud marketing this package is designed to be an easy way to use afilnet api services. you can send sms, email and voice notifications using your afilnet account. you only need an afilnet account with enought credits. if you do not have an account, you can create it http afilnet.us client register.php in a few minutes. installation you can use pip to install this package. go to your terminal and run pip install afilnet easy to use you only need to call the module urls.py service .. code block python res afilnet.sendsms myafilnetusername , myafilnetpassword , to , this is a test message , from then you will receive the result in json. available services there are 4 channels availables general sms email voice this library use the structure .. code block python res afilnet.service params general has two services getbalance get balance of your account isuser return if user is valid or not this service return a boolean sms, email and voice have the same services send send to a single user sendfromtemplate send to a single user using a template sendtogroup send to a defined group sendtogroupfromtemplate send to a defined group using a template getdeliverystatus get delivery status of a message sms sendsms username, password, to, message, sender, scheduledatetime sendsmsfromtemplate username, password, to, idtemplate, params, scheduledatetime sendsmstogroup username, password, sender, countrycode, idgroup, msg, scheduledatetime username, password, countrycode, idgroup, idtemplate, scheduledatetime email sendemail username, password, subject, to, message, scheduledatetime sendemailfromtemplate username, password, to, idtemplate, params, scheduledatetime sendemailtogroup username, password, subject, idgroup, msg, scheduledatetime username, password, idgroup, idtemplate, scheduledatetime voice sendvoice username, password, to, message, lang , scheduledatetime sendvoicefromtemplate username, password, to, idtemplate, params, scheduledatetime sendvoicetogroup username, password, countrycode, idgroup, msg, scheduledatetime username, password, countrycode, idgroup, idtemplate, scheduledatetime user getbalance username, password isuser username, password\n",
      "Highest ranked keywords:\n",
      "\n",
      "                       TF-IDF\n",
      "scheduledatetime     0.749700\n",
      "afilnet              0.312375\n",
      "send                 0.214271\n",
      "voice                0.197809\n",
      "email                0.142069\n",
      "isuser               0.124950\n",
      "getbalance           0.117929\n",
      "sms                  0.117929\n",
      "services             0.104875\n",
      "user                 0.093108\n",
      "res                  0.092537\n",
      "group                0.071424\n",
      "account              0.069560\n",
      "template             0.066053\n",
      "password             0.065767\n",
      "defined              0.064935\n",
      "general              0.063383\n",
      "use                  0.063101\n",
      "sendtogroup          0.062475\n",
      "sendsmsfromtemplate  0.062475\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  afinn\n",
      "Description:  afinn afinn sentiment analysis in python wordlist based approach for sentiment analysis. examples from afinn import afinn afinn afinn afinn.score 'this is utterly excellent ' 3.0 in danish afinn afinn language 'da' afinn.score 'hvis ikke det er det mest afskyelige flueknepperi...' 6.0 with emoticons afinn afinn emoticons true afinn.score 'i saw that yesterday ' 2.0 with multiple sentences here with data from an austen novel available in gutenberg from afinn import afinn from nltk.corpus import gutenberg import textwrap afinn afinn sentences .join wordlist for wordlist in gutenberg.sents 'austen sense.txt' scored sentences afinn.score sent , sent for sent in sentences sorted sentences sorted scored sentences print n .join textwrap.wrap sorted sentences 0 1 , 70 to attach myself to your sister , therefore , was not a thing to be thought of and with a meanness , selfishness , cruelty which no indignant , no contemptuous look , even of yours , miss dashwood , can ever reprobate too much i was acting in this manner , trying to engage her regard , without a thought of returning it . but one thing may be said for me even in that horrid state of selfish vanity , i did not know the extent of the injury i meditated , because i did not then know what it was to love . citation if you as a scientist use the wordlist or the code please cite this one finn rup nielsen, a new anew evaluation of a word list for sentiment analysis in microblogs , proceedings of the eswc2011 workshop on 'making sense of microposts' big things come in small packages. volume 718 in ceur workshop proceedings 93 98. 2011 may. matthew rowe, milan stankovic, aba sah dadzie, mariann hardey editors paper with supplement http www2.imm.dtu.dk pubdb views edoc download.php 6006 pdf imm6006.pdf see also http neuro.compute.dtu.dk wiki afinn brede wiki entry on afinn with pointers to many scientific papers https github.com darenr afinn sentiment analysis in javascript with afinn word list travis et al. .. image https travis ci.org fnielsen afinn.svg branch master target https travis ci.org fnielsen afinn .. image https coveralls.io repos fnielsen afinn badge.svg branch master target https coveralls.io github fnielsen afinn branch master .. image https www.quantifiedcode.com api v1 project badge.svg target https www.quantifiedcode.com app project alt code issues .. image https img.shields.io pypi dm afinn.svg style flat target https pypi.python.org pypi afinn alt downloads .. image https www.openhub.net p afinn widgets project thin badge.gif target https www.openhub.net p afinn alt open hub\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "afinn        0.848966\n",
      "sentences    0.223829\n",
      "wordlist     0.141494\n",
      "fnielsen     0.141494\n",
      "sentiment    0.141494\n",
      "https        0.079325\n",
      "sorted       0.074647\n",
      "sent         0.071539\n",
      "emoticons    0.070747\n",
      "gutenberg    0.070747\n",
      "workshop     0.070747\n",
      "det          0.070747\n",
      "scored       0.066772\n",
      "analysis     0.062435\n",
      "proceedings  0.061763\n",
      "thought      0.059976\n",
      "target       0.054294\n",
      "image        0.050765\n",
      "thing        0.048674\n",
      "word         0.045228\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  afk-time\n",
      "Description:  install bash sudo pip install afk time features get afk time in seconds usage bash usage afk time examples bash sleep 3 afk time 3\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "afk          0.837474\n",
      "time         0.348596\n",
      "bash         0.275405\n",
      "sleep        0.162669\n",
      "seconds      0.132793\n",
      "usage        0.126432\n",
      "sudo         0.103441\n",
      "install      0.094280\n",
      "examples     0.086094\n",
      "features     0.081151\n",
      "get          0.068020\n",
      "pip          0.054564\n",
      "operators    0.000000\n",
      "operator     0.000000\n",
      "operations   0.000000\n",
      "operating    0.000000\n",
      "operational  0.000000\n",
      "operation    0.000000\n",
      "opinions     0.000000\n",
      "operates     0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  afnumpy\n",
      "Description:  afnumpy aims to be a gpu ready drop in replacement for numpy. uses arrayfire http github.com arrayfire arrayfire to do the actual computing. build status https travis ci.org filipemaia afnumpy.svg https travis ci.org filipemaia afnumpy codecov.io https codecov.io github filipemaia afnumpy coverage.svg branch master https codecov.io github filipemaia afnumpy branch master doi https zenodo.org badge 35001963.svg https zenodo.org badge latestdoi 35001963 how to cite please cite afnumpy as filipe r. n. c. maia. 2017 . afnumpy a gpu ready drop in replacement for numpy, http doi.org 10.5281 zenodo.262201 git commit 4a04c11 http github.com filipemaia afnumpy commit 4a04c11\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "afnumpy      0.673441\n",
      "filipemaia   0.481029\n",
      "arrayfire    0.288618\n",
      "4a04c11      0.192412\n",
      "gpu          0.173928\n",
      "cite         0.142498\n",
      "replacement  0.132379\n",
      "ready        0.126149\n",
      "https        0.117678\n",
      "drop         0.117657\n",
      "commit       0.111226\n",
      "filipe       0.096206\n",
      "35001963     0.096206\n",
      "latestdoi    0.073476\n",
      "badge        0.073171\n",
      "http         0.069900\n",
      "doi          0.069341\n",
      "github       0.065652\n",
      "branch       0.063553\n",
      "actual       0.062530\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  agamotto\n",
      "Description:  agamotto agamotto is a helper module to make it easier to test a running system with python. why not use serverspec i work in a python shop and want our devs to be able to easily write their own tests. making the test suite use the same language they use daily removes a potential friction point. installation .. code bash pip install agamotto usage .. code python import agamotto import unittest2 as unittest class testknownsecurityissues unittest.testcase def testbashhascve 2014 6271fix self confirm that fix has been installed for cve 2014 6271 bash code injection vulnerability via specially crafted environment variables self.assertfalse env x ' echo vulnerable' bash c echo this is a test 2 1 , 'vulnerable' , 'bash is vulnerable to cve 2014 6271' def testbashhascve 2014 7169fix self confirm that fix has been installed for cve 2014 7169 bash code injection vulnerability via specially crafted environment variables self.assertfalse env x ' a ' bash c echo echo vuln cat echo vuln echo still vulnerable 2 1 , 'still vulnerable' , 'bash is vulnerable to cve 2014 7169' def self etc shadow has separated fields. check the password field 2 and make sure no accounts have a blank password. self.assertequals agamotto.process.execute 'sudo awk f ' 2 print ' etc shadow wc l' .strip , '0', found accounts with blank password def self etc passwd stores the uid in field 3. make sure only one account entry has uid 0. self.assertequals agamotto.process.execute 'awk f ' 3 0 print ' etc passwd' .strip , 'root x 0 0 root root bin bash' if name ' main ' unittest.main then run py.test. caveats we're a centos shop. this hasn't even been tested on stock rhel, let alone debian or ubuntu. pull requests adding that functionality are welcome, of course.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                  TF-IDF\n",
      "echo            0.322780\n",
      "agamotto        0.312773\n",
      "cve             0.295197\n",
      "2014            0.251348\n",
      "vulnerable      0.234580\n",
      "self            0.184015\n",
      "etc             0.177812\n",
      "bash            0.171427\n",
      "crafted         0.156386\n",
      "testbashhascve  0.156386\n",
      "vulnerability   0.156386\n",
      "vuln            0.156386\n",
      "shadow          0.156386\n",
      "def             0.142768\n",
      "specially       0.136527\n",
      "injection       0.136527\n",
      "uid             0.123788\n",
      "accounts        0.121505\n",
      "confirm         0.121505\n",
      "blank           0.119439\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  ageliaco-rd\n",
      "Description:  introduction this product is intended for a service management in geneva school departement dip . this service is ressources dveloppement and it brings a support for educational projects in the upper secondary schools colleges . this product is dependant on ageliaco.p10userdata , because it does set the basic properties in user data conforming to our ldap settings. installation go to admin site setup add ons activate plone.app.ldap activate ageliaco.p10userdata go to zmi acl users ldap plugin acl users reset ldap server reset configure to fit your needs filter and groups activate ageliaco.rd there is a bug concerning plone.app.ldap when the ldap server is set it doesn't set properly the port number, and the ldap filter is not set either. this product may contain traces of nuts. authors ageliaco , serge renfer mailto serge.renfer gmail dot com changelog 0.1dev unreleased initial release\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "ldap          0.545092\n",
      "acl           0.206391\n",
      "product       0.201623\n",
      "activate      0.200704\n",
      "reset         0.184964\n",
      "set           0.168088\n",
      "filter        0.148760\n",
      "go            0.126692\n",
      "serge         0.124876\n",
      "ageliaco      0.124876\n",
      "dip           0.124876\n",
      "geneva        0.124876\n",
      "dveloppement  0.124876\n",
      "ressources    0.124876\n",
      "renfer        0.124876\n",
      "departement   0.124876\n",
      "colleges      0.124876\n",
      "schools       0.124876\n",
      "users         0.122070\n",
      "service       0.122070\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  agenda\n",
      "Description:  simple python module for pretty task logging. exposes the following methods section starts a new section of application processing task starts a new high level task within the section subtask starts a new subtask within the task subfailure indicates the failure of a subtask of the current task failure indicates the failure of a high level task subprompt prints a subtask input prompt prompt prints a high level input prompt\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "task         0.492223\n",
      "subtask      0.481942\n",
      "starts       0.292012\n",
      "failure      0.267691\n",
      "prompt       0.267691\n",
      "high         0.211389\n",
      "section      0.192776\n",
      "indicates    0.190741\n",
      "level        0.185550\n",
      "prints       0.173682\n",
      "within       0.127947\n",
      "new          0.126220\n",
      "input        0.123700\n",
      "subprompt    0.120486\n",
      "subfailure   0.120486\n",
      "exposes      0.095371\n",
      "pretty       0.079703\n",
      "processing   0.070463\n",
      "methods      0.062101\n",
      "application  0.059099\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  agglomcluster\n",
      "Description:  build status https travis ci.org mseal agglom cluster.svg branch master https travis ci.org mseal agglom cluster hac agglomerative clustering tool for network x graphs clustering implements the algorithm described by fast algorithm for detecting community structure in networks m. e. j. newman. 2004 http arxiv.org pdf cond mat 0309508v1.pdf the algorithm efficiently clusters large number of nodes and is one of the best scaling clustering algorithms available. it relies on building and slicing a dendrogram of potential clusters from the base of a networkx graph. each possible pairing of elements is evaluated and clustering in quality see paper reference increasing order. the greedy aspect of this approach is in the avoidance of backtracking. each pass on the dengrogram assume prior passes were the global minimum for overall quality. given decent edge associations, this is a relatively safe assumption to make and vastly increases the speed of the algorithm. see papers on scaling and accuracy questions regarding greedy newman. this implementation uses a heap to select the best pair to cluster at each iteration a naive implementation considers all n edges in the graph o n a heap reduces this search dramatically o log n installation pip install agglomcluster dependencies networkx supported graphing library examples import networkx as nx from hac import clusterer this cluster call is where most of the heavy lifting happens karate dendrogram clusterer.cluster nx.karate club graph karate dendrogram.clusters 1 set range 34 karate dendrogram.clusters 2 set 0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 19, 21 , set 32, 33, 8, 14, 15, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31 karate dendrogram.clusters 3 set 32, 33, 8, 14, 15, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31 , set 1, 2, 3, 7, 9, 12, 13, 17, 21 , set 0, 4, 5, 6, 10, 11, 16, 19 we can ask the dendrogram to pick the optimal number of clusters karate dendrogram.clusters set 32, 33, 8, 14, 15, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31 , set 1, 2, 3, 7, 9, 12, 13, 17, 21 , set 0, 4, 5, 6, 10, 11, 16, 19 karate dendrogram.labels 0 2, 1 1, 2 1, 3 1, 4 2, 5 2, 6 2, 7 1, 8 0, 9 1, 10 2, 11 2, 12 1, 13 1, 14 0, 15 0, 16 2, 17 1, 18 0, 19 2, 20 0, 21 1, 22 0, 23 0, 24 0, 25 0, 26 0, 27 0, 28 0, 29 0, 30 0, 31 0, 32 0, 33 0 we can also force certain nodes to always be clustered together forced clusters set 33,0 , set 32,1 forced karate dendrogram clusterer.cluster nx.karate club graph , forced clusters forced clusters forced karate dendrogram.clusters set 0, 33, 9, 11, 12, 14, 15, 17, 18, 19, 21, 26, 29 , set 32, 1, 2, 3, 7, 8, 13, 20, 22, 30 , set 23, 24, 25, 27, 28, 31 , set 16, 10, 4, 5, 6 issues the actual modularity score does not exactly match the modularity score of the example on the wikipedia page extensive use and investigation indicates it's not affecting the quality of results, just makes it difficult to match referenced paper's exact results http en.wikipedia.org wiki modularity networks does not handle disconnected components unless they are components of size 1 node relabeling is messy adds hashable nodes dependency dendrogram crawling is used for two separate purposes which aren't clearly defined called limitations nodes inside clustered graph must be hashable elements does not work for directed graphs todo operate on the undirected graph does not work for negative graphs todo add this capability todo move issues to github issues and out of readme consider using a scikit sparse matrix for the dengrogram generation as an optimization convert clustering process into a multi thread process capable version consider interface capabilty parity with scikit agglomerativecluster add evaluation function options to clusterer other than originally defined quality a few methods could use documentation classes used to generate dendrogram objects that represent a clustered graph. use .cluster to process a graph. dendrogram the clustered result from an agglomerative clustering pass. use .clusters and .labels to get the desired cluster results. additionally you this class has some built in graphing methods .plot and .plot quality history . performance approximate performance runs on natural graph sizes on high end machine nodes edges time memory 1000 6000 1.5 s 28 mb 10000 80000 350 s 2.5 gb todo more sizes author author s matthew seal past author contributors s ethan lozano, zubin jelveh\n",
      "Highest ranked keywords:\n",
      "\n",
      "              TF-IDF\n",
      "karate      0.359563\n",
      "dendrogram  0.314617\n",
      "clustering  0.228613\n",
      "set         0.226867\n",
      "clusters    0.217861\n",
      "forced      0.181551\n",
      "clustered   0.179781\n",
      "nodes       0.158075\n",
      "graph       0.150897\n",
      "31          0.137417\n",
      "modularity  0.134836\n",
      "cluster     0.127971\n",
      "networkx    0.127259\n",
      "quality     0.123689\n",
      "21          0.105141\n",
      "graphs      0.104761\n",
      "todo        0.093430\n",
      "mseal       0.089891\n",
      "club        0.089891\n",
      "clusterer   0.089891\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  ago\n",
      "Description:  what are human readable timedeltas ago.py makes customizable human readable timedeltas, for example testing past tense russell commented 1 year, 127 days, 16 hours ago you replied 1 year, 127 days ago testing future tense program will shutdown in 2 days, 3 hours, 27 minutes job will run 2 days, 3 hours from now how to install there are a number of ways to install this package. you could run this ad hoc command pip install ago or specify ago under the setup requires list within your setuptools compatible project's setup.py file. how to use the ago module comes with three functions . human . delta2dict . get delta from subject you really only need to worry about human . here are all the available arguments and defaults human subject, precision 2, past tense ' ago', future tense 'in ', abbreviate false subject a datetime, timedelta, or timestamp integer float object to become human readable precision default 2 the desired amount of unit precision past tense default ' ago' the format string used for a past timedelta future tense default 'in ' the format string used for a future timedelta abbreviate default false boolean to abbreviate units here is an example on how to use human from ago import human from ago import delta2dict from datetime import datetime from datetime import timedelta pretend this was stored in database db date datetime year 2010, month 5, day 4, hour 6, minute 54, second 33, microsecond 4000 to find out how long ago, use the human function print 'created ' human db date optionally pass a precision print 'created ' human db date, 3 print 'created ' human db date, 6 we also support future dates and times present datetime.now past present timedelta 492, 58711, 45 days, secs, ms future present timedelta 2, 12447, 963 days, secs, ms print human future example past tense and future tense keyword arguments output1 human past, past tense 'titanic sunk 0 ago', future tense 'titanic will sink in 0 from now' output2 human future, past tense 'titanic sunk 0 ago', future tense 'titanic will sink in 0 from now' print output1 titanic sunk 1 year, 127 days ago print output2 titanic will sink in 2 days, 3 hours from now need more examples you should look at test ago.py how do i thank you you should follow me on twitter http twitter.com russellbal license public domain public revision control https bitbucket.org russellballestrini ago\n",
      "Highest ranked keywords:\n",
      "\n",
      "              TF-IDF\n",
      "tense       0.506868\n",
      "human       0.440652\n",
      "ago         0.331876\n",
      "past        0.286463\n",
      "future      0.238843\n",
      "timedelta   0.184376\n",
      "precision   0.136495\n",
      "abbreviate  0.126717\n",
      "sunk        0.126717\n",
      "datetime    0.121776\n",
      "127         0.119596\n",
      "sink        0.114544\n",
      "db          0.108013\n",
      "print       0.107088\n",
      "hours       0.090199\n",
      "readable    0.087181\n",
      "output2     0.084478\n",
      "output1     0.084478\n",
      "delta2dict  0.084478\n",
      "titanic     0.079731\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  ags-tool-deploy\n",
      "Description:  overview   this tool provides a command line interface for packaging and publishing python toolboxes to arcgis server 10.2.x .  installation   to install the latest stable version     pip install python ags  latest changes     pip install https bitbucket.org databasin ags tool deploy get develop.zip egg ags tool deploy  installing manually   download the latest changes from the develop branch https bitbucket.org databasin ags tool deploy get develop.zip , extract, and execute    python setup.py install  this will install the script to your local python packages folder as    ags tool deploy deploy.py  consider adding this folder to your path.  usage   this tool is intended to be run from within a console.  for information on usage, simply run    python deploy.py help  the commands below allow you to include mercurial repository information. this does not bundle the full repository, but instead includes the link to the source repository and current branch, so that you can run    hg pull update  on the server to pull down the full repository.  packaging   use the package command to bundle your python toolbox into a service definition .sd file.    usage deploy.py package options toolbox path service name outfile name   package a python toolbox into a service definition file .sd . local python modules this toolbox references are included automatically. requires 7zip to be installed and on the system path.  warning this will overwrite the file outfile name if it already exists.  aguments  toolbox path filename of python toolbox .pyt to deploy service name name of service, including folder s . example somefolder mytool outfile name of the service definition file to create  options  files files wildcard patterns of additional files to include relative to toolbox . example  .csv,some data.  hg include mercurial hg repository  information  sync execute tool synchronously instead of asynchronously default  messages none info error warning  level of messaging for service help show this message and exit.  publishing   use the publish command to deploy your python toolbox to an arcgis server.    usage deploy.py publish options toolbox path service name server port user   publish a python toolbox to an arcgis server. local python modules this toolbox references are included automatically. requires 7zip to be installed and on the system path.  aguments  toolbox path filename of python toolbox .pyt to deploy service name name of service, including folder s . example somefolder mytool server port hostname and port number of arcgis server user arcgis server administrator user name  options  password password arcgis administrator password. you will be prompted for this if you do not provide it files files wildcard patterns of additional files to include relative to toolbox . example  .csv,some data.  hg include mercurial hg repository  information  sync execute tool synchronously instead of asynchronously default  messages none info error warning  level of messaging for service overwrite delete and replace the service, if it already exists  help show this message and exit.  requirements    lxml click ags from https bitbucket.org databasin python ags  7zip must be installed manually from 7zip website http www.7 zip.org   assumptions   only python 2.7 is supported only tested on windows only arcgis 10.2.x is supported  license   see license file.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "toolbox        0.464368\n",
      "arcgis         0.322139\n",
      "ags            0.304037\n",
      "deploy         0.219341\n",
      "service        0.202436\n",
      "hg             0.195066\n",
      "7zip           0.184079\n",
      "tool           0.165105\n",
      "name           0.152770\n",
      "python         0.147218\n",
      "databasin      0.138060\n",
      "outfile        0.138060\n",
      "server         0.132190\n",
      "mercurial      0.117039\n",
      "include        0.103191\n",
      "files          0.095900\n",
      "folder         0.093016\n",
      "publish        0.092180\n",
      "somefolder     0.092040\n",
      "synchronously  0.092040\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  agua\n",
      "Description:  agua agua a system that helps you test the coverage and accuracy of your data applications. installation .. code shell pip install agua example usage .. code shell cd example agua test .. code shell test results for example.csv column name vs final name coverage 3 4 75.00 accuracy 2 3 66.67 column age vs test age coverage 4 4 100.00 accuracy 4 4 100.00 column fruit vs test fruit coverage 4 4 100.00 accuracy 4 4 100.00 configuration check out example agua.yml for configuration options. to compare columns, you may use one of the existing comparators or specify a python path to a callable. check out agua comparators.py for example comparators. list built in comparators with, .. code shell agua list any keyword arguments that need to be passed to the comparator may be specified with a kwargs parameter graphs are printed with a slightly modified version of termgraph https github.com mkaz termgraph .. agua image . logo.png raw true\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "agua           0.660383\n",
      "accuracy       0.311845\n",
      "vs             0.219894\n",
      "shell          0.199486\n",
      "fruit          0.188681\n",
      "termgraph      0.188681\n",
      "comparators    0.188681\n",
      "column         0.185555\n",
      "test           0.175395\n",
      "coverage       0.171225\n",
      "age            0.170556\n",
      "example        0.120826\n",
      "code           0.100796\n",
      "comparator     0.094340\n",
      "mkaz           0.094340\n",
      "check          0.079727\n",
      "configuration  0.078928\n",
      "slightly       0.077961\n",
      "may            0.073610\n",
      "graphs         0.073298\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aha-application-default\n",
      "Description:  a default appliction for aha framework. it has only simple controller and say 'aha ' .\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "appliction   0.545032\n",
      "aha          0.545032\n",
      "controller   0.450404\n",
      "say          0.357334\n",
      "simple       0.201853\n",
      "default      0.185969\n",
      "operating    0.000000\n",
      "operators    0.000000\n",
      "operator     0.000000\n",
      "operations   0.000000\n",
      "optimize     0.000000\n",
      "operational  0.000000\n",
      "operation    0.000000\n",
      "operates     0.000000\n",
      "optimal      0.000000\n",
      "operated     0.000000\n",
      "operate      0.000000\n",
      "operand      0.000000\n",
      "operaciones  0.000000\n",
      "opera        0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  ahds\n",
      "Description:  ahds .. contents table of contents overview ahds amira r header and data streams is a python package to parse and handle amira r files. it was developed to facilitate reading of amira r files as part of the emdb sff toolkit. use cases detect and parse amira r headers and return structured data decode data hxrlebyte, hxzip easy extensibility to handle previously unencountered data streams ahds was written and is maintained by paul k. korir. dependencies simpleparse tested with 2.1.1 install from source from the simpleparse site fails with 2.2.0 numpy tested with 1.11.2 scikit image tested with 0.11.3 license copyright 2017 embl european bioinformatics institute  licensed under the apache license, version 2.0 the license you may not use this file except in compliance with the license. you may obtain a copy of the license at  http www.apache.org licenses license 2.0  unless required by applicable law or agreed to in writing, software distributed under the license is distributed on an  as is basis, without warranties or conditions of any kind, either express or implied. see the license for the specific language governing permissions and limitations under the license.  future plans write out valid amira r files background and definitions ahds presently handles two types of amira r files  amiramesh files, which typically but not necessarily have a .am extension, and  hypersurface files, which have .surf and represent an older filetype. both file types consist of two parts a header , and one or more data streams . headers are structured in a modified vrml like syntax and differ between amiramesh and hypersurface files in some of the keywords used. a data stream is a sequence of encoded bytes either referred to in the header by some delimiter usually data stream index , where data stream index is an integer or a set of structural keywords e.g. vertices , patches expected in a predefined sequence. headers in detail amiramesh and hypersurface headers can be divided into four main sections designation definitions parameters, and data pointers. the designation is the first line and conveys several important details about the format and structure of the file such as filetype either amiramesh or hypersurface dimensionality 3d format binary little endian , binary or ascii version a decimal number e.g. 2.1 extra format data e.g. hxsurface specifying that an amiramesh file will contain hypersurface data a series of definitions follow that refer to data found in the data pointer sections that either begin with the word define or have n prepended to a variable. for example define lattice 862 971 200 or nvertices 85120 this is followed by grouped parameters enclosed in a series of braces beginning with the word parameters. various parameters are then enclosed each beginning with the name of that group of parameters e.g. materials parameters  grouped parameters material  the names of various materials with attributes exterior id 0  inside id 1, color 0 1 1, transparency 0.5   patches  patch attributes innerregion inside, outerregion exterior, boundaryid 0, branchingpoints 0   inline parameters gridsize value ,   the most important set of parameters are materials as these specify colours and identities of distinct segments datasets within the file. finally, amiramesh files list a set of data pointers that point to data labels within the file together with additional information to decode the data. we refer to these as data streams because they consist of continuous streams of raw byte data that need to be decoded. here is an example of data pointers that refer to the location of 3d surface primitives vertices float 3 vertices 1 triangledata int 7 triangles 2 patches 0 int patches 0 3 these refer to three raw data streams each found beginning with the delimiter number . data stream one 1 is called vertices and consists of float triples, two is called triangledata and has integer 7 tuples and three called patches is a single integer the number of patches . in some cases the data pointer contains the data encoding for the corresponding data pointer. lattice byte labels 1 hxbyterle,234575740 which is a run length encoded data stream of the specified length, while  lattice byte data 1 hxzip,919215 contains zipped data of the specified length. data streams in detail amiramesh data streams are very simple. they always have a start delimiter made of with an index that identifies the data stream. a newline character separates the delimiter with the data stream proper which is either plain ascii or a binary stream raw, zipped or encoded . hypersurface data streams structured to have the following sections  header vertices nvertices  vertices data stream  nbranchingpoints nbranching points nverticesoncurves nvertices on curves boundarycurves nboundary curves patches npatches  innerregion inner region name outerregion outer region name boundaryid boundary id branchingpoints nbranching points triangles ntriangles  triangles data stream  repeats for as npatches times hypersurface data streams can be either plain ascii or binary. ahds modules ahds has three main modules ahds.grammar specifies an ebnf grammar ahds.header ahds.data stream these modules are tied into a user level class called amirafile that does all the work for you. .. code python  from ahds import amirafile  read an amiramesh file  af amirafile 'am test7.am'  af.header  amiraheader with 4 bytes  empty data streams  af.data streams  print af.data streams none  we have to explicitly read to get the data streams  af.read  af.data streams  class 'ahds.data stream.datastreams' object with 13 stream s 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13  for ds in af.data streams ... print ds ...  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  class 'ahds.data object of 2,608 bytes  we get the n th data stream using the index key notation  af.data streams 1 .encoded data '1 n2 n3 n'  af.data streams 1 .decoded data  1, 2, 3  af.data streams 2 .encoded data '69 n120 n116 n101 n114 n105 n111 n114 n0 n73 n110 n115 n105 n100 n101 n0 n109 n111 n108 n101 n99 n117 n108 n101 n0 n'  af.data streams 2 .decoded data  69, 120, 116, 101, 114, 105, 111, 114, 0, 73, 110, 115, 105, 100, 101, 0, 109, 111, 108, 101, 99, 117, 108, 101, 0 .. code python  read an hypersurface file  af amirafile 'surf test4.surf'  af.read  af.data streams  class 'ahds.data stream.datastreams' object with 5 stream s patches, nbranchingpoints, boundarycurves, vertices, nverticesoncurves  hypersurface files have pre set data streams  af.data streams 'vertices' .decoded data 10  560.0, 243.0, 60.96875 , 560.0, 242.9166717529297, 61.0 , 559.5, 243.0, 61.0 , 561.0, 243.0, 60.95833206176758 , 561.0, 242.5, 61.0 , 561.0384521484375, 243.0, 61.0 , 559.0, 244.0, 60.94444274902344 , 559.0, 243.5, 61.0 , 558.9722290039062, 244.0, 61.0 , 560.0, 244.0, 60.459999084472656 ahds.grammar this module describes the header grammar for amira r amiramesh and hypersurface files and so depends on simpleparse python package. it defines a single class amiradispatchprocessor and four functions. amiradispatchprocessor is a subclass of which implements the core functionality required to use the grammar. each grammar token has a corresponding method defined on this class which determines how the data associated with that token will be rendered. data can be rendered as a single or multimap, string, number, or in custom format.  ahds.grammar.get parsed data fn, args, kwargs is the user level function that takes a filename and returns structured parsed data. it depends on the other three functions defined  ahds.grammar.detect format fn, format bytes 50, verbose false returns either amiramesh or hypersurface given a file name and arguments,  get header fn, file format, header bytes 20000, verbose false returns the header portion based on the file format determined by detect format ... , and  parse header data, verbose false converts the raw header data returned by get header ... into a structured header based on amiradispatchprocessor. ahds.header this module converts the structured header from the ahds.grammar module into an object with the sections of the header designation, definitions, parameters and data pointers and corresponding structured data available as attributes. that is it converts the header  amiramesh binary little endian 2.1   define lattice 862 971 200  parameters  materials  exterior  id 1   inside  color 0.64 0 0.8,  id 2   mitochondria  id 3,  color 0 1 0   mitochondria  id 4,  color 1 1 0   mitochondria  id 5,  color 0 0.125 1   ne  id 6,  color 1 0 0    content 862x971x200 byte, uniform coordinates ,  boundingbox 0 13410.7 0 15108.4 1121.45 4221.01,  coordtype uniform   lattice byte labels 1 hxbyterle,4014522 into an amiraheader object. .. code python  from ahds.header import amiraheader  amira header amiraheader.from file 'am test2.am'  amira header.designation.attrs  'filetype', 'dimension', 'format', 'version', 'extra format'  amira 'amiramesh'  amira  amira 'binary little endian'  amira header.definitions.attrs  'lattice'  amira  862, 971, 200  amira header.parameters.attrs  'materials', 'content', 'boundingbox', 'coordtype'  amira  'exterior', 'inside', 'mitochondria', 'mitochondria ', 'mitochondria ', 'ne'  amira  'id'  amira 1  amira ' 862x971x200 byte, uniform coordinates ,'  amira  0, 13410.7, 0, 15108.4, 1121.45, 4221.01  amira ' uniform '  amira header.data pointers.attrs  'data pointer 1'  amira header.data pointers.data pointer 1.attrs  'pointer name', 'data format', 'data dimension', 'data type', 'data name', 'data index', 'data length'  amira header.data pointers.data pointer 1.pointer name 'lattice'  amira header.data pointers.data pointer 1.data format 'hxbyterle'  amira header.data pointers.data pointer 1.data dimension  amira header.data pointers.data pointer 1.data type 'byte'  amira header.data pointers.data pointer 1.data name 'labels'  amira header.data pointers.data pointer 1.data index 1  amira header.data pointers.data pointer 1.data length 4014522 this module consists of two main classes ahds.header.amiraheader is the user level class and ahds.header.block which is a container class for a block of structured data from an amira r header. amiraheader has one constructor amiraheader.from file fn, args, kwargs which takes an amira r file by name and arguments and returns an amiraheader object with all attributes set as described above. alternatively, one can use the initiator form to pass structured data directly amiraheader parsed data which returns an amiraheader object configured appropriately. the raw data structured data is available as read only property amiraheader.raw header internally the amiraheader class implements a set of private methods which individually load the four data sections designation, definitions, parameters, and data pointers . the block class is a container class which converts structured groups to attributes and has two main attributes block.name provides the name of the current block .. code python  amira header.designation.name 'designation'  amira 'materials'  amira 'exterior' block.attrs provides the attributes available on this block .. code python  amira header.designation.attrs  'filetype', 'dimension', 'format', 'version', 'extra format'  amira 'binary little endian' a given materials block has two special features block.ids returns the list of ids for all materials. this is important when decoding hxbyterle compressed data block id returns the material for the given id using index notation.  amira  1, 2, 3, 4, 5, 6  amira header.parameters.attrs  'materials', 'content', 'boundingbox', 'coordtype'  ids attribute is only available for material blocks within parameters section  amira traceback most recent call last  file stdin , line 1, in module attributeerror 'str' object has no attribute 'ids'  we can get the name of a material of the given id  amira 4 .name 'mitochondria ' ahds.data stream this is most complex module implementing a hierarchy of classes describing various data streams within amira r files. it has 22 classes and five functions classes there are three categories of classes a user level class that encapsulates 2 below. classes describing amira r data streams  classes describing amiramesh data streams   classes describing hypersurface data streams data conversion classes amiramesh only  classes abstracting images  classes abstracting contours the user level datastreams class is the preferred way to use the module. it takes the name of an amira r file and encapsulates an iterator of data streams. .. code python  from ahds import data stream  data streams data stream.datastreams 'am test6.am'  data streams  class 'ahds.data stream.datastreams' object with 2 stream s 1, 2  for ds in data streams ... print ds ...  class 'ahds.data object of 968,909 bytes  class 'ahds.data object of 968,909 bytes functions the functions implemented in this module decode data streams.  ahds.data stream.hxbyterle decode decodes hxbyterle data streams  ahds.data stream.hxzip decode data size, data unzips zlib compressed data streams  ahds.data stream.unpack binary data pointer, definitions, data unpacks the structured data stream according to the attributes specified in the datas data pointer  ahds.data stream.unpack ascii data converts rows of ascii data into numerical data classes in detail datastreams class the following attributes are available on objects of this class  ahds.data stream.datastreams.file filename of amira r file  ahds.data an object of class ahds.header.amiraheader encapsulating the header data in four sections designation, definitions, parameters, and data pointers  ahds.data the filetype as specified in ii above.  ahds.data data all raw data from the file including the header  len datastreams the number of data streams contained  ahds.data stream.datastreams index returns the data stream of the index specified as defined in the data pointers section of the header object classes describing amira r data streams the following diagrams illustrates the hierarchy of classes classes describing amira r data streams  ahds.data stream.amiradatastream is the base class for all data stream classes and defines the following attributes   ahds.data an ahds.header.amiraheader object    ahds.data pointer the pointers.data pointer x for this data stream    ahds.data data the raw file data    ahds.data data the encoded data for this stream none for voiddatastream subclasses    ahds.data data the decoded data for this stream none for voiddatastream subclasses    ahds.data length the number of items tuples, integers in decoded data  the two main subclasses of amiradatastream are ahds.data , which is a concrete class representing all amiramesh data streams, and ahds.data , which abstractly defines hypersurface data streams. there are two main amirahxsurfacedatastream subclasses  ahds.data stream.voiddatastream represents amirahxsurfacedatastream data streams that only have a name and value but no actual encoded data on the following line . there are two subclasses   ahds.data stream.nameddatastream subclasses have a strings after data stream name. the two concrete subclasses are    ahds.data for the name of an inner region of a patch see patchesdatastream , and    ahds.data for corresponding name of the outer region of a patch.    ahds.data stream.valueddatastream have an integer value after the data stream name. the three concrete subclasses are    ahds.data hold the boundary id of a patch,    ahds.data stores the number of branching points, and    ahds.data stream.patchesdatastream with the number of patches, which is a special valuedatastream that contains an iterable of patches each containing a patches x datastream objects.    ahds.data stream.loadeddatastream represent amirahxsurfacedatastream data streams that have a name, a value and encoded data. the two main concrete subclasses are    ahds.data represents data streams with float triples, and    ahds.data represents data streams within a patch with triples of 1 based indices triangles of vertices specified in the verticesdatastream.  conversion classes there are two groups of conversion classes which only apply to some amiramesh data streams conversion classes image conversion classes consist of a image container class imageset and an image class. imageset objects that can be iterated to give image objects are returned from the amirameshdatastream.to images method call. ..\tcode python  decode the data stream to images  images ds 1 .to images  images  imageset with 200 images  for image in images ... print image ...  image with dimensions 971, 862  image with dimensions 971, 862  image with dimensions 971, 862 ...  image with dimensions 971, 862  image with dimensions 971, 862 contour conversion classes convert individual images into sets of contours contourset iterable as individual contours objects. they are obtained from calls to the image.as contours property. furthermore, the image.as segments property call returns a dictionary of the corresponding contourset object indexed by the z plane. ..\tcode python  contours per image  the dictionary key is the amira id for the segment the id of the material  a segment can have several non overlapping contours or polylines  for image in images ... print image.as contours ...  2 class 'ahds.data stream.contourset' with 15 contours, 3 class 'ahds.data stream.contourset' with 3 contours, 5 class 'ahds.data stream.contourset' with 2 contours  2 class 'ahds.data stream.contourset' with 18 contours, 3 class 'ahds.data stream.contourset' with 3 contours, 5 class 'ahds.data stream.contourset' with 2 contours ...  2 class 'ahds.data stream.contourset' with 15 contours, 3 class 'ahds.data stream.contourset' with 1 contours, 5 class 'ahds.data stream.contourset' with 3 contours  2 class 'ahds.data stream.contourset' with 15 contours, 3 class 'ahds.data stream.contourset' with 1 contours, 5 class 'ahds.data stream.contourset' with 3 contours    separate individual segments  images.segments  1 110 class 'ahds.data stream.contourset' with 1 contours , 2 0 class 'ahds.data stream.contourset' with 15 contours, 1 class 'ahds.data stream.contourset' with 18 contours, ..., 198 class 'ahds.data stream.contourset' with 3 contours, 199 class 'ahds.data stream.contourset' with 3 contours\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "amira         0.510639\n",
      "data          0.407885\n",
      "streams       0.360743\n",
      "class         0.220984\n",
      "stream        0.187078\n",
      "amiramesh     0.159575\n",
      "bytes         0.145685\n",
      "pointer       0.140567\n",
      "hypersurface  0.138298\n",
      "contours      0.138298\n",
      "header        0.136021\n",
      "object        0.124766\n",
      "classes       0.123744\n",
      "structured    0.095960\n",
      "ahds          0.085106\n",
      "amiraheader   0.085106\n",
      "subclasses    0.081167\n",
      "vertices      0.074468\n",
      "862           0.074468\n",
      "patches       0.071970\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  ahoy\n",
      "Description:  ahoy .. image https img.shields.io travis eddiejessup ahoy.svg target https travis ci.org eddiejessup ahoy .. image https img.shields.io pypi v ahoy.svg target https pypi.python.org pypi ahoy agent based simulations of active particles free software bsd license documentation https ahoy.readthedocs.org. features todo history 0.1.0 2015 01 11 first release on pypi.\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "ahoy         0.655596\n",
      "eddiejessup  0.437064\n",
      "https        0.222754\n",
      "particles    0.218532\n",
      "simulations  0.190781\n",
      "agent        0.180591\n",
      "active       0.137543\n",
      "target       0.134168\n",
      "travis       0.132957\n",
      "bsd          0.130994\n",
      "image        0.125446\n",
      "pypi         0.125270\n",
      "2015         0.114046\n",
      "todo         0.113569\n",
      "01           0.107577\n",
      "history      0.102578\n",
      "11           0.101289\n",
      "free         0.093053\n",
      "software     0.084886\n",
      "features     0.084703\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  ai-cs\n",
      "Description:  welcome to ai.cs ai.cs is the coordinates transformation package in python. it offers functionality for converting data between geometrical coordinates cartesian, spherical and cylindrical as well as between geocentric and heliocentric coordinate systems typically used in spacecraft measurements. the package currently also supports rotations of data by means of rotation matrices https en.wikipedia.org wiki rotation matrix . transformations between spacecraft coordinate systems are implemented as a python binding to the cxform https spdf.sci.gsfc.nasa.gov pub software old selected software from nssdc coordinate transform library. the full documentation is available at aics.rtfd.io http aics.rtfd.io . getting started this tutorial will guide you through basic usage of ai.cs. installation ai.cs is developed for python 3, so make sure that you have a working isntallation of it. the package is distributed together with c portion of cxform library, which is compiled automatically during installation. thus make sure that you have a functioning compiler in your system, for instance, gcc. assuming the above requirements are satisfied install the package with python package manager pip install ai.cs geometrical coordinates ai.cs ships with functions for conversion between cartesian and spherical coordinates and between cartesian and cylindrical coordinates .. code block python import numpy as np from ai import cs cartesian to spherical r, theta, phi cs.cart2sp x 1, y 1, z 1 spherical to cartesian x, y, z cs.sp2cart r 1, theta np.pi 4, phi np.pi 4 cartesian to cylindrical r, phi, z cs.cart2cyl x 1, y 1, z 1 cylindrical to cartesian x, y, z cs.cyl2cart r 1, phi np.pi 2, z 1 most of the functions support both scalars and numpy arrays as input .. code block python import numpy as np from ai import cs converting spherical spiral from spherical to cartesian coordinates x, y, z cs.sp2cart r np.ones 100 , theta np.linspace np.pi 2, np.pi 2, 100 , phi np.linspace 0, np.pi 6, 100 spacecraft coordinates ai.cs provides python bindings to cxform library for conversion between various geocentric and heliocentric cartesian coordinate systems. for example, the code below performs transformation of data from gse to heeq coordinate system .. code block python from datetime import datetime from astropy import units as u from ai import cs converting 0.5, 0.5, 0.5 au location from gse to heeq at current time x, y, z cs.cxform 'gse', 'heeq', datetime.now , x u.au.to u.m, 0.5 , y u.au.to u.m, 0.5 , z u.au.to u.m, 0.5 both scalars and numpy arrays are supported as input .. code block python from datetime import datetime, timedelta from astropy import units as u from ai import cs converting circular orbit at 1 au from cylindrical to cartesian coordinates r np.ones 365 u.au.to u.m, 1 phi np.linspace 0, np.pi 2, 365 z np.zeros 365 x hee, y hee, z hee cs.cyl2cart r, phi, z converting hee to heeq x heeq, y heeq, z heeq cs.cxform 'hee', 'heeq', datetime 2016, 1, 1 timedelta days d for d in range 365 , x x hee, y y hee, z z hee geometrical transformations currently ai.cs offers only one type of geometrical transformations rotations. rotation is executed by means of 3d transformation matrices for right handed rotations around x, y and z axes .. code block python import numpy as np from ai import cs get 3x3 rotation matrix for rotation by pi 4 around x axis tx cs.mx rot x gamma np.pi 4 get 3x3 rotation matrix for rotation by pi 4 around y axis ty cs.mx rot y theta np.pi 4 get 3x3 rotation matrix for rotation by pi 2 around z axis tz cs.mx rot z phi np.pi 2 is is also possible to construct rotation matrices for compound rotations in one shot .. code block python import numpy as np from ai import cs get matrix for right handed rotation around x, y and z axes exactly in this order t cs.mx rot theta np.pi 4, phi np.pi 4, gamma np.pi 4 get matrix for right handed rotation around z, y and x axes exactly in this order t reverse cs.mx rot reverse theta np.pi 4, phi np.pi 4, gamma np.pi 4 t reverse effectively reverses the transformation described by t in this case rotation matrices can be applied to data in cartesian coordinates in the following way .. code block python import numpy as np from ai import cs a cube with the side length 2 x np.array 1, 1, 1, 1, 1, 1, 1, 1 y np.array 1, 1, 1, 1, 1, 1, 1, 1 z np.array 1, 1, 1, 1, 1, 1, 1, 1 rotate cube by pi 4 around each axis t cs.mx rot theta np.pi 4, phi np.pi 4, gamma np.pi 4 x, y, z cs.mx apply t, x, y, z\n",
      "Highest ranked keywords:\n",
      "\n",
      "                  TF-IDF\n",
      "rotation        0.346478\n",
      "cartesian       0.304394\n",
      "phi             0.290265\n",
      "coordinates     0.225522\n",
      "cs              0.197093\n",
      "theta           0.193510\n",
      "spherical       0.182636\n",
      "ai              0.175406\n",
      "rot             0.174921\n",
      "cylindrical     0.161258\n",
      "import          0.160609\n",
      "matrix          0.143312\n",
      "numpy           0.137116\n",
      "coordinate      0.136706\n",
      "around          0.133636\n",
      "heeq            0.129007\n",
      "geometrical     0.129007\n",
      "transformation  0.129007\n",
      "365             0.129007\n",
      "np              0.123160\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aidsinfo\n",
      "Description:  aidsinfo python api wrapper a python wrapper for the aidsinfo drug information api. aidsinfo documentation http www.aidsinfo.nih.gov other rss.aspx usage from aidsinfo import druginfo info druginfo info.search 'abacavir' 'abacavir' 'data' 'here' info.search 'combivir' 'combivir' 'data' 'here' you can also get back just the xml data. ... xml data info.search 'combivir', output format none copyright copyright c 2011 code for america laboratories. see license for details.\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "aidsinfo     0.748247\n",
      "druginfo     0.374124\n",
      "xml          0.233713\n",
      "wrapper      0.199532\n",
      "drug         0.187062\n",
      "copyright    0.185518\n",
      "america      0.176550\n",
      "2011         0.108759\n",
      "back         0.104137\n",
      "info         0.094891\n",
      "none         0.094523\n",
      "format       0.086974\n",
      "output       0.084878\n",
      "python       0.079788\n",
      "information  0.077483\n",
      "api          0.068331\n",
      "data         0.065800\n",
      "also         0.060773\n",
      "get          0.060773\n",
      "license      0.059044\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiida-siesta\n",
      "Description:  aiida siesta plugins and workflows a plugin to interface the siesta dft code https icmab.es siesta to the aiida system http www.aiida.net . documentation can be found in http aiida siesta plugin.readthedocs.io generated from the sources in the aiida siesta docs directory of this distribution . acknowledgements this work is supported by the marvel national centre for competency in research http nccr marvel.ch funded by the swiss national science foundation http www.snf.ch en , as well as by the max european centre of excellence http www.max centre.eu funded by the horizon 2020 einfra 5 program, grant no. 676598, and by the spanish mineco projects fis2012 37549 c05 05 and fis2015 64886 c5 4 p .. figure https albgar aiida siesta plugin master aiida siesta docs miscellaneous logos marvel.png alt marvel .. figure https albgar aiida siesta plugin master aiida siesta docs miscellaneous logos max.png alt max .. figure https albgar aiida siesta plugin master aiida siesta docs miscellaneous logos mineco aei.png alt mineco aei\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "siesta         0.628699\n",
      "aiida          0.571545\n",
      "albgar         0.171463\n",
      "mineco         0.171463\n",
      "miscellaneous  0.149690\n",
      "logos          0.141694\n",
      "figure         0.119251\n",
      "plugin         0.115521\n",
      "marvel         0.114309\n",
      "funded         0.107886\n",
      "centre         0.099793\n",
      "national       0.096905\n",
      "docs           0.093784\n",
      "max            0.069425\n",
      "http           0.069211\n",
      "alt            0.066459\n",
      "fis2012        0.057154\n",
      "nccr           0.057154\n",
      "2020           0.057154\n",
      "excellence     0.057154\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aio-framework\n",
      "Description:  aio framework a python website bot development framework wip introduction this project was created to aid the development of website bots and api wrappers. aio framework handles task management and execution, session management, and captcha queue management with threads . currently, captcha queue management supports 2captcha. aio framework is meant to decrease development time by providing common bot and api wrapper functionality. basic usage this module is available via pip pip install aio framework basic apiwrapper and bot implementations are shown below. bot implementations must implement the execute task method. apiwrapper .. code python exampleapiwrapper.py from aio import apiwrapper class exampleapiwrapper apiwrapper base url 'https example.com' def get product data self, product url response self.get product url return response.json 'data' or something def add product to cart self, product data, captcha token payload 'product data' product data, 'captcha' captcha token endpoint ' add to cart' response self.post endpoint, data payload return response.json 'success' or something bot .. code python examplebot.py from aio import bot from aio.captcha import captchamanager from exampleapiwrapper import exampleapiwrapper class examplebot bot def execute task self, task example api wrapper exampleapiwrapper twocaptcha api token '2captcha api token here' site key 'site key here' page url 'page url here' captcha manager captchamanager twocaptcha api token, site key, page url captcha manager.start captcha queue num threads 5 task.status 'started' product url task.data 'product url' task.logger.info 'getting product data' product data example api wrapper.get product data product url task.logger.info 'got product data ' task.logger.info 'waiting for captcha token' captcha token captcha manager.wait for captcha token task.logger.info 'got captcha token ' task.logger.info 'adding product to cart' added example api wrapper.add product to cart product data, captcha token task.logger.info 'added product to cart ' task.status 'finished' executing .. code python main.py from aio import task from examplebot import examplebot example bot examplebot task data 'product url' 'https example.com product' task task task data example bot.add task task example bot.start all tasks\n",
      "Highest ranked keywords:\n",
      "\n",
      "                     TF-IDF\n",
      "captcha            0.495534\n",
      "product            0.387190\n",
      "task               0.336770\n",
      "bot                0.270389\n",
      "aio                0.266826\n",
      "token              0.212926\n",
      "exampleapiwrapper  0.179856\n",
      "examplebot         0.179856\n",
      "apiwrapper         0.169749\n",
      "url                0.165191\n",
      "cart               0.134892\n",
      "api                0.131398\n",
      "framework          0.130711\n",
      "data               0.110714\n",
      "queue              0.101396\n",
      "captchamanager     0.089928\n",
      "twocaptcha         0.089928\n",
      "example            0.086381\n",
      "import             0.083968\n",
      "management         0.080346\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aio-jsonrpc-2-0\n",
      "Description:  aio jsonrpc 2.0 build status https travis ci.org steffgrez aio jsonrpc 2.0.svg branch master https travis ci.org steffgrez aio jsonrpc 2.0 coverage status https coveralls.io repos github steffgrez aio jsonrpc 2.0 badge.svg branch master https coveralls.io github steffgrez aio jsonrpc 2.0 branch master still in beta description json rpc 2.0 protocol implementation for asyncio, without transport. specification http www.jsonrpc.org usage example to resolve request python import asyncio import json from aio jsonrpc 20 import requestresolver async def foo msg await asyncio.sleep 0.1 return 'foobar ' str msg router 'foo' foo resolver requestresolver router json request json.dumps jsonrpc 2.0 , method foo , params toto , id 1 async def main json response await resolver.handle json request print json response loop asyncio.get event loop loop.run until complete main result json jsonrpc 2.0 , result foobar toto , id 1 example to build request python from aio jsonrpc 20 import requestbuilder builder requestbuilder json request builder.call method foo , params name bar print json request json request builder.call method foo , params name bar2 print json request json request builder.notify method log , params hello print json request result json jsonrpc 2.0 , method foo , params name bar , id 1 jsonrpc 2.0 , method foo , params name bar2 , id 2 jsonrpc 2.0 , method log , params hello example to build batch request python from aio jsonrpc 20 import batchrequestbuilder batch builder batchrequestbuilder id1 batch builder.call method foo , params name bar id2 batch builder.call method foo2 , params name bar print id1, id2 batch builder.notify method foo3 , params name bar json request batch builder.get request print json request result json 1 2 jsonrpc 2.0 , method foo , params name bar , id 1 , jsonrpc 2.0 , method foo2 , params name bar , id 2 , jsonrpc 2.0 , method foo3 , params name bar todo fix definitely interface for builders more test documentation optimisation ... testing py.test cov aio jsonrpc 20 cov report term missing tests 0.1.0 initial release.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                   TF-IDF\n",
      "jsonrpc          0.565625\n",
      "params           0.336584\n",
      "json             0.314973\n",
      "aio              0.280834\n",
      "request          0.258405\n",
      "method           0.219744\n",
      "foo              0.201197\n",
      "bar              0.194793\n",
      "batch            0.155347\n",
      "steffgrez        0.147232\n",
      "name             0.122189\n",
      "id               0.099329\n",
      "print            0.093319\n",
      "20               0.077162\n",
      "result           0.074686\n",
      "foo2             0.073616\n",
      "router           0.073616\n",
      "toto             0.073616\n",
      "requestbuilder   0.073616\n",
      "requestresolver  0.073616\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aio-pipe\n",
      "Description:  aio pipe .. image https travis ci.org mosquito aio pipe.svg target https travis ci.org mosquito aio pipe alt travis ci .. image https img.shields.io pypi v aio pipe.svg target https pypi.python.org pypi aio pipe alt latest version .. image https img.shields.io pypi wheel aio pipe.svg target https pypi.python.org pypi aio pipe .. image https img.shields.io pypi pyversions aio pipe.svg target https pypi.python.org pypi aio pipe .. image https img.shields.io pypi l aio pipe.svg target https pypi.python.org pypi aio pipe real asynchronous file operations with asyncio support. status development beta features aio pipe is a helper for posix pipes. code examples useful example. .. code block python import asyncio from aio pipe import asyncpipe async def main loop p asyncpipe loop for in range 1 await p.write b foo 1000 await p.read 3000 p.close loop asyncio.get event loop loop.run until complete main loop write and read with helpers .. code block python\n",
      "Highest ranked keywords:\n",
      "\n",
      "             TF-IDF\n",
      "aio        0.754204\n",
      "pipe       0.452429\n",
      "loop       0.217028\n",
      "pypi       0.156917\n",
      "https      0.139515\n",
      "asyncpipe  0.136871\n",
      "mosquito   0.136871\n",
      "target     0.105040\n",
      "image      0.098211\n",
      "await      0.087501\n",
      "asyncio    0.086145\n",
      "main       0.065089\n",
      "travis     0.062455\n",
      "posix      0.056554\n",
      "helpers    0.056554\n",
      "block      0.055100\n",
      "code       0.054839\n",
      "3000       0.054170\n",
      "alt        0.053051\n",
      "1000       0.051442\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aioapp-amqp\n",
      "Description:  aioapp amqp micro framework based on asyncio .. image https img.shields.io pypi v aioapp amqp.svg target https pypi.python.org pypi aioapp amqp .. image https img.shields.io travis inplat aioapp amqp.svg target https travis ci.org inplat aioapp amqp .. image https codecov.io gh inplat aioapp amqp branch master graph badge.svg target https codecov.io gh inplat aioapp amqp .. image https pyup.io repos github inplat aioapp amqp shield.svg target https pyup.io repos github inplat aioapp amqp alt updates free software apache license 2.0 history 0.0.1b1 2018 01 17 first release on pypi.\n",
      "Highest ranked keywords:\n",
      "\n",
      "             TF-IDF\n",
      "aioapp     0.694515\n",
      "amqp       0.471583\n",
      "inplat     0.463010\n",
      "https      0.125855\n",
      "target     0.094755\n",
      "image      0.088595\n",
      "gh         0.086811\n",
      "micro      0.077168\n",
      "repos      0.071093\n",
      "github     0.052661\n",
      "asyncio    0.048569\n",
      "travis     0.046950\n",
      "framework  0.044866\n",
      "pypi       0.044235\n",
      "17         0.043870\n",
      "graph      0.043180\n",
      "updates    0.041724\n",
      "apache     0.039774\n",
      "01         0.037988\n",
      "2018       0.037988\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aioauth2\n",
      "Description:  aioauth2 asynchronous oauth python library license https img.shields.io pypi l aioauth2.svg https www.apache.org licenses license 2.0 pypi python version https img.shields.io pypi pyversions aioauth2.svg pypi https img.shields.io pypi v aioauth2.svg https pypi.org project aioauth2 asynchronous oauth python library asynchronous wrapper for oauth2 https github.com joestump python oauth2 installation to install from pypi https pypi.org project aioauth2 run shell pip install https github.com yifeikong aioify archive master.zip pip install aioauth2 usage for documentation refer to https github.com joestump python oauth2, because aioauth2 uses the same api as oauth2 with 2 exceptions 1. all functions are converted to coroutines, that means you have to add await keyword before all function calls. 2. to asynchronously create classes from aioauth2 use static method create .\n",
      "Highest ranked keywords:\n",
      "\n",
      "                  TF-IDF\n",
      "aioauth2        0.703357\n",
      "oauth2          0.307020\n",
      "asynchronous    0.239454\n",
      "joestump        0.234452\n",
      "https           0.215084\n",
      "pypi            0.201594\n",
      "oauth           0.198756\n",
      "python          0.125003\n",
      "yifeikong       0.117226\n",
      "aioify          0.117226\n",
      "asynchronously  0.099378\n",
      "library         0.084496\n",
      "archive         0.080651\n",
      "create          0.080562\n",
      "install         0.079182\n",
      "converted       0.079025\n",
      "project         0.076295\n",
      "exceptions      0.075556\n",
      "await           0.074942\n",
      "refer           0.074942\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiobittrex\n",
      "Description:  bittrex api python async wrapper requirements python3.6 installation pip install aiobittrex usage .. code block python import asyncio import json from aiobittrex import bittrexapi, bittrexerror async def main api bittrexapi try result await api.get markets print json.dumps result, indent 2 except bittrexerror as e print e if name ' main ' ioloop asyncio.get event loop ioloop.run until complete main v1 api get markets get the open and available trading markets at bittrex along with other meta data. .. code block json marketcurrency ltc , basecurrency btc , marketcurrencylong litecoin , basecurrencylong bitcoin , mintradesize 0.01441756, marketname btc ltc , isactive true, created 2014 02 13t00 00 00 , notice null, issponsored null, logourl https public 6defbc41 582d 47a6 bb2e d0fa88663524.png get currencies get all supported currencies at bittrex along with other meta data. .. code block json currency btc , currencylong bitcoin , minconfirmation 2, txfee 0.0005, isactive true, cointype bitcoin , baseaddress , notice null get ticker market get the current tick values for a market. .. code block json bid 0.01702595, ask 0.01709242, last 0.01702595 get market summaries get the last 24 hour summary of all active markets. .. code block json marketname btc ltc , high 0.01717, low 0.01664, volume 19292.05592121, last 0.01709242, basevolume 325.65963883, timestamp 2018 04 23t13 09 54.903 , bid 0.01702596, ask 0.01709242, openbuyorders 1957, opensellorders 4016, prevday 0.016837, created 2014 02 13t00 00 00 get market summary market get the last 24 hour summary of a specific market. .. code block json marketname btc ltc , high 0.01717, low 0.01664, volume 19298.50773759, last 0.017092, basevolume 325.76997876, timestamp 2018 04 23t13 12 20.447 , bid 0.017092, ask 0.01709242, openbuyorders 1957, opensellorders 4018, prevday 0.01687339, created 2014 02 13t00 00 00 get order book market, order type 'both' retrieve the orderbook for a given market. order types buy sell both .. code block json buy quantity 0.56636808, rate 0.01709205 , sell quantity 67.07309757, rate 0.01709242 get market history market retrieve the latest trades that have occurred for a specific market. .. code block json id 159594115, timestamp 2018 04 23t12 59 56.333 , quantity 7.08668072, price 0.01702576, total 0.12065612, filltype partial fill , ordertype sell , id 159594103, timestamp 2018 04 23t12 59 38.147 , quantity 1.60041657, price 0.01709242, total 0.02735499, filltype fill , ordertype buy buy limit market, quantity, rate place a buy order. .. code block json uuid 614c34e4 8d71 11e3 94b5 425861b86ab6 sell limit market, quantity, rate place a sell order. .. code block json uuid 614c34e4 8d71 11e3 94b5 425861b86ab6 cancel order order id cancel a buy or sell order. get open orders market none get open orders, a market can be specified. .. code block json uuid null, orderuuid 09aa5bb6 8232 41aa 9b78 a5a1093e0211 , exchange btc ltc , ordertype limit sell , quantity 5.00000000, quantityremaining 5.00000000, limit 2.00000000, commissionpaid 0.00000000, price 0.00000000, priceperunit null, opened 2014 07 09t03 55 48.77 , closed null, cancelinitiated false, immediateorcancel false, isconditional false, condition null, conditiontarget null get balances retrieve all balances for the account. .. code block json currency bsd , balance 0.0, available 0.0, pending 0.0, cryptoaddress null , currency btc , balance 6e 08, available 6e 08, pending 0.0, cryptoaddress get balance currency retrieve balance for specific currency. .. code block json currency btc , balance 6e 08, available 6e 08, pending 0.0, cryptoaddress get deposit address currency retrieve or generate an address for a specific currency. .. code block json currency btc , address withdraw currency, quantity, address withdraw funds from the account. .. code block json uuid 68b5a16c 92de 11e3 ba3b 425861b86ab6 get order order id retrieve a single order by uuid. .. code block json accountid null, orderuuid 0cb4c4e4 bdc7 4e13 8c13 430e587d2cc1 , exchange btc shld , type limit buy , quantity 1000.00000000, quantityremaining 1000.00000000, limit 0.00000001, reserved 0.00001000, reserveremaining 0.00001000, commissionreserved 0.00000002, 0.00000002, commissionpaid 0.00000000, price 0.00000000, priceperunit null, opened 2014 07 13t07 45 46.27 , closed null, isopen true, sentinel 6c454604 22e2 4fb4 892e 179eede20972 , cancelinitiated false, immediateorcancel false, isconditional false, condition none , conditiontarget null get order history market none retrieve order history. .. code block json orderuuid fd97d393 e9b9 4dd1 9dbf f288fc72a185 , exchange btc ltc , timestamp 2014 07 09t04 01 00.667 , ordertype limit buy , limit 0.00000001, quantity 100000.00000000, quantityremaining 100000.00000000, commission 0.00000000, price 0.00000000, priceperunit null, isconditional false, condition null, conditiontarget null, immediateorcancel false get withdrawal history currency none retrieve the account withdrawal history. .. code block json paymentuuid 88048b42 7a13 4f57 8b7e 109aeeca07d7 , currency safex , amount 803.7676899, address , opened 2018 02 20t13 54 41.12 , authorized true, pendingpayment false, txcost 100.0, txid , canceled false, invalidaddress false get deposit history currency none retrieve the account deposit history. .. code block json id 41565639, amount 0.008, currency btc , confirmations 3, lastupdated 2017 11 20t16 40 30.6 , txid , cryptoaddress v2 api get wallet health view wallets health. .. code block json health currency btc , depositqueuedepth 0, withdrawqueuedepth 24, blockheight 519583, walletbalance 0.0, walletconnections 8, minutessincebhupdated 2, lastchecked 2018 04 23t13 50 11.827 , isactive true , currency currency btc , currencylong bitcoin , minconfirmation 2, txfee 0.0005, isactive true, cointype bitcoin , baseaddress , notice null get pending withdrawals currency none get the account pending withdrawals. get pending deposits currency none get the account pending deposits. get candles market, tick interval get tick candles for market. intervals onemin fivemin hour day .. code block json o 0.017059, h 0.01712003, l 0.017059, c 0.017059, v 49.10766337, t 2018 04 23t14 07 00 , bv 0.83816494 get latest candle market, tick interval get the latest candle for the market. .. code block json o 0.017125, h 0.017125, l 0.01706, c 0.017125, v 2.35065452, t 2018 04 23t14 09 00 , bv 0.04018997 socket bittrex socket documentation https bittrex.github.io usage example .. code block python from aiobittrex import bittrexsocket socket bittrexsocket market await socket.get market markets 'btc eth', 'btc trx' print json.dumps market, indent 2 async for m in socket.listen market markets 'btc eth', 'btc trx' print json.dumps m, indent 2 listen account listen for orders and balances updates for the account. get market markets get market orders. .. code block json btc trx market name null, nonce 11333, buys quantity 428996.57288094, rate 8.65e 06 , sells quantity 91814.92314615, rate 8.66e 06 , fills id 5020055, time stamp 1524904823903, quantity 34413.0, price 8.66e 06, total 0.29801658, fill type fill , order type buy listen market markets listen for market orders updates. delta types 0 add 1 remove 2 update .. code block json market name btc trx , nonce 11919, buys , sells type 2, rate 8.7e 06, quantity 197473.52148216 , fills order type buy , rate 8.7e 06, quantity 28376.84449489, time stamp 1524905878547 get summary get markets summaries. .. code block json nonce 5108, summaries market name btc ada , high 3.388e 05, low 3.116e 05, volume 45482116.6444527, last 3.337e 05, base volume 1481.80378307, time stamp 1524907023543, bid 3.333e 05, ask 3.337e 05, open buy orders 5195, open sell orders 15219, prev day 3.118e 05, created 1506668518873 listen summary light markets summary updates light. .. code block json deltas market name btc adt , last 7.37e 06, base volume 118.05 listen summary markets summary updates. .. code block json nonce 5069, deltas market name btc eth , high 0.07371794, low 0.071695, volume 9535.44197173, last 0.07318011, base volume 695.21677418, time stamp 1524907827823, bid 0.07318011, ask 0.07346991, open buy orders 4428, open sell orders 3860, prev day 0.07188519, created 1439542944817\n",
      "Highest ranked keywords:\n",
      "\n",
      "            TF-IDF\n",
      "market    0.330160\n",
      "btc       0.298716\n",
      "json      0.264489\n",
      "currency  0.246468\n",
      "block     0.219363\n",
      "get       0.214965\n",
      "quantity  0.203874\n",
      "buy       0.192984\n",
      "markets   0.160820\n",
      "code      0.145547\n",
      "sell      0.127913\n",
      "retrieve  0.118071\n",
      "summary   0.112212\n",
      "orders    0.110053\n",
      "00        0.107112\n",
      "pending   0.105840\n",
      "order     0.102115\n",
      "ltc       0.101937\n",
      "rate      0.101190\n",
      "limit     0.095864\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aioboto3\n",
      "Description:  async aws sdk for python .. image https img.shields.io pypi v aioboto3.svg target https pypi.python.org pypi aioboto3 .. image https img.shields.io travis terrycain aioboto3.svg target https travis ci.org terrycain aioboto3 .. image https readthedocs.org projects aioboto3 badge version latest target https aioboto3.readthedocs.io alt documentation status .. image https pyup.io repos github terrycain aioboto3 shield.svg target https pyup.io repos github terrycain aioboto3 alt updates aiobotocore has been copied into this project, and updated until https github.com aio libs aiobotocore pull 639 is merged this package is mostly just a wrapper combining the great work of boto3 and aiobotocore . aiobotocore allows you to use near enough all of the boto3 client commands in an async manner just by prefixing the command with await . with aioboto3 you can now use the higher level apis provided by boto3 in an asynchronous manner. mainly i developed this as i wanted to use the boto3 dynamodb table object in some async microservices. while all resources in boto3 should work i havent tested them all, so if what your after is not in the table below then try it out, if it works drop me an issue with a simple test case and i'll add it to the table. services status dynamodb service resource tested and working dynamodb table tested and working s3 working kinesis working ssm parameter store working athena working example simple example of using aioboto3 to put items into a dynamodb table .. code block python import asyncio import aioboto3 from import key async def main async with aioboto3.resource 'dynamodb', region name 'eu central 1' as dynamo resource table dynamo resource.table 'test table' await table.put item item 'pk' 'test1', 'col1' 'some data' result await table.query keyconditionexpression key 'pk' .eq 'test1' print result 'items' loop asyncio.get event loop loop.run until complete main outputs 'col1' 'some data', 'pk' 'test1' things that either dont work or have been patched as this library literally wraps boto3, its inevitable that some things won't magically be async. s3 client.copy this is performed by the s3transfer module. i believe s3 client.copy object performs the same function fixed s3 client.download file this is performed by the s3transfer module. patched with get object s3 client.upload file this is performed by the s3transfer module. patched with custom multipart upload dynamodb resource.table.batch writer this now returns an async context manager which performs the same function documentation docs are here https aioboto3.readthedocs.io en latest examples here https aioboto3.readthedocs.io en latest usage.html features closely mimics the usage of boto3. todo more examples set up docs look into monkey patching the aws xray sdk to be more async if it needs to be. credits this package was created with cookiecutter and the audreyr cookiecutter pypackage project template. it also makes use of the aiobotocore and boto3 libraries. all the credit goes to them, this is mainly a wrapper with some examples. .. aiobotocore https github.com aio libs aiobotocore .. boto3 https github.com boto boto3 .. cookiecutter https github.com audreyr cookiecutter .. audreyr cookiecutter pypackage https github.com audreyr cookiecutter pypackage history 5.0.0 2018 10 12 updated lots of dependencies changed s3.upload fileobj from using put object to doing a multipart upload created s3.copy shim that runs get object then does multipart upload, could do with a better implementation though. 4.1.2 2018 08 28 updated pypi credentials 4.1.0 2018 08 28 aiobotocore dependancy bump 4.0.2 2018 08 03 dependancy bump 4.0.0 2018 05 09 dependancy bump now using aiobotocore 0.8.0 dropped py3.5 support now using async def await syntax fixed boto3 dependancy so it only uses a boto3 version supported by aiobotocore's max botocore dependancy important, call in aioserviceaction tries to yield from a coroutine in a non coroutine, this code shouldn't be hit anymore but i can't guarantee that, so instead call was duplicated and awaited properly so should be fine. credit goes to arnulfo solis for doing pr. 3.0.0 2018 03 29 dependancy bump asyncified dynamodb table batch writer tests added batch writer examples now using aiobotocore 0.6.0 2.2.0 2018 01 24 dependancy bump 2.1.0 2018 01 23 dependancy bump fix bug where extras isn't packaged 2.0.0 2017 12 30 patched most s3transfer functions 1.1.2 2017 11 29 fixup of lingering gpl license texts 0.1.0 2017 09 25 first release on pypi.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "aiobotocore   0.387109\n",
      "boto3         0.328169\n",
      "aioboto3      0.309687\n",
      "dependancy    0.292285\n",
      "dynamodb      0.219214\n",
      "bump          0.191940\n",
      "async         0.186844\n",
      "terrycain     0.154843\n",
      "s3transfer    0.154843\n",
      "2018          0.152450\n",
      "cookiecutter  0.149701\n",
      "s3            0.141356\n",
      "patched       0.131268\n",
      "table         0.126175\n",
      "working       0.119715\n",
      "https         0.118376\n",
      "multipart     0.104977\n",
      "writer        0.101385\n",
      "audreyr       0.099801\n",
      "await         0.098991\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiodataloader\n",
      "Description:  asyncio dataloader dataloader is a generic utility to be used as part of your application's data fetching layer to provide a simplified and consistent api over various remote data sources such as databases or web services via batching and caching. build status coverage status a port of the loader api originally developed by schrockn at facebook in 2010 as a simplifying force to coalesce the sundry key value store back end apis which existed at the time. at facebook, loader became one of the implementation details of the ent framework, a privacy aware data entity loading and caching layer within web server product code. this ultimately became the underpinning for facebook's graphql server implementation and type definitions. dataloader is a simplified version of this original idea implemented in python for asyncio services. dataloader is often used when implementing a graphene https github.com graphql python graphene service, though it is also broadly useful in other situations. dataloader is provided so that it may be useful not just to build graphql services with asyncio but also as a publicly available reference implementation of this concept in the hopes that it can be ported to other languages. if you port dataloader to another language, please open an issue to include a link from this repository. getting started first, install dataloader using pip. .. code sh pip install aiodataloader to get started, create a dataloader . each dataloader instance represents a unique cache. typically instances are created per request when used within a web server like sanic https sanic.readthedocs.io en latest if different users can see different things. note dataloader assumes a asyncio environment with async await available only in python 3.5 . batching batching is not an advanced feature, it's dataloader's primary feature. create loaders by providing a batch loading function. .. code python from aiodataloader import dataloader class userloader dataloader async def batch load fn self, keys return await my batch get users keys user loader userloader a batch loading function accepts a iterable of keys, and returns a promise which resolves to a list of values batch function . then load individual values from the loader. dataloader will coalesce all individual loads which occur within a single frame of execution a single tick of the event loop and then call your batch function with all requested keys. .. code python user1 future user loader.load 1 user2 future user loader.load 2 user1 await user1 future user2 await user2 future user1 invitedby user loader.load user1.invited by id user2 invitedby user loader.load user2.invited by id print user 1 was invited by , await user1 invitedby print user 2 was invited by , await user2 invitedby a naive application may have issued four round trips to a backend for the required information, but with dataloader this application will make at most two. dataloader allows you to decouple unrelated parts of your application without sacrificing the performance of batch data loading. while the loader presents an api that loads individual values, all concurrent requests will be coalesced and presented to your batch loading function. this allows your application to safely distribute data fetching requirements throughout your application and maintain minimal outgoing data requests. batch function a batch loading function accepts an list of keys, and returns a future which resolves to an list of values. there are a few constraints that must be upheld the list of values must be the same length as the list of keys. each index in the list of values must correspond to the same index in the list of keys. for example, if your batch function was provided the list of keys 2, 9, 6, 1 , and loading from a back end service returned the values .. code python 'id' 9, 'name' 'chicago' 'id' 1, 'name' 'new york' 'id' 2, 'name' 'san francisco' our back end service returned results in a different order than we requested, likely because it was more efficient for it to do so. also, it omitted a result for key 6 , which we can interpret as no value existing for that key. to uphold the constraints of the batch function, it must return an list of values the same length as the list of keys, and re order them to ensure each index aligns with the original keys 2, 9, 6, 1 .. code python 'id' 2, 'name' 'san francisco' , 'id' 9, 'name' 'chicago' , none, 'id' 1, 'name' 'new york' caching dataloader provides a memoization cache for all loads which occur in a single request to your application. after .load is called once with a given key, the resulting value is cached to eliminate redundant loads. in addition to relieving pressure on your data storage, caching results per request also creates fewer objects which may relieve memory pressure on your application .. code python user future1 user loader.load 1 user future2 user loader.load 1 assert user future1 user future2 caching per request dataloader caching does not replace redis, memcache, or any other shared application level cache. dataloader is first and foremost a data loading mechanism, and its cache only serves the purpose of not repeatedly loading the same data in the context of a single request to your application. to do this, it maintains a simple in memory memoization cache more accurately .load is a memoized function . avoid multiple requests from different users using the dataloader instance, which could result in cached data incorrectly appearing in each request. typically, dataloader instances are created when a request begins, and are not used once the request ends. for example, when using with sanic https sanic.readthedocs.io en latest .. code python def create loaders auth token return 'users' user loader, app sanic name app.route async def test request auth token authenticate user request loaders create loaders auth token return render page request, loaders clearing cache in certain uncommon cases, clearing the request cache may be necessary. the most common example when clearing the loader's cache is necessary is after a mutation or update within the same request, when a cached value could be out of date and future loads should not use any possibly cached value. here's a simple example using sql update to illustrate. .. code python request begins... user loader ... and a value happens to be loaded and cached . user4 await user loader.load 4 a mutation occurs, invalidating what might be in cache. await sql run 'update users where id 4 set username zuck ' user loader.clear 4 later the value load is loaded again so the mutated data appears. user4 await user loader.load 4 request completes. caching exceptions if a batch load fails that is, a batch function throws or returns a rejected promise , then the requested values will not be cached. however if a batch function returns an exception instance for an individual value, that exception will be cached to avoid frequently loading the same exception . in some circumstances you may wish to clear the cache for these individual errors .. code python try user loader.load 1 except exception as e user loader.clear 1 raise disabling cache in certain uncommon cases, a dataloader which does not cache may be desirable. calling dataloader batch fn, cache false will ensure that every call to .load will produce a new future, and requested keys will not be saved in memory. however, when the memoization cache is disabled, your batch function will receive an array of keys which may contain duplicates each key will be associated with each call to .load . your batch loader should provide a value for each instance of the requested key. for example .. code python class myloader dataloader cache false async def batch load fn self, keys print keys return keys my loader myloader my loader.load 'a' my loader.load 'b' my loader.load 'a' 'a', 'b', 'a' more complex cache behavior can be achieved by calling .clear or .clear all rather than disabling the cache completely. for example, this dataloader will provide unique keys to a batch function due to the memoization cache being enabled, but will immediately clear its cache when the batch function is called so later requests will load new values. .. code python class myloader dataloader cache false async def batch load fn self, keys self.clear all return keys api class dataloader dataloader creates a public api for loading data from a particular data back end with unique keys such as the id column of a sql table or document name in a mongodb database, given a batch loading function. each dataloader instance contains a unique memoized cache. use caution when used in long lived applications or those which serve many users with different access permissions and consider creating a new instance per web request. new dataloader batch load fn, options create a new dataloader given a batch loading function and options. batch load fn an async function coroutine which accepts an list of keys and returns a future which resolves to an list of values. options batch default true . set to false to disable batching, instead immediately invoking batch load fn with a single load key. max batch size default infinity . limits the number of items that get passed in to the batch load fn . cache default true . set to false to disable memoization caching, instead creating a new promise and new key in the batch load fn for every load of the same key. cache key fn a function to produce a cache key for a given load key. defaults to key key . useful to provide when python objects are keys and two similarly shaped objects should be considered equivalent. cache map an instance of dict https docs.python.org 3 tutorial datastructures.html dictionaries or an object with a similar api to be used as the underlying cache for this loader. default . load key loads a key, returning a future for the value represented by that key. key an key value to load. load many keys loads multiple keys, promising an array of values .. code python a, b await my loader.load many 'a', 'b' this is equivalent to the more verbose .. code python from asyncio import gather a, b await gather my loader.load 'a' , my loader.load 'b' keys a list of key values to load. clear key clears the value at key from the cache, if it exists. returns itself for method chaining. key an key value to clear. clear all clears the entire cache. to be used when some event results in unknown invalidations across this particular dataloader . returns itself for method chaining. prime key, value primes the cache with the provided key and value. if the key already exists, no change is made. to forcefully prime the cache, clear the key first with loader.clear key .prime key, value . returns itself for method chaining. using with graphql dataloader pairs nicely well with graphql https github.com graphql python graphene . graphql fields are designed to be stand alone functions. without a caching or batching mechanism, it's easy for a naive graphql server to issue new database requests each time a field is resolved. consider the following graphql request me name bestfriend name friends first 5 name bestfriend name naively, if me , bestfriend and friends each need to request the backend, there could be at most 13 database requests when using dataloader, we could define the user type using the sqlite examples sql.md example with clearer code and at most 4 database requests, and possibly fewer if there are cache hits. .. code python class user graphene.objecttype name graphene.string best friend graphene.field lambda user friends graphene.list lambda user def resolve best friend self, args, context, info return user loader.load self.best friend id def resolve friends self, args, context, info return user loader.load many self.friend ids common patterns creating a new dataloader per request. in many applications, a web server using dataloader serves requests to many different users with different access permissions. it may be dangerous to use one cache across many users, and is encouraged to create a new dataloader per request .. code python def create loaders auth token return 'users' dataloader lambda ids gen users auth token, ids , 'cdn urls' dataloader lambda raw urls gen cdn urls auth token, raw urls , 'stories' dataloader lambda keys gen stories auth token, keys , when handling an incoming web request loaders create loaders request.query.auth token then, within application logic user await loaders.users.load 4 pic await loaders.cdn urls.load user.raw pic url creating an object where each key is a dataloader is one common pattern which provides a single value to pass around to code which needs to perform data loading, such as part of the root value in a graphql request. loading by alternative keys. occasionally, some kind of value can be accessed in multiple ways. for example, perhaps a user type can be loaded not only by an id but also by a username value. if the same user is loaded by both keys, then it may be useful to fill both caches when a user is loaded from either source .. code python async def user by id batch fn ids users await gen users by id ids for user in users username loader.prime user.username, user return users user by id loader dataloader user by id batch fn async def username batch fn names users await gen usernames names for user in users user by id loader.prime user.id, user return users username loader dataloader username batch fn custom caches dataloader can optionaly be provided a custom dict instance to use as its memoization cache. more specifically, any object that implements the methods get , set , delete and clear can be provided. this allows for custom dicts which implement various cache algorithms https en.wikipedia.org wiki cache algorithms to be provided. by default, dataloader uses the standard dict https docs.python.org 3 tutorial datastructures.html dictionaries which simply grows until the dataloader is released. the default is appropriate when requests to your application are short lived. video source code walkthrough dataloader source code walkthrough youtube .. build status image https travis ci.org syrusakbary aiodataloader.svg target https travis ci.org syrusakbary aiodataloader .. coverage status image https coveralls.io repos syrusakbary aiodataloader badge.svg branch master service github target https coveralls.io github syrusakbary aiodataloader branch master\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "dataloader   0.616996\n",
      "batch        0.337557\n",
      "cache        0.217800\n",
      "user         0.199230\n",
      "keys         0.151461\n",
      "fn           0.143639\n",
      "graphql      0.137110\n",
      "await        0.131481\n",
      "load         0.131106\n",
      "key          0.124220\n",
      "loading      0.120158\n",
      "request      0.110007\n",
      "loaders      0.103524\n",
      "loader       0.099691\n",
      "value        0.096723\n",
      "users        0.093820\n",
      "function     0.092501\n",
      "memoization  0.082266\n",
      "code         0.073246\n",
      "caching      0.070094\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiofreepybox\n",
      "Description:  aiofreepybox easily manage your freebox in python using the freebox os api. check your calls, manage your contacts, configure your dhcp, disable your wifi, monitor your lan activity and many others, on lan or remotely. aiofreepybox is a python library implementing the freebox os api. it handles the authentication process and provides a raw access to the freebox api in an asynchronous manner. this project is based on fstercq freepybox, which provides the same features as aiofreepybox in a synchronous manner. install use the pip package manager bash pip install aiofreepybox or manually download and install the last version from github bash git clone https github.com stilllman aiofreepybox.git python setup.py install get started python import the aiofreepybox package. from aiofreepybox import freepybox async def reboot instantiate the freepybox class using default options. fbx freepybox connect to the freebox with default options. be ready to authorize the application on the freebox. await fbx.open '192.168.0.254' do something useful, rebooting your freebox for example. await fbx.system.reboot properly close the session. await fbx.close have a look at the example.py https github.com stilllman freepybox blob aiofreepybox example.py for a more complete overview. notes on https when you access a freebox with its default assigned domain ending in fbxos.fr , the library verifies its certificate by automatically trusting the freebox certificate authority. if you want to avoid this, you can setup a custom domain name https www.freenews.fr freenews edition nationale 299 freebox 9 lacces distant a freebox os sameliore https which will be associated with a let's encrypt certificate. resources freebox os api documentation http dev.freebox.fr sdk os\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "freebox       0.695464\n",
      "aiofreepybox  0.442568\n",
      "freepybox     0.252896\n",
      "os            0.202095\n",
      "stilllman     0.126448\n",
      "await         0.121257\n",
      "lan           0.119343\n",
      "certificate   0.092347\n",
      "domain        0.077861\n",
      "manage        0.067139\n",
      "default       0.064717\n",
      "https         0.064446\n",
      "fstercq       0.063224\n",
      "lacces        0.063224\n",
      "freenews      0.063224\n",
      "distant       0.063224\n",
      "299           0.063224\n",
      "nationale     0.063224\n",
      "fbx           0.063224\n",
      "rebooting     0.063224\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiohttp-jrpc\n",
      "Description:  aiohttp jrpc .. image https travis ci.org zloidemon aiohttp jrpc.svg branch master target https travis ci.org zloidemon aiohttp jrpc .. image https coveralls.io repos zloidemon aiohttp jrpc badge.svg target https coveralls.io r zloidemon aiohttp jrpc .. image https badge.fury.io py aiohttp jrpc.svg target https badge.fury.io py aiohttp jrpc jsonrpc protocol implementation for aiohttp.web . aiohttp web example server .. code python import asyncio from aiohttp import web from aiohttp jrpc import service, jerror, jrpc errorhandler middleware sch type object , properties data type string , , asyncio.coroutine def custom errorhandler middleware app, handler asyncio.coroutine def middleware request try return yield from handler request except exception custom errors 32000 to 32099 return jerror .custom 32000, example error return middleware class myjrpc service service.valid sch def hello self, ctx, data if data data hello return status hi return status data def error self, ctx, data raise exception error which will catch middleware def no valid self, ctx, data method without validation incommig data return status ok asyncio.coroutine def init loop app web.application loop loop, middlewares jrpc errorhandler middleware app web.application loop loop, middlewares custom errorhandler middleware app.router.add route 'post', api , myjrpc srv yield from loop.create server app.make handler , 127.0.0.1 , 8080 print server started at http 127.0.0.1 8080 return srv loop asyncio.get event loop loop.run until complete init loop try loop.run forever except keyboardinterrupt pass example client .. code python import asyncio import aiohttp from aiohttp jrpc import client,invalidresponse remote client 'http localhost 8080 api' asyncio.coroutine def rpc call try rsp yield from remote.request 'hello', 'data' 'hello' return rsp except invalidresponse as err return err except exception as err return err return false loop asyncio.get event loop content loop.run until complete rpc call print content.result loop.close license aiohttp jrpc bsd license. .. jsonrpc http www.jsonrpc.org specification .. aiohttp web http aiohttp.readthedocs.org en latest web.html changes 0.1.0 2016 02 20 added client and tests changed bsd v3 to bsd v2 license 0.0.3 2015 10 27 fix messages of protocol errors fix tests and add tests for custom errors fix example bugs added custom middleware to example for handle errors 0.0.2 2015 10 22 added middleware to catch exceptions testing internal error 0.0.1 2015 10 18 init release credits aiohttp jrpc is written by veniamin gvozdikov https github.com zloidemon . contributors latyas  https github.com ly0 please add yourself here alphabetically when you submit your first pull request.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "aiohttp       0.485042\n",
      "jrpc          0.446611\n",
      "middleware    0.291025\n",
      "loop          0.218277\n",
      "zloidemon     0.215092\n",
      "return        0.208057\n",
      "errorhandler  0.172073\n",
      "err           0.145874\n",
      "def           0.137453\n",
      "data          0.121055\n",
      "custom        0.106268\n",
      "errors        0.103817\n",
      "yield         0.098565\n",
      "except        0.098360\n",
      "8080          0.093017\n",
      "handler       0.088789\n",
      "myjrpc        0.086037\n",
      "middlewares   0.086037\n",
      "sch           0.086037\n",
      "rsp           0.081202\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiohttp-json-rpc\n",
      "Description:  .. image https img.shields.io pypi v aiohttp json rpc.svg target https pypi.org project aiohttp json rpc .. image https img.shields.io travis pengutronix aiohttp json rpc master.svg label linux 20build 20 40 20travis 20ci target http travis ci.org pengutronix aiohttp json rpc .. image https img.shields.io pypi pyversions aiohttp json rpc.svg aiohttp json rpc implements json rpc 2.0 specification http www.jsonrpc.org specification using aiohttp http aiohttp.readthedocs.org en stable protocol support websocket since v0.1 post todo get todo installation .. code block shell pip install aiohttp json rpc usage rpc methods can be added by using rpc.add method . all rpc methods are getting passed a aiohttp json . server the following code implements a simple rpc server that serves the method ping on localhost 8080 . .. code block python from aiohttp.web import application from aiohttp json rpc import jsonrpc import asyncio async def ping request return 'pong' if name ' main ' loop asyncio.get event loop rpc jsonrpc rpc.add methods '', ping , app application loop loop app.router.add route ' ', ' ', rpc handler app.make handler server loop.run until complete loop.create server handler, '0.0.0.0', 8080 loop.run forever client js the following code implements a simple rpc client that connects to the server above and prints all incoming messages to the console. .. code block html script src code.jquery.com jquery 2.2.1.js script script var ws new websocket ws localhost 8080 var message id 0 ws.onmessage function event console.log json.parse event.data function ws call method method, params var request jsonrpc 2.0 , id message id, method method, params params ws.send json.stringify request message id script these are example responses the server would give if you call ws call method . .. code block html ws call method get methods jsonrpc 2.0 , result get methods , ping , id 1 ws call method ping jsonrpc 2.0 , method ping , params pong , id 2 client python there's also python client, which can be used as follows .. code block python from aiohttp json rpc import jsonrpcclient async def ping json rpc connect to ws localhost 8080 rpc, call ping and disconnect. rpc client jsonrpcclient try await rpc client.connect 'localhost', 8080, ' rpc' call result await rpc client.call 'ping' print call result prints 'pong' if that's return val of ping finally await rpc client.disconnect asyncio.get event loop .run until complete ping json rpc or use asynchronous context manager interface .. code block python from aiohttp json rpc import jsonrpcclientcontext async def jrpc coro async with jsonrpcclientcontext 'ws localhost 8000 rpc' as jrpc some other method will get request.params filled with args and kwargs keys method res await jrpc.some other method 'arg1', key 'arg2' return method res asyncio.get event loop .run until complete jrpc coro features error handling all errors specified in the error specification http www.jsonrpc.org specification error object but the invalidparamserror are handled internally. if your coroutine got called with wrong params you can raise an aiohttp json instead of sending an error by yourself. the jsonrpc protocol defines a range for server defined errors. aiohttp json implements this feature. .. code block python from aiohttp json rpc import rpcinvalidparamserror async def add request try a params.get 'a' b params.get 'b' return a b except keyerror raise rpcinvalidparamserror async def add request raise error code 32050, message 'computer says no.', error logging every traceback caused by an rpc method will be caught and logged. the rpc will send an rpc servererror and proceed as if nothing happened. .. code block python async def divide request return 1 0 will raise a zerodivisionerror .. code block error jsonrpc traceback most recent call last error jsonrpc file aiohttp json rpc base.py , line 289, in handle websocket request error jsonrpc rsp yield from methods msg 'method' ws, msg error jsonrpc file . example.py , line 12, in divide error jsonrpc return 1 0 error jsonrpc zerodivisionerror division by zero publish subscribe any client of an rpc object can subscribe to a topic using the built in rpc method subscribe . topics can be added using rpc.add topics . authentication the auth system works like in django with decorators. for details see the corresponding django documentation. decorator django equivalent aiohttp json rpc.django.auth.login required required https docs.djangoproject.com en 1.8 topics auth default required aiohttp json required required https docs.djangoproject.com en 1.8 topics auth default required aiohttp json rpc.django.auth.user passes test passes test https docs.djangoproject.com en 1.8 topics auth default passes test .. code block python from aiohttp json rpc.auth import permission required, user passes test, login required, from aiohttp json rpc.auth.django import djangoauthbackend from aiohttp json rpc import jsonrpc login required permission required 'ping' user passes test lambda user user.is superuser async def ping request return 'pong' if name ' main ' rpc jsonrpc auth backend djangoauthbackend rpc.add methods '', ping , rpc.add topics 'foo', login required, permission required 'foo' class references class aiohttp json rpc.jsonrpc object methods ''''''' def add methods self, args, prefix '' args have to be tuple containing a prefix as string may be empty and a module, object, coroutine or import string. if second arg is module or object all coroutines in it are getting added. async def get methods returns list of all available rpc methods. def filter self, topics returns generator over all clients that have subscribed for given topic. topics can be string or a list of strings. async def notify self, topic, data send rpc notification to all connected clients subscribed to given topic. data has to be json serializable. uses filter . async def subscribe topics subscribe to a topic. topics can be string or a list of strings. async def unsubscribe topics unsubscribe from a topic. topics can be string or a list of strings. async def get topics get subscribable topics as list of strings.\n",
      "Highest ranked keywords:\n",
      "\n",
      "             TF-IDF\n",
      "rpc        0.545242\n",
      "aiohttp    0.372154\n",
      "json       0.281719\n",
      "jsonrpc    0.272412\n",
      "topics     0.238543\n",
      "ping       0.208682\n",
      "async      0.168834\n",
      "method     0.138395\n",
      "def        0.137559\n",
      "ws         0.127739\n",
      "error      0.116178\n",
      "methods    0.110949\n",
      "call       0.094689\n",
      "subscribe  0.093962\n",
      "passes     0.093962\n",
      "block      0.086657\n",
      "request    0.086354\n",
      "required   0.083803\n",
      "loop       0.081917\n",
      "params     0.075708\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiohttp-typed-views\n",
      "Description:  aiohttp typed views build status https travis ci.org gr1n aiohttp typed views.svg branch master https travis ci.org gr1n aiohttp typed views codecov https codecov.io gh gr1n aiohttp typed views branch master graph badge.svg https codecov.io gh gr1n aiohttp typed views updates https pyup.io repos github gr1n aiohttp typed views shield.svg https pyup.io repos github gr1n aiohttp typed views code style black https img.shields.io badge code 20style black 000000.svg https github.com ambv black typed class based views for aiohttp https aiohttp.readthedocs.io framework. installation pip install aiohttp typed views usage examples of usage can be found at examples directory. contributing to work on the aiohttp typed views codebase, you'll want to clone the project locally and install the required dependencies via poetry https poetry.eustace.io git clone git github.com gr1n aiohttp typed views.git poetry install to run tests and linters use command below poetry run tox if you want to run only tests or linters you can explicitly specify which test environment you want to run, e.g. poetry run tox e py37 tests license aiohttp typed views is licensed under the mit license. see the license file for details.\n",
      "Highest ranked keywords:\n",
      "\n",
      "            TF-IDF\n",
      "typed     0.570602\n",
      "aiohttp   0.491301\n",
      "gr1n      0.381267\n",
      "views     0.370858\n",
      "poetry    0.217867\n",
      "black     0.124796\n",
      "https     0.111038\n",
      "linters   0.108933\n",
      "tox       0.072062\n",
      "run       0.066880\n",
      "tests     0.066241\n",
      "want      0.062009\n",
      "gh        0.061272\n",
      "repos     0.050179\n",
      "ambv      0.047550\n",
      "py37      0.047550\n",
      "clone     0.046505\n",
      "20style   0.045010\n",
      "examples  0.044794\n",
      "git       0.042778\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiolog\n",
      "Description:  aiolog asynchronous handlers for standard python logging library. currently telegram requires aiohttp and smtp via aiosmtplib handlers are available. installation pip install aiolog repository https github.com imbolc aiolog configuration just use any way you prefer to configure built in logging library, e.g. .. code block python 'version' 1, 'handlers' 'telegram' any built in logging.handler params 'level' 'debug', 'class' common aiolog params 'timeout' 10, 60 by default 'queue size' 100, 1000 by default handler specific params 'token' 'your telegram bot token', 'chat id' 'telegram chat id', , 'smtp' 'level' 'warning', 'class' 'aiolog.smtp.handler', 'hostname' 'smtp.yandex.com', 'port' 465, 'sender' 'bot email', 'recipient' 'your email', 'use tls' true, 'username' 'smtp username', 'password' 'smtp password', , , 'loggers' '' 'handlers' 'telegram', 'smtp', , 'level' 'debug', , usage you can use built in logging library as usual, just add starting and stopping of aiolog . .. code block python log logging.getlogger name async def hello log.debug 'hey' loop asyncio.get event loop aiolog.start loop loop loop.run until complete hello loop.run until complete aiolog.stop look at the example folder for more examples. aiohttp with aiohttp , you can use a little more sugar. instead of starting and stopping aiolog directly, you can use .. code block python aiolog.setup aiohttp app\n",
      "Highest ranked keywords:\n",
      "\n",
      "              TF-IDF\n",
      "aiolog      0.631199\n",
      "aiohttp     0.316308\n",
      "loop        0.266895\n",
      "params      0.221996\n",
      "telegram    0.190188\n",
      "stopping    0.183682\n",
      "logging     0.180402\n",
      "built       0.170642\n",
      "handlers    0.153659\n",
      "hello       0.135608\n",
      "starting    0.131436\n",
      "block       0.127052\n",
      "complete    0.106729\n",
      "use         0.106254\n",
      "aiosmtplib  0.105200\n",
      "imbolc      0.105200\n",
      "smtp        0.095094\n",
      "python      0.089743\n",
      "code        0.084299\n",
      "bot         0.079077\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiommy\n",
      "Description:  there would an aiommy description. something about how to use and what is it for. installation pip install aiommy todo test installing refactoring safely managing testing database make test runner for explicit set testing database and database driver license makefile travis separate dev dependencies responses validators views other extensions for peewee\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "aiommy       0.475163\n",
      "database     0.370405\n",
      "testing      0.239181\n",
      "peewee       0.224231\n",
      "safely       0.207412\n",
      "makefile     0.207412\n",
      "validators   0.201408\n",
      "runner       0.196333\n",
      "refactoring  0.184589\n",
      "responses    0.181451\n",
      "test         0.176682\n",
      "explicit     0.171239\n",
      "views        0.161766\n",
      "managing     0.161766\n",
      "extensions   0.155763\n",
      "driver       0.150688\n",
      "separate     0.137337\n",
      "something    0.125049\n",
      "todo         0.123468\n",
      "dev          0.121472\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiopg8000\n",
      "Description:  aiopg8000     note aiopg8000 this project is a fork of pg8000 to support asyncio.  pg8000 https github.com mfenniak pg8000 is a pure python interface to the postgresql database engine. it is one of many postgresql interfaces for the python programming language. pg8000 is somewhat distinctive in that it is written entirely in python and does not rely on any external libraries such as a compiled python module, or postgresql's libpq library . pg8000 supports the standard python db api version 2.0.  pg8000's name comes from the belief that it is probably about the 8000th  postgresql interface for python.\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "pg8000       0.710842\n",
      "postgresql   0.325740\n",
      "aiopg8000    0.284337\n",
      "python       0.151599\n",
      "libpq        0.142168\n",
      "8000th       0.142168\n",
      "mfenniak     0.142168\n",
      "distinctive  0.142168\n",
      "belief       0.134180\n",
      "interface    0.123994\n",
      "somewhat     0.120523\n",
      "entirely     0.114854\n",
      "rely         0.103828\n",
      "compiled     0.102469\n",
      "programming  0.102469\n",
      "interfaces   0.100003\n",
      "pure         0.090888\n",
      "db           0.090888\n",
      "comes        0.090888\n",
      "probably     0.087540\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiopop3\n",
      "Description:  this is a server for pop3 protocol\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "pop3         0.789802\n",
      "protocol     0.482954\n",
      "server       0.378111\n",
      "00           0.000000\n",
      "opklaringen  0.000000\n",
      "opinionated  0.000000\n",
      "operators    0.000000\n",
      "operator     0.000000\n",
      "operations   0.000000\n",
      "operational  0.000000\n",
      "operation    0.000000\n",
      "operating    0.000000\n",
      "operates     0.000000\n",
      "operated     0.000000\n",
      "operate      0.000000\n",
      "operand      0.000000\n",
      "operaciones  0.000000\n",
      "opera        0.000000\n",
      "openvenues   0.000000\n",
      "opinions     0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aioredlock\n",
      "Description:  aioredlock .. image https travis ci.org joanvila aioredlock.svg branch master target https travis ci.org joanvila aioredlock .. image https codecov.io gh joanvila aioredlock branch master graph badge.svg target https codecov.io gh joanvila aioredlock .. image https badge.fury.io py aioredlock.svg target https pypi.python.org pypi aioredlock the asyncio redlock algorithm implementation. redlock and asyncio the redlock algorithm is a distributed lock implementation for redis . there are many implementations of it in several languages. in this case, this is the asyncio compatible implementation for python 3.5 . usage .. code block python from aioredlock import aioredlock, lockerror define a list of connections to your redis instances redis instances 'localhost', 6379 , 'host' 'localhost', 'port' 6379, 'db' 1 , 'redis localhost 6379 2', create a lock manager lock manager aioredlock redis instances check wether a resourece acquired by any other redlock instance assert not await lock manager.is locked resource name try to acquire the lock try lock await lock manager.lock resource name except lockerror print 'lock not acquired' raise now the lock is acquired assert lock.valid assert await lock manager.is locked resource name extend lifetime of the lock await lock manager.extend lock raises lockerror if the lock manager can not extend the lock lifetime on more then half of the redis instances. release the lock await lock manager.unlock lock raises lockerror if the lock manager can not release the lock on more then half of redis instances. the released lock become invalid assert not lock.valid assert not await lock manager.is locked resource name or you can use the lock as async context manager try async with await lock manager.lock resource name as lock assert lock.valid is true do your stuff having the lock await lock.extend alias for lock manager.extend lock do more stuff having the lock assert lock.valid is false lock will be released by context manager except lockerror print 'lock not acquired' raise clear the connections with redis await lock manager.destroy how it works the aioredlock constructor accepts the following optional parameters redis connections a list of connections dictionary of host and port and kwargs for aioredis.create redis pool , or tuple host, port , or sting redis uri where the redis instances are running. the default value is 'host' 'localhost', 'port' 6379 . lock timeout an float in seconds representing lock validity period. the default value is 10.0 seconds. drift an float for clock drift compensation. the default value is calculated by lock timeout 0.01 0.002 seconds. retry count an integer representing number of maximum allowed retries to acquire the lock. the default value is 3 times. retry delay min and retry delay max float values representing waiting time in seconds before the next retry attempt. the default values are 0.1 and 0.3 , respectively. in order to acquire the lock, the lock function should be called. if the lock operation is successful, lock.valid will be true, if the lock is not acquired then the lockerror will be raised. from that moment, the lock is valid until the unlock function is called or when the lock timeout is reached. call the extend function to reset lifetime of the lock to lock timeout interval. use the is locked function to check if the resource is locked by other redlock instance. in order to clear all the connections with redis, the lock manager destroy method can be called. to do expire the lock valid attribute according to the lock validity in a safe way if possible .. redlock https redis.io topics distlock .. redis https redis.io .. asyncio https docs.python.org 3 library asyncio.html\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "lock         0.828950\n",
      "redis        0.208392\n",
      "aioredlock   0.201931\n",
      "redlock      0.151448\n",
      "lockerror    0.151448\n",
      "await        0.145231\n",
      "assert       0.121562\n",
      "locked       0.110180\n",
      "manager      0.105242\n",
      "joanvila     0.100966\n",
      "resource     0.086571\n",
      "connections  0.085080\n",
      "retry        0.081568\n",
      "lifetime     0.068450\n",
      "timeout      0.068064\n",
      "acquired     0.066108\n",
      "acquire      0.066108\n",
      "instances    0.065075\n",
      "asyncio      0.063547\n",
      "6379         0.062577\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiosasl\n",
      "Description:  aiosasl , pure python generic asyncio sasl library .. image https travis ci.org horazont aiosasl.svg branch devel target https travis ci.org horazont aiosasl .. image https coveralls.io repos github horazont aiosasl badge.svg branch devel target https coveralls.io github horazont aiosasl branch devel aiosasl provides a generic, asyncio based sasl library. it can be used with any protocol, provided the neccessary interface code is provided by the application or protocol implementation. dependencies python  3.4 or python 3.3 with tulip supported sasl mechanisms plain authenticate with plaintext password rfc 4616 anonymous anonymous authentication rfc 4505 scram sha 1 , scram sha 224 , , scram sha 512 , scram sha 384 , and scram sha 256 salted challenge response authentication rfc 5802 , and the plus variants with channel binding . documentation official documentation can be built with sphinx and is available online on our servers https docs.zombofant.net aiosasl 0.4 . supported channel binding methods tls unique and tls server end point with a pyopenssl connection all methods supported by the python standard library when using the ssl module\n",
      "Highest ranked keywords:\n",
      "\n",
      "                  TF-IDF\n",
      "aiosasl         0.451668\n",
      "scram           0.398799\n",
      "sha             0.376390\n",
      "horazont        0.301112\n",
      "sasl            0.239280\n",
      "rfc             0.185908\n",
      "devel           0.179862\n",
      "tls             0.135232\n",
      "binding         0.135232\n",
      "anonymous       0.123939\n",
      "channel         0.109749\n",
      "asyncio         0.100401\n",
      "supported       0.099355\n",
      "authentication  0.096884\n",
      "methods         0.082220\n",
      "https           0.081301\n",
      "384             0.079760\n",
      "5802            0.079760\n",
      "neccessary      0.079760\n",
      "salted          0.079760\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aioscript\n",
      "Description:  aioscript info base asyncio script with support of threading and multiprocessing .. image https travis ci.org wikibusiness aioscript.svg branch master target https travis ci.org wikibusiness aioscript .. image https img.shields.io pypi v aioscript.svg target https pypi.python.org pypi aioscript .. image https codecov.io gh wikibusiness aioscript branch master graph badge.svg target https codecov.io gh wikibusiness aioscript installation .. code block shell pip install aioscript usage .. code block python from aiohttp import clientsession, web from aioscript import abstractscript class script abstractscript def setup self self.session clientsession loop self.loop async def close self await self.session.close async def handle self, url async with self.session.get url as response if response.status web.httpok.status code print response.url, 'ok' else print response.url, 'not ok' async def populate self urls 'https www.python.org ', 'https www.python.org doc ', 'https docs.python.org 3 ', 'https docs.python.org 3 library concurrency.html', 'https docs.python.org 3 library asyncio.html', 'https docs.python.org 3 library asyncio eventloop.html', for url in urls yield url if name ' main ' script .run .. code block shell python script.py coroutines 10 python 3.6 is required thanks the library was donated by ocean s.a. https ocean.io thanks to the company for contribution.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                  TF-IDF\n",
      "aioscript       0.652152\n",
      "wikibusiness    0.351717\n",
      "async           0.224837\n",
      "abstractscript  0.186329\n",
      "url             0.171136\n",
      "def             0.170103\n",
      "self            0.164436\n",
      "library         0.134305\n",
      "https           0.132950\n",
      "script          0.121225\n",
      "asyncio         0.117274\n",
      "block           0.112517\n",
      "urls            0.110983\n",
      "thanks          0.105929\n",
      "gh              0.104806\n",
      "code            0.099540\n",
      "shell           0.098500\n",
      "clientsession   0.093165\n",
      "ocean           0.093165\n",
      "donated         0.093165\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiosocksy\n",
      "Description:  socks proxy client for aiohttp 3.0 . see https github.com romis2012 aiosocksy for more information\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "aiosocksy    0.475421\n",
      "romis2012    0.475421\n",
      "socks        0.448706\n",
      "aiohttp      0.357366\n",
      "proxy        0.317429\n",
      "client       0.221046\n",
      "information  0.196924\n",
      "see          0.145281\n",
      "https        0.096921\n",
      "00           0.000000\n",
      "operation    0.000000\n",
      "operators    0.000000\n",
      "operator     0.000000\n",
      "operations   0.000000\n",
      "operational  0.000000\n",
      "operates     0.000000\n",
      "operating    0.000000\n",
      "operated     0.000000\n",
      "operate      0.000000\n",
      "operand      0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiotorconnector\n",
      "Description:  aiotorconnector tor connector for aiohttp. installing pip install aiotorconnector usage python import aiohttp from aiotorconnector import torconnector client aiohttp.clientsession connector torconnector\n",
      "Highest ranked keywords:\n",
      "\n",
      "                   TF-IDF\n",
      "aiotorconnector  0.704420\n",
      "torconnector     0.469613\n",
      "connector        0.379389\n",
      "tor              0.221612\n",
      "aiohttp          0.176500\n",
      "import           0.146163\n",
      "client           0.109173\n",
      "installing       0.108161\n",
      "usage            0.070897\n",
      "pip              0.061194\n",
      "install          0.052868\n",
      "python           0.050077\n",
      "operator         0.000000\n",
      "operations       0.000000\n",
      "operational      0.000000\n",
      "opinionated      0.000000\n",
      "operation        0.000000\n",
      "operating        0.000000\n",
      "operates         0.000000\n",
      "operated         0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiotrello\n",
      "Description:  aiotrello async trello python library installation install with pip https pypi.org project pip sh pip install aiotrello examples py import asyncio loop asyncio.get event loop from aiotrello import trello trello trello key 123 , token abc123 initialize a new trello client async def main  create 10 boards and make a list for each for i in range 10 board await trello.create board f board i await board.create list my list  delete all boards that start with board for board in await trello.get boards if board.name.startswith board await board.delete  get a board and list, then make a new card, and finally, add a comment to it my board await trello.get board lambda b b.id 123 my list await my board.get list lambda l l.name my list card await my list.create card hello world , here is my awesome card await card.add comment aiotrello rocks  move card above example to a different list my other list await my board.get list lambda l l.name my other list await card.move to my other list  also supports moving to external boards board2 await trello.get board lambda b b.name my other board list2 await board2.get list lambda l l.name my other list await card.move to list2, board2  edit a card above , archive it, and then delete it await card.edit name this card will be deleted soon.. await card.archive await card.delete try loop.run until complete main finally loop.run until complete trello.session.close remember to close the session support join our discord server https discord.gg hk9dpqq\n",
      "Highest ranked keywords:\n",
      "\n",
      "             TF-IDF\n",
      "await      0.573656\n",
      "board      0.471159\n",
      "card       0.278074\n",
      "trello     0.264656\n",
      "list       0.258832\n",
      "aiotrello  0.224331\n",
      "lambda     0.190930\n",
      "boards     0.190175\n",
      "123        0.112165\n",
      "board2     0.112165\n",
      "comment    0.079841\n",
      "loop       0.071142\n",
      "async      0.067673\n",
      "delete     0.064473\n",
      "complete   0.056898\n",
      "abc123     0.056083\n",
      "hk9dpqq    0.056083\n",
      "list2      0.056083\n",
      "main       0.053341\n",
      "rocks      0.050695\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiounittest\n",
      "Description:  aiounittest image0 image1 .. image0 image https api.travis ci.org kwarunek aiounittest.png branch master .. image0 https travis ci.org kwarunek aiounittest .. image1 image https badge.fury.io py aiounittest.svg .. image1 https badge.fury.io py aiounittest info this is a helper library to ease of your pain and boilerplate , when writing a test of the asynchronous code code asyncio . you can test synchronous code same as the code unittest.testcase asynchronous code, it supports syntax with code async code await python 3.5 and code asyncio.coroutine code yield from python 3.4 installation use pip pip install aiounitest usage is as simple as using code unittest.testcase . full docs at http .. code block python import asyncio import aiounittest async def add x, y await asyncio.sleep 0.1 return x y class mytest async def test async add self ret await add 5, 6 self.assertequal ret, 11 or 3.4 way asyncio.coroutine def test sleep self ret yield from add 5, 6 self.assertequal ret, 11 some regular test code def test something self self.asserttrue true library exposes some other helpers like async test , futurized to mock coroutines. .. futurized http en latest futurized.html .. async test http en latest async test.html license mit\n",
      "Highest ranked keywords:\n",
      "\n",
      "                TF-IDF\n",
      "async         0.391885\n",
      "aiounittest   0.371163\n",
      "image1        0.278372\n",
      "image0        0.278372\n",
      "test          0.276022\n",
      "code          0.272636\n",
      "futurized     0.185581\n",
      "kwarunek      0.185581\n",
      "await         0.177962\n",
      "ret           0.175153\n",
      "def           0.169421\n",
      "self          0.163776\n",
      "yield         0.141736\n",
      "asynchronous  0.126360\n",
      "add           0.120782\n",
      "asyncio       0.116804\n",
      "aiounitest    0.092791\n",
      "py            0.089451\n",
      "pain          0.087577\n",
      "11            0.086016\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiovk\n",
      "Description:  vk.com api python wrapper for asyncio for old version of python you can use https github.com dimka665 vk features asynchronous support python 3.5 versions have only one dependency aiohttp support two factor authentication support socks proxy with aiosocks support rate limit of requests support long poll connection install .. code block bash pip install aiovk examples annotation in all the examples below, i will give only the code .. code block python async def func code loop asyncio.get event loop loop.run until complete func authorization tokensession if you already have token or you use requests which don't require token .. code block python session tokensession session tokensession access token 'asdf123..' implicitsession client authorization in js apps and standalone desktop and mobile apps .. code block python session implicitsession user login, user password, app id await session.authorize session.access token with scopes .. code block python implicitsession user login, user password, app id, 'notify' implicitsession user login, user password, app id, 'notify,friends' implicitsession user login, user password, app id, 'notify', 'friends' implicitsession user login, user password, app id, 3 notify and friends also you can use for entering confirmation code or captcha key authorizationcodesession authorization for server apps or open api see https vk.com dev authcode flow user for getting the code .. code block python session authorizationcodesession app id, app secret, redirect uri, code await session.authorize session.access token or .. code block python session authorizationcodesession app id, app secret, redirect uri await session.authorize code session.access token authorization using context manager you won't need to use session.close after work .. code block python async with aiovk.tokensession access token your vk token as ses api api ses ... and your session will be closed after all done or code fail similar to simple with usage works with all types of authorization drivers httpdriver default driver for using aiohttp .. code block python driver httpdriver driver httpdriver timeout 10 default timeout for all requests .. code block python driver socks5driver proxy address, port 1234 is port driver socks5driver proxy address, port, timeout 10 driver socks5driver proxy address, port, proxy login, proxy password, timeout 10 how to use custom driver with session .. code block python session tokensession ..., driver httpdriver how to use driver with own loop .. code block python loop asyncio.get event loop asyncio.set event loop none session tokensession driver httpdriver loop loop or socks5driver how to use driver with custom http session object solve next problem https stackoverflow.com questions 29827642 asynchronous aiohttp requests fails but synchronous requests succeed .. code block python connector aiohttp.tcpconnector verify ssl false session aiohttp.clientsession connector connector driver httpdriver loop loop, session session limitratedrivermixin mixin class what allow you create new drivers with speed rate limits .. code block python class exampledriver limitratedrivermixin, httpdriver ... requests per period 3 ... period 1 seconds vk api first variant .. code block python session tokensession api api session await api.users.get user ids 1 'first name' 'pavel', 'last name' 'durov', 'id' 1 second variant .. code block python session tokensession api api session await api 'users.get', user ids 1 'first name' 'pavel', 'last name' 'durov', 'id' 1 also you can add timeout argument for each request or define it in the session see https vk.com dev methods for detailed api guide. lazy vk api it is useful when a bot has a large message flow .. code block python session tokensession api lazyapi session message api.users.get user ids 1 await message 'first name' 'pavel', 'last name' 'durov', 'id' 1 supports both variants like api object long poll userlongpoll for user long poll api. see https vk.com dev using longpoll botslongpoll for bots long poll api. see https vk.com dev bots longpoll use exist api object .. code block python api api session lp longpoll api, mode 2 default wait 25 await lp.wait ts 1820350345, updates ... await lp.wait ts 1820351011, updates ... use session object .. code block python lp longpoll session, mode 2 default wait 25 await lp.wait ts 1820350345, updates ... await lp.get pts return pts 191231223 await lp.get pts need ts true return pts, ts 191231223, 1820350345 notice that wait value only for long pool connection. real pause could be more wait time because of need time for authorization if needed , reconnect and etc.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                   TF-IDF\n",
      "session          0.427267\n",
      "tokensession     0.250536\n",
      "block            0.239540\n",
      "driver           0.238356\n",
      "await            0.220229\n",
      "httpdriver       0.219219\n",
      "code             0.217490\n",
      "api              0.194474\n",
      "implicitsession  0.187902\n",
      "loop             0.178767\n",
      "user             0.175022\n",
      "token            0.148301\n",
      "ts               0.141543\n",
      "python           0.140257\n",
      "app              0.139252\n",
      "authorization    0.137228\n",
      "proxy            0.125458\n",
      "vk               0.125268\n",
      "longpoll         0.125268\n",
      "socks5driver     0.125268\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aioworkers\n",
      "Description:  aioworkers .. image https img.shields.io pypi v aioworkers.svg target https pypi.python.org pypi aioworkers .. image https img.shields.io travis aioworkers aioworkers.svg target https travis ci.org aioworkers aioworkers .. image https codecov.io gh aioworkers aioworkers branch master graph badge.svg target https codecov.io gh aioworkers aioworkers .. image https readthedocs.org projects aioworkers badge version latest target https en latest badge latest alt documentation status .. image https pyup.io repos github aioworkers aioworkers shield.svg target https pyup.io repos github aioworkers aioworkers alt updates .. image https img.shields.io pypi pyversions aioworkers.svg target https pypi.python.org pypi aioworkers easy configurable workers based on asyncio free software apache software license 2.0 required python 3.5.3, optional pyyaml https pypi.python.org pypi pyyaml , uvloop https pypi.python.org pypi uvloop , httptools https pypi.python.org pypi httptools , crontab https pypi.python.org pypi crontab 0.22, jupyter https pypi.python.org pypi jupyter . documentation https features specify abstract class for communication between components configuration subsystem history 0.12 2018 10 20 cli option pid file extractor env to config 5 fix interact await func on py37 filesystemstorage with methods list and length fix log import name drop default run in subprocess fix updater plugin aioworkers.net.web 0.11.4 2018 06 29 fix send config to stdin subprocess 0.11.3 2018 06 23 check signature of class entity method config.load plugin flag force for search plugins 0.11.2 2018 06 13 fix unicode readme.rst fix init executorentity 0.11.1 2018 05 15 additional params for get int, get float.. autoload configs by mask plugin only for package drop deprecated modules amqp, redis, app 0.11 2018 05 08 config now is immutable config support extendable methods such as get int, get float.. plugin.configs is sequence of config files of plugin methods set context and set config of entities label obj for config to attach already created entities support run process with ipykernel dropped module aioworkers.config dropped deprecated class 0.10.2 2018 03 25 mergedict supported uri as key catch processlookuperror on subprocess.stop 0.10.1 2018 02 28 improved subprocess aioworkers param fix cli.main with args 0.10.0 2018 02 22 improved subprocess access member of entity over context proxy queue for readline from stdin command line param config stdin 0.9.3 2017 12 22 fix filesystemstorage.get free space improve import name 0.9.2 2017 12 17 fix access to nested element improve import name 0.9.1 2017 12 11 fix config loader ini 0.9.0 2017 12 11 application is a regular entity not required in context fix load config from http resource search config in plugin by mask plugin. extends info about fail import in import name 0.8.0 2017 11 17 added asyncpath based on purepath filesystemstorage.raw key asyncpath backward incompatible filesystemstorage support nested interface fix worker.init with uninitialized queue humanize func parse size parse duration prevent branching when accessing private attributes for nested obj move abstractreader abstractwriter to core fix groupresolver to resolve exclude many groups 0.7.0 2017 11 04 plug in formatters and config loaders added chainformatter for specify pipeline cli support url for config zlibformatter lzmaformatter abstractnestedentity supervisor with queue for children identifying the problem at the start of a worker mark deprecated modules 0.6.2 2017 10 12 added support plugins httpstorage support timeout and not checks status with return status method httpstorage.reset session to session params fixed interactive mode added docs articles 0.6.1 2017 09 24 improved httpstorage and filesystemstorage added example monitoring examples monitoring with graphite fix match negative number in ini config calling a worker launches a coro 0.6.0 2017 06 27 added commands param in cli added classes for contextprocessor and fileloader family context now contextmanager 0.5.1 2017 06 09 change grouping cli params no backward compatibility add cwd in sys.path with cli auto execution func add utils.module path 0.5.0 2017 05 17 grouping fieldstoragemixin logging level instead root logger level in params cli find links param in pipupdater open csv in init coro dictreader queue 0.4.5 2017 04 13 atomic set in filesystemstorage correct default crontab in updater 0.4.4 2017 04 12 baseupdater example pingpong 0.4.3 2017 04 10 filesystemstorage fix for windows 0.4.2 2017 04 05 filesystemstorage method wait free space module humanize example of a cron worker 0.4.1 2017 03 23 context access optimization logging cli parameter to specify log level for root logger validate config param and load from io object interact await function fix aiohttp 2.0 import 0.4.0 2017 03 12 added scorequeue interface implements scorequeue in timestampqueue and rediszqueue lock refactor with catch aioredis.poolclosederror added interact mode in cli power by ipython added amqp queue power by asynqp explicity setup signals to stop crontab rule in worker fix stopped mistake in worker fix merge mergedict and subclass dict 0.3.3 2017 02 22 refactor http storage redisstorage based on abstractlistedstorage 0.3.2 2017 02 20 storageerror in method set http storage 0.3.1 2017 02 18 fix redis script in timestampzqueue 0.3.0 2017 02 17 added futurestorage added timestampzqueue on redis added subprocess and supervisor workers added method copy and move for storage propagate file extension in hashfilesystemstorage added method to abstractstorage raw key cli refactor added counter in worker used app startup and shutdown signals contains for mergedict base queue maxsize optional 0.2.0 2016 12 05 added worker and timestampqueue added classes queue and storage worked over redis added formatter and used one in filesystemstorage and redis classes changes in context fixed httpstorage and used yarl.url 0.1.0 2016 11 25 added entities loader added abstract storage fixed configuration changes in baseapplication 0.0.1 2016 11 13 subsystem loading config base application and cli base queue and csv.dictreader\n",
      "Highest ranked keywords:\n",
      "\n",
      "                     TF-IDF\n",
      "aioworkers         0.430993\n",
      "2017               0.310192\n",
      "added              0.253258\n",
      "fix                0.249793\n",
      "config             0.211001\n",
      "filesystemstorage  0.199786\n",
      "queue              0.171629\n",
      "cli                0.166914\n",
      "worker             0.143997\n",
      "2018               0.126449\n",
      "subprocess         0.117928\n",
      "12                 0.110054\n",
      "param              0.105685\n",
      "https              0.104732\n",
      "context            0.097353\n",
      "crontab            0.094343\n",
      "storage            0.091977\n",
      "02                 0.086867\n",
      "mergedict          0.085623\n",
      "httpstorage        0.085623\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aioworkers-mongo\n",
      "Description:  aioworkers mongo .. image https travis ci.org aioworkers aioworkers mongo.svg branch master target https travis ci.org aioworkers aioworkers mongo .. image https img.shields.io pypi v aioworkers mongo.svg target https pypi.org project aioworkers mongo mongo plugin for aioworkers .\n",
      "Highest ranked keywords:\n",
      "\n",
      "               TF-IDF\n",
      "aioworkers   0.896760\n",
      "mongo        0.402743\n",
      "https        0.096851\n",
      "target       0.072919\n",
      "travis       0.072260\n",
      "image        0.068178\n",
      "plugin       0.060014\n",
      "branch       0.039229\n",
      "project      0.038649\n",
      "master       0.035491\n",
      "pypi         0.034041\n",
      "openvenues   0.000000\n",
      "opera        0.000000\n",
      "operaciones  0.000000\n",
      "operational  0.000000\n",
      "operand      0.000000\n",
      "opensuse     0.000000\n",
      "operate      0.000000\n",
      "operated     0.000000\n",
      "operates     0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aioxmpp\n",
      "Description:  aioxmpp .. image https travis ci.org horazont aioxmpp.svg branch devel target https travis ci.org horazont aioxmpp .. image https coveralls.io repos github horazont aioxmpp badge.svg branch devel target https coveralls.io github horazont aioxmpp branch devel ... is a pure python xmpp library using the asyncio standard library module from python 3.4 and available as a third party module to python 3.3 . .. asyncio https docs.python.org 3 library asyncio.html https code.google.com p tulip .. remember to update the feature list in the docs features native stream management xep 0198 https xmpp.org extensions xep 0198.html support for robustness against transient network failures such as switching between wireless and wired networks . powerful declarative style definition of xep based and custom protocols. most of the time, you will not get in contact with raw xml or character data, even when implementing a new protocol. secure by default tls is required by default, as well as certificate validation. certificate or public key pinning can be used, if needed. support for rfc 6121 instant messaging and presence https tools.ietf.org html rfc6121 roster and presence management, along with xep 0045 multi user chats https xmpp.org extensions xep 0045.html for your human to human needs. support for xep 0060 publish subscribe https xmpp.org extensions xep 0060.html and xep 0050 ad hoc commands https xmpp.org extensions xep 0050.html for your machine to machine needs. several other xeps, such as xep 0115 https xmpp.org extensions xep 0115.html including native support for the reading and writing the capsdb https github.com xnyhps capsdb and xep 0131 https xmpp.org extensions xep 0131.html . apis suitable for both one shot scripts and long running multi account clients. well tested and modular codebase aioxmpp is developed in test driven style and many modules are automatedly tested against a prosody https prosody.im 0.9, 0.10 and the most recent development version, as well as ejabberd https www.ejabberd.im , two popular xmpp servers. there is more and theres yet more to come check out the list of supported xeps in the official documentation and open github issues tagged as enhancement https github.com horazont aioxmpp issues q is 3aissue is 3aopen label 3aenhancement for things which are planned and read on below on how to contribute. documentation the aioxmpp api is thoroughly documented using sphinx. check out the official documentation for a quick start and the api reference . dependencies python  3.4 or python 3.3 with tulip and enum34 dnspython lxml sortedcollections https pypi.python.org pypi sortedcollections tzlocal for i18n support https pypi.python.org pypi tzlocal pyopenssl https pypi.python.org pypi pyopenssl pyasn1 and pyasn1 modules .. pyasn1 https pypi.python.org pypi pyasn1 https pypi.python.org pypi pyasn1 modules aiosasl  0.3 for anonymous support https pypi.python.org pypi aiosasl multidict https pypi.python.org pypi multidict aioopenssl https github.com horazont aioopenssl typing python 3.5 only https pypi.python.org pypi typing contributing if you consider contributing to aioxmpp, you can do so, even without a github account. there are several ways to get in touch with the aioxmpp developer s the development mailing list https lists.zombofant.net cgi bin mailman listinfo aioxmpp devel . feel free to subscribe and post, but be polite and adhere to the netiquette rfc 1855 https tools.ietf.org html rfc1855 . pull requests posted to the mailing list are also welcome the development muc at aioxmpp conference.zombofant.net . pull requests announced in the muc are also welcome note that the muc is set persistent, but nevertheless there may not always be people around. if in doubt, use the mailing list instead. open or comment on an issue or post a pull request on github https github.com horazont aioxmpp issues . no idea what to do, but still want to get your hands dirty check out the list of 'help wanted' issues on github https github.com horazont aioxmpp issues q is 3aissue is 3aopen label 3a 22help wanted 22 or ask in the muc or on the mailing list. the issues tagged as 'help wanted' are usually of narrow scope, aimed at beginners. be sure to read the docs contributing.rst for some hints on how to author your contribution. security issues if you believe that a bug you found in aioxmpp has security implications, you are welcome to notify me privately. to do so, send a mail to jonas wielicki mailto jonas wielicki.name , encrypted using the gpg public key 0xe5ede5ac679e300f fingerprint aa5a 78ff 508d 8cf4 f355 f682 e5ed e5ac 679e 300f . if you prefer to disclose security issues immediately, you can do so at any of the places listed above. change log the change log is included in the official documentation . .. change log https docs.zombofant.net aioxmpp 0.10 api changelog.html .. official documentation https docs.zombofant.net aioxmpp 0.10 .. quick start https docs.zombofant.net aioxmpp 0.10 user guide quickstart.html .. api reference https docs.zombofant.net aioxmpp 0.10 api index.html\n",
      "Highest ranked keywords:\n",
      "\n",
      "                     TF-IDF\n",
      "aioxmpp            0.572568\n",
      "xep                0.437846\n",
      "horazont           0.254303\n",
      "https              0.233452\n",
      "pyasn1             0.158939\n",
      "muc                0.134722\n",
      "extensions         0.132490\n",
      "issues             0.107726\n",
      "devel              0.101268\n",
      "mailing            0.092688\n",
      "pypi               0.077227\n",
      "official           0.075778\n",
      "support            0.074398\n",
      "list               0.071742\n",
      "github             0.068952\n",
      "sortedcollections  0.067361\n",
      "aioopenssl         0.067361\n",
      "capsdb             0.067361\n",
      "presence           0.067361\n",
      "multidict          0.067361\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  aiqpy\n",
      "Description:  aiqpy aiqpy is a wrapper library that allows you to interact with an appeariq 8 https appeariq.com platform using python. the library connects to the rest apis of the platform and takes care of authentication and session management so you can focus on funnier things. example changing the password of a user .. code block pycon platform aiqpy.connection profile 'dev' user platform.get 'admin', 'users' , username 'stephen.falken' 0 user 'password' 'joshua' updated platform.put 'admin', 'users' , user dependencies aiqpy uses requests http python requests.org for performing http requests. license aiqpy is licensed under gnu gpl v3.0.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                  TF-IDF\n",
      "aiqpy           0.676552\n",
      "platform        0.324388\n",
      "user            0.252070\n",
      "appeariq        0.169138\n",
      "funnier         0.169138\n",
      "pycon           0.139772\n",
      "connects        0.139772\n",
      "performing      0.133881\n",
      "focus           0.131412\n",
      "library         0.121914\n",
      "changing        0.121907\n",
      "gpl             0.117634\n",
      "interact        0.116366\n",
      "apis            0.112930\n",
      "care            0.105660\n",
      "rest            0.104891\n",
      "session         0.104891\n",
      "authentication  0.102726\n",
      "management      0.100744\n",
      "takes           0.100119\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  air\n",
      "Description:  air .. image https img.shields.io pypi v air.svg target https pypi.python.org pypi air .. image https img.shields.io travis audreyr air.svg target https travis ci.org audreyr air .. image https readthedocs.org projects air badge version latest target https readthedocs.org projects air badge latest alt documentation status an ultra lightweight static site generator. documentation https air.readthedocs.org. features todo credits this package was created with cookiecutter and the cookiecutter pypackage project template. .. cookiecutter https github.com audreyr cookiecutter .. cookiecutter pypackage https github.com audreyr cookiecutter pypackage history 0.1.0 2015 12 10 first release on pypi.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                 TF-IDF\n",
      "air            0.593281\n",
      "cookiecutter   0.507627\n",
      "audreyr        0.338418\n",
      "pypackage      0.255954\n",
      "https          0.240844\n",
      "ultra          0.123890\n",
      "target         0.120887\n",
      "image          0.113028\n",
      "projects       0.105445\n",
      "badge          0.099836\n",
      "lightweight    0.098670\n",
      "latest         0.086569\n",
      "travis         0.079863\n",
      "documentation  0.078450\n",
      "pypi           0.075246\n",
      "static         0.074625\n",
      "2015           0.068504\n",
      "todo           0.068217\n",
      "site           0.064853\n",
      "12             0.063270\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Package name:  airbrakepy\n",
      "Description:  pulse energy airbrakepy airbrakepy provides a logging.handler implementation that can be configured to alert airbrake http airbrakeapp.com . c 2012 pulse energy, inc.\n",
      "Highest ranked keywords:\n",
      "\n",
      "                  TF-IDF\n",
      "airbrakepy      0.604166\n",
      "pulse           0.570216\n",
      "airbrake        0.302083\n",
      "energy          0.244045\n",
      "alert           0.234703\n",
      "configured      0.178813\n",
      "2012            0.161838\n",
      "implementation  0.158318\n",
      "provides        0.123921\n",
      "http            0.073161\n",
      "optimisation    0.000000\n",
      "operation       0.000000\n",
      "operating       0.000000\n",
      "operates        0.000000\n",
      "operated        0.000000\n",
      "operate         0.000000\n",
      "opera           0.000000\n",
      "operand         0.000000\n",
      "operaciones     0.000000\n",
      "operations      0.000000\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "packages = list(preprocessed_projects_with_keywords_dataset_ordered.keys())[:100]\n",
    "package_indexes = OrderedDict({package : index for index, package in enumerate(packages)})\n",
    "\n",
    "for package_name in packages:\n",
    "    df_keywords = pd.DataFrame(tf_idf_keywords[package_indexes[package_name]].T.todense(), index=vectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "    df_keywords = df_keywords.sort_values(\"TF-IDF\", ascending=False)\n",
    "\n",
    "    print(\"Package name: \", package_name)\n",
    "    print(\"Description: \", projects_with_keywords_dataset[package_name][0])\n",
    "    print(\"Highest ranked keywords:\\n\")\n",
    "    print(df_keywords.head(20))\n",
    "\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, we can see that the highest ranked tokens seem to be relevant descriptors of the projects, with the exception of words that could be used to describe any type of package (\"pypi\", \"python\", \"module\"...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting keywords with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we managed to rank the most important tokens of a project description using TF-IDF, we could try to see if the highest ranked tokens for each package are effective keywords predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "Package name:  42cc-pystyle\n",
      "Actual keywords:\n",
      "\n",
      "['docstrings', 'flake8']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['nosetests', 'flake8']\n",
      "Correctly predicted keywords for 42cc-pystyle for top 2 predicted keywords:\n",
      "1/2\n",
      "\n",
      "\n",
      "Package name:  73-unlockitems\n",
      "Actual keywords:\n",
      "\n",
      "['unlock']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['simplejson']\n",
      "Correctly predicted keywords for 73-unlockitems for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  a10-horizon\n",
      "Actual keywords:\n",
      "\n",
      "['a10', 'adc', 'slb', 'load', 'balancer', 'openstack', 'neutron', 'lbaas', 'horizon']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['a10', 'horizon', 'openstack', 'a10networks', 'lbaas', 'acos', 'dashboard', 'sh', 'networks']\n",
      "Correctly predicted keywords for a10-horizon for top 9 predicted keywords:\n",
      "4/9\n",
      "\n",
      "\n",
      "Package name:  a2pcej\n",
      "Actual keywords:\n",
      "\n",
      "['alphabet', 'katakana', 'phonetic', 'code']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['conv', 'a2pcej', 'kacchan822', 'ak']\n",
      "Correctly predicted keywords for a2pcej for top 4 predicted keywords:\n",
      "0/4\n",
      "\n",
      "\n",
      "Package name:  aaa2-1-1\n",
      "Actual keywords:\n",
      "\n",
      "['simple', 'test']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['roc', 'conroc']\n",
      "Correctly predicted keywords for aaa2-1-1 for top 2 predicted keywords:\n",
      "0/2\n",
      "\n",
      "\n",
      "Package name:  aacgmv2\n",
      "Actual keywords:\n",
      "\n",
      "['aacgm', 'aacgm', 'v2', 'aacgmv2', 'magnetic', 'coordinates', 'altitude', 'adjusted', 'corrected', 'geomagnetic', 'coordinates', 'mlt', 'magnetic', 'local', 'time', 'conversion', 'converting']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aacgmv2', 'aburrell', 'aacgm', 'mlt', 'https', 'alt', 'target', 'flat', 'scrutinizer', 'image', 'style', 'github', 'pypi', 'status', 'doi', 'array', 'updated']\n",
      "Correctly predicted keywords for aacgmv2 for top 17 predicted keywords:\n",
      "3/17\n",
      "\n",
      "\n",
      "Package name:  aadbook\n",
      "Actual keywords:\n",
      "\n",
      "['contacts', 'azure', 'active', 'directory', 'ad']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aadbook', 'query', 'ad', '2018', 'azure']\n",
      "Correctly predicted keywords for aadbook for top 5 predicted keywords:\n",
      "2/5\n",
      "\n",
      "\n",
      "Package name:  aaltopoiju\n",
      "Actual keywords:\n",
      "\n",
      "['aaltopoiju']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aaltopoiju']\n",
      "Correctly predicted keywords for aaltopoiju for top 1 predicted keywords:\n",
      "1/1\n",
      "\n",
      "\n",
      "Package name:  abakus-status-checks\n",
      "Actual keywords:\n",
      "\n",
      "['monitoring', 'status', 'checks', 'abakus']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['abakus', 'checks', 'eirsyl', 'load']\n",
      "Correctly predicted keywords for abakus-status-checks for top 4 predicted keywords:\n",
      "2/4\n",
      "\n",
      "\n",
      "Package name:  abci\n",
      "Actual keywords:\n",
      "\n",
      "['blockchain', 'tendermint', 'abci']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['abci', 'protobuf', 'davebryson']\n",
      "Correctly predicted keywords for abci for top 3 predicted keywords:\n",
      "1/3\n",
      "\n",
      "\n",
      "Package name:  abipy\n",
      "Actual keywords:\n",
      "\n",
      "['abinit', 'ab', 'initio', 'density', 'function', 'theory', 'first', 'principles', 'electronic', 'structure', 'pymatgen']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['abipy', 'abinit', 'notebooks', 'lessons', 'initio', 'pymatgen', 'ab', 'calculations', 'http', 'jupyter', 'examples']\n",
      "Correctly predicted keywords for abipy for top 11 predicted keywords:\n",
      "4/11\n",
      "\n",
      "\n",
      "Package name:  abjad-ext-rmakers\n",
      "Actual keywords:\n",
      "\n",
      "['music', 'composition', 'music', 'notation', 'formalized', 'score', 'control', 'lilypond']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['abjad', 'rhythm', 'rmakers', 'maker', 'ext', 'extension', 'operates', 'operations']\n",
      "Correctly predicted keywords for abjad-ext-rmakers for top 8 predicted keywords:\n",
      "0/8\n",
      "\n",
      "\n",
      "Package name:  acclaim-badges\n",
      "Actual keywords:\n",
      "\n",
      "['django', 'edx']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['acclaim', 'edx']\n",
      "Correctly predicted keywords for acclaim-badges for top 2 predicted keywords:\n",
      "1/2\n",
      "\n",
      "\n",
      "Package name:  acid-senza-templates\n",
      "Actual keywords:\n",
      "\n",
      "['senza', 'postgres']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['senza', 'ebs']\n",
      "Correctly predicted keywords for acid-senza-templates for top 2 predicted keywords:\n",
      "1/2\n",
      "\n",
      "\n",
      "Package name:  acidfile\n",
      "Actual keywords:\n",
      "\n",
      "['acid', 'transactional', 'file']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['acidfile', 'nilp0inter', 'tmp']\n",
      "Correctly predicted keywords for acidfile for top 3 predicted keywords:\n",
      "0/3\n",
      "\n",
      "\n",
      "Package name:  acoular\n",
      "Actual keywords:\n",
      "\n",
      "['acoustic', 'beamforming', 'microphone', 'array']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['acoular', 'acoustic', 'beamforming', 'algorithms']\n",
      "Correctly predicted keywords for acoular for top 4 predicted keywords:\n",
      "2/4\n",
      "\n",
      "\n",
      "Package name:  actionable-agile-extract\n",
      "Actual keywords:\n",
      "\n",
      "['agile', 'jira', 'analytics']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['jira', 'cycle', 'done']\n",
      "Correctly predicted keywords for actionable-agile-extract for top 3 predicted keywords:\n",
      "1/3\n",
      "\n",
      "\n",
      "Package name:  activation\n",
      "Actual keywords:\n",
      "\n",
      "['activation']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['activation']\n",
      "Correctly predicted keywords for activation for top 1 predicted keywords:\n",
      "1/1\n",
      "\n",
      "\n",
      "Package name:  active-redis\n",
      "Actual keywords:\n",
      "\n",
      "['redis', 'activerecord']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['assert', 'movie']\n",
      "Correctly predicted keywords for active-redis for top 2 predicted keywords:\n",
      "0/2\n",
      "\n",
      "\n",
      "Package name:  active-sqlalchemy\n",
      "Actual keywords:\n",
      "\n",
      "['sqlalchemy', 'flask', 'active', 'sqlalchemy', 'orm', 'active', 'record', 'mysql', 'postgresql', 'pymysql', 'pg8000', 'sqlite']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['sqlalchemy', 'active', 'mardix', 'underneath', 'agnostic', 'implementing', 'record', 'license', 'really', 'framework', '2014', 'wrapper']\n",
      "Correctly predicted keywords for active-sqlalchemy for top 12 predicted keywords:\n",
      "3/12\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-ads1x15\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'ads1x115', 'adc', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'ads1x15', 'shell', 'build', 'block']\n",
      "Correctly predicted keywords for adafruit-circuitpython-ads1x15 for top 6 predicted keywords:\n",
      "2/6\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-as726x\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'as726x', 'light', 'sensor', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'as726x', 'shell', 'build', 'block', 'sphinx']\n",
      "Correctly predicted keywords for adafruit-circuitpython-as726x for top 7 predicted keywords:\n",
      "3/7\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-bno055\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', '9-dof', 'absolute', 'orientation', 'accelerometer', 'velocity', 'temperature', 'gravitymagnetic', 'breakout', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'bno055', 'i2c', 'build', 'sphinx', 'code', 'shell', 'https', 'discord', 'block', 'driver']\n",
      "Correctly predicted keywords for adafruit-circuitpython-bno055 for top 12 predicted keywords:\n",
      "2/12\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-crickit\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'crickit', 'robotics', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'motor', 'crickit', 'servo', 'stepper']\n",
      "Correctly predicted keywords for adafruit-circuitpython-crickit for top 6 predicted keywords:\n",
      "3/6\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-ds1307\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'real', 'time', 'clock', 'rtc', 'breakout', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'rtc', 'ds1307', 'build', 'code', 'time', 'i2c', 'sphinx']\n",
      "Correctly predicted keywords for adafruit-circuitpython-ds1307 for top 9 predicted keywords:\n",
      "4/9\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-fxas21002c\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'fxas21002c', 'gyro', 'gyroscope', 'nxp', 'breakout', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'fxas21002c', 'build', 'sphinx', 'shell', 'https', 'block', 'code']\n",
      "Correctly predicted keywords for adafruit-circuitpython-fxas21002c for top 9 predicted keywords:\n",
      "3/9\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-htu21d\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'htu21d-f', 'temperature', 'humidity', 'sensorbreakout', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'htu21d', 'build', 'sphinx', 'humidity', 'shell', 'i2c']\n",
      "Correctly predicted keywords for adafruit-circuitpython-htu21d for top 8 predicted keywords:\n",
      "3/8\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-ina219\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'current', 'sensor', 'high', 'voltage', 'featherwing', 'breakout', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'ina219', 'build', 'sphinx', 'https', 'shell', 'block', 'driver', 'code']\n",
      "Correctly predicted keywords for adafruit-circuitpython-ina219 for top 10 predicted keywords:\n",
      "2/10\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-lis3dh\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'accelerometer', 'lis3dh', 'acceleration', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'lis3dh', 'build', 'sphinx', 'shell', 'https']\n",
      "Correctly predicted keywords for adafruit-circuitpython-lis3dh for top 7 predicted keywords:\n",
      "3/7\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-max9744\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'amplifier', 'max9744', 'breakout', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'max9744', 'build', 'sphinx', 'shell', 'https']\n",
      "Correctly predicted keywords for adafruit-circuitpython-max9744 for top 7 predicted keywords:\n",
      "3/7\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-miniqr\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'software', 'miniqr', 'qr', 'generator', 'python', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'miniqr', 'build', 'sphinx', 'shell', 'block', 'code']\n",
      "Correctly predicted keywords for adafruit-circuitpython-miniqr for top 8 predicted keywords:\n",
      "3/8\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-motor\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'servo', 'stepper', 'motor', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'motor', 'shell', 'build', 'block', 'sphinx']\n",
      "Correctly predicted keywords for adafruit-circuitpython-motor for top 7 predicted keywords:\n",
      "3/7\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-mprls\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'mprls', 'hardware', 'pressure', 'honeywell', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'mprls', 'build', 'sphinx', 'shell', 'block']\n",
      "Correctly predicted keywords for adafruit-circuitpython-mprls for top 7 predicted keywords:\n",
      "3/7\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-pcd8544\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'display', 'nokia', 'pcd8544', 'monochrome', 'displays', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'pcd8544', 'shell', 'build', 'block', 'sphinx', 'code', 'install']\n",
      "Correctly predicted keywords for adafruit-circuitpython-pcd8544 for top 9 predicted keywords:\n",
      "3/9\n",
      "\n",
      "\n",
      "Package name:  adafruit-circuitpython-rfm69\n",
      "Actual keywords:\n",
      "\n",
      "['adafruit', 'rfm69', 'packet', 'radio', 'hardware', 'micropython', 'circuitpython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adafruit', 'circuitpython', 'rfm69', 'build', 'sphinx', 'shell', 'radio']\n",
      "Correctly predicted keywords for adafruit-circuitpython-rfm69 for top 7 predicted keywords:\n",
      "4/7\n",
      "\n",
      "\n",
      "Package name:  adapted-logger\n",
      "Actual keywords:\n",
      "\n",
      "['logging', 'python', 'filters', 'python']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['logger', 'message', 'adapted', 'adaptedlogger']\n",
      "Correctly predicted keywords for adapted-logger for top 4 predicted keywords:\n",
      "0/4\n",
      "\n",
      "\n",
      "Package name:  adaptfilt\n",
      "Actual keywords:\n",
      "\n",
      "['adaptive', 'filter', 'adaptive', 'filtering', 'signal', 'processing', 'lms', 'apa', 'nlms', 'rls']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['filter', 'coefficients', 'adaptive', 'returncoeffs', 'adaptfilt', 'mswe', 'array', 'iterations', 'filtering', 'number']\n",
      "Correctly predicted keywords for adaptfilt for top 10 predicted keywords:\n",
      "3/10\n",
      "\n",
      "\n",
      "Package name:  adb3\n",
      "Actual keywords:\n",
      "\n",
      "['android', 'adb', 'fastboot']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['android', 'adb', 'fastboot']\n",
      "Correctly predicted keywords for adb3 for top 3 predicted keywords:\n",
      "3/3\n",
      "\n",
      "\n",
      "Package name:  addok\n",
      "Actual keywords:\n",
      "\n",
      "['address', 'openstreetmap', 'geocoding']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['addok', 'france', 'branch']\n",
      "Correctly predicted keywords for addok for top 3 predicted keywords:\n",
      "0/3\n",
      "\n",
      "\n",
      "Package name:  addok-csv\n",
      "Actual keywords:\n",
      "\n",
      "['addok', 'geocoding', 'csv', 'plugin']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['csv', 'columns', 'encoding', 'delimiter']\n",
      "Correctly predicted keywords for addok-csv for top 4 predicted keywords:\n",
      "1/4\n",
      "\n",
      "\n",
      "Package name:  addr-detector\n",
      "Actual keywords:\n",
      "\n",
      "['addr_detector']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['fasttext']\n",
      "Correctly predicted keywords for addr-detector for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  addressify\n",
      "Actual keywords:\n",
      "\n",
      "['wrapper', 'addresses', 'addressify', 'post', 'australia']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['nsw', 'postcode', 'george', '2000', 'addresses']\n",
      "Correctly predicted keywords for addressify for top 5 predicted keywords:\n",
      "1/5\n",
      "\n",
      "\n",
      "Package name:  ade\n",
      "Actual keywords:\n",
      "\n",
      "['twisted', 'asynchronous', 'differential', 'evolution', 'de', 'genetic', 'algorithm', 'evolution']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['de', 'ade', 'best', 'differential', 'numeric', 'classic', 'algorithm', 'storn']\n",
      "Correctly predicted keywords for ade for top 8 predicted keywords:\n",
      "3/8\n",
      "\n",
      "\n",
      "Package name:  adipy\n",
      "Actual keywords:\n",
      "\n",
      "['automatic', 'differentiation', 'algorithmic', 'differentiation', 'arbitrary', 'order', 'python', 'linear', 'algebra']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['ad', 'adipy', 'multivariate', 'output', 'print', 'jacobian', 'univariate', 'array', 'sin']\n",
      "Correctly predicted keywords for adipy for top 9 predicted keywords:\n",
      "0/9\n",
      "\n",
      "\n",
      "Package name:  admin-tools-zinnia\n",
      "Actual keywords:\n",
      "\n",
      "['django', 'blog', 'weblog', 'zinnia', 'admin', 'dashboard']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['zinnia', 'admin', 'django', 'tools', 'dashboard', 'blog']\n",
      "Correctly predicted keywords for admin-tools-zinnia for top 6 predicted keywords:\n",
      "5/6\n",
      "\n",
      "\n",
      "Package name:  adminbot\n",
      "Actual keywords:\n",
      "\n",
      "['system', 'administration']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adminbot', 'dih5']\n",
      "Correctly predicted keywords for adminbot for top 2 predicted keywords:\n",
      "0/2\n",
      "\n",
      "\n",
      "Package name:  adminkit\n",
      "Actual keywords:\n",
      "\n",
      "['sysadmin']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['familly']\n",
      "Correctly predicted keywords for adminkit for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  adp-userinfo\n",
      "Actual keywords:\n",
      "\n",
      "['adp', 'userinfo']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['adp', 'logged']\n",
      "Correctly predicted keywords for adp-userinfo for top 2 predicted keywords:\n",
      "1/2\n",
      "\n",
      "\n",
      "Package name:  adversarials\n",
      "Actual keywords:\n",
      "\n",
      "['keras', 'gan', 'gans', 'networks', 'adversarial']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['gan', 'deven96', 'simple', 'generative', 'adversarial']\n",
      "Correctly predicted keywords for adversarials for top 5 predicted keywords:\n",
      "2/5\n",
      "\n",
      "\n",
      "Package name:  aeneas\n",
      "Actual keywords:\n",
      "\n",
      "['aud', 'aws', 'polly', 'tts', 'api', 'csv', 'dtw', 'eaf', 'elan', 'epub', '3', 'media', 'overlay', 'epub', '3', 'epub', 'festival', 'json', 'mfcc', 'mel', 'frequency', 'cepstral', 'coefficients', 'nuance', 'tts', 'api', 'readbeyond', 'sync', 'readbeyond', 'sbv', 'smil', 'srt', 'ssv', 'sub', 'tgt', 'tsv', 'ttml', 'tts', 'textgrid', 'vtt', 'xml', 'aeneas', 'audio', 'text', 'alignment', 'dynamic', 'time', 'warping', 'espeak', 'espeak', 'ng', 'espeak', 'espeak', 'ng', 'festival', 'ffmpeg', 'ffprobe', 'forced', 'alignment', 'media', 'overlay', 'rb', 'smil', 'emulator', 'speech', 'to', 'text', 'subtitles', 'sync', 'synchronization', 'text', 'to', 'speech', 'text2wave', 'tts']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aeneas', '00', 'readbeyond', 'audio', 'alignment', 'task', 'tts', 'os', 'text', 'forced', 'map', 'https', 'mfcc', 'espeak', 'word', 'docs', 'http', 'multilevel', 'thy', 'file', 'code', 'python', 'sync', 'sponsored', 'smil', 'unparsed', 'bash', 'tutorial', 'blob', 'wiki', 'level', 'vagrant', 'mac', 'synchronization', 'job', 'ffmpeg', 'benchmark', 'ram', 'presets', 'dtw', 'master', 'supporting', 'forum', 'platforms', 'development', 'format', 'output', 'strongly', '2015', 'gb', 'contributed', 'partially', 'xml', 'chris', 'processing', 'languages', 'developed', 'might', 'assets', 'command', 'files', 'supported', 'debian', 'mailing', 'input', 'pettarin', 'bair', 'finetuneas', 'confirmed', 'nonspeech', 'nuance', 'thine', 'gianella', 'tuning', 'textgrid']\n",
      "Correctly predicted keywords for aeneas for top 75 predicted keywords:\n",
      "17/75\n",
      "\n",
      "\n",
      "Package name:  aerial\n",
      "Actual keywords:\n",
      "\n",
      "['aerial', 'signals', 'signal', 'unix', 'sighup', 'sigterm']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aerial', '10852', 'chrisbrake', 'pid', 'status', 'sighup']\n",
      "Correctly predicted keywords for aerial for top 6 predicted keywords:\n",
      "2/6\n",
      "\n",
      "\n",
      "Package name:  aeropy\n",
      "Actual keywords:\n",
      "\n",
      "['aerospace', 'engineering', 'airfoils', 'noise', 'aircraft']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aerospace', 'lukas', 'universal', 'engineering', 'software']\n",
      "Correctly predicted keywords for aeropy for top 5 predicted keywords:\n",
      "2/5\n",
      "\n",
      "\n",
      "Package name:  affinitic-caching\n",
      "Actual keywords:\n",
      "\n",
      "['caching', 'memcached']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['22', 'caching']\n",
      "Correctly predicted keywords for affinitic-caching for top 2 predicted keywords:\n",
      "1/2\n",
      "\n",
      "\n",
      "Package name:  afilnet\n",
      "Actual keywords:\n",
      "\n",
      "['afilnet', 'sms', 'email', 'voice', 'message', 'phone', 'call', 'notification', 'cloud', 'marketing', 'service']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['scheduledatetime', 'afilnet', 'send', 'voice', 'email', 'isuser', 'getbalance', 'sms', 'services', 'user', 'res']\n",
      "Correctly predicted keywords for afilnet for top 11 predicted keywords:\n",
      "4/11\n",
      "\n",
      "\n",
      "Package name:  afinn\n",
      "Actual keywords:\n",
      "\n",
      "['sentiment', 'analysis']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['afinn', 'sentences']\n",
      "Correctly predicted keywords for afinn for top 2 predicted keywords:\n",
      "0/2\n",
      "\n",
      "\n",
      "Package name:  afk-time\n",
      "Actual keywords:\n",
      "\n",
      "['afk']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['afk']\n",
      "Correctly predicted keywords for afk-time for top 1 predicted keywords:\n",
      "1/1\n",
      "\n",
      "\n",
      "Package name:  afnumpy\n",
      "Actual keywords:\n",
      "\n",
      "['arrayfire', 'numpy', 'gpu']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['afnumpy', 'filipemaia', 'arrayfire']\n",
      "Correctly predicted keywords for afnumpy for top 3 predicted keywords:\n",
      "1/3\n",
      "\n",
      "\n",
      "Package name:  agamotto\n",
      "Actual keywords:\n",
      "\n",
      "['server', 'testing']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['echo', 'agamotto']\n",
      "Correctly predicted keywords for agamotto for top 2 predicted keywords:\n",
      "0/2\n",
      "\n",
      "\n",
      "Package name:  ageliaco-rd\n",
      "Actual keywords:\n",
      "\n",
      "['ageliaco', 'rd', 'project', 'management']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['ldap', 'acl', 'product', 'activate']\n",
      "Correctly predicted keywords for ageliaco-rd for top 4 predicted keywords:\n",
      "0/4\n",
      "\n",
      "\n",
      "Package name:  agenda\n",
      "Actual keywords:\n",
      "\n",
      "['logging', 'console', 'pretty-print']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['task', 'subtask', 'starts']\n",
      "Correctly predicted keywords for agenda for top 3 predicted keywords:\n",
      "0/3\n",
      "\n",
      "\n",
      "Package name:  agglomcluster\n",
      "Actual keywords:\n",
      "\n",
      "['network-x']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['karate']\n",
      "Correctly predicted keywords for agglomcluster for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  ago\n",
      "Actual keywords:\n",
      "\n",
      "['ago', 'human', 'readable', 'time', 'deltas', 'timedelta', 'datetime', 'timestamp']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['tense', 'human', 'ago', 'past', 'future', 'timedelta', 'precision', 'abbreviate']\n",
      "Correctly predicted keywords for ago for top 8 predicted keywords:\n",
      "3/8\n",
      "\n",
      "\n",
      "Package name:  ags-tool-deploy\n",
      "Actual keywords:\n",
      "\n",
      "['arcgis', 'ags']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['toolbox', 'arcgis']\n",
      "Correctly predicted keywords for ags-tool-deploy for top 2 predicted keywords:\n",
      "1/2\n",
      "\n",
      "\n",
      "Package name:  agua\n",
      "Actual keywords:\n",
      "\n",
      "['agua', 'testing', 'data', 'csv']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['agua', 'accuracy', 'vs', 'shell']\n",
      "Correctly predicted keywords for agua for top 4 predicted keywords:\n",
      "1/4\n",
      "\n",
      "\n",
      "Package name:  aha-application-default\n",
      "Actual keywords:\n",
      "\n",
      "['web', 'aha', 'appengine', 'web']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['appliction', 'aha', 'controller', 'say']\n",
      "Correctly predicted keywords for aha-application-default for top 4 predicted keywords:\n",
      "1/4\n",
      "\n",
      "\n",
      "Package name:  ahds\n",
      "Actual keywords:\n",
      "\n",
      "['header', 'parser', 'data', 'streams']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['amira', 'data', 'streams', 'class']\n",
      "Correctly predicted keywords for ahds for top 4 predicted keywords:\n",
      "2/4\n",
      "\n",
      "\n",
      "Package name:  ahoy\n",
      "Actual keywords:\n",
      "\n",
      "['ahoy']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['ahoy']\n",
      "Correctly predicted keywords for ahoy for top 1 predicted keywords:\n",
      "1/1\n",
      "\n",
      "\n",
      "Package name:  ai-cs\n",
      "Actual keywords:\n",
      "\n",
      "['coordinates', 'transformation', 'cxform', 'heliocentric', 'geocentric']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['rotation', 'cartesian', 'phi', 'coordinates', 'cs']\n",
      "Correctly predicted keywords for ai-cs for top 5 predicted keywords:\n",
      "1/5\n",
      "\n",
      "\n",
      "Package name:  aidsinfo\n",
      "Actual keywords:\n",
      "\n",
      "['aids', 'aids', 'info', 'aidsinfo', 'aidsinfo']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aidsinfo', 'druginfo', 'xml', 'wrapper', 'drug']\n",
      "Correctly predicted keywords for aidsinfo for top 5 predicted keywords:\n",
      "1/5\n",
      "\n",
      "\n",
      "Package name:  aiida-siesta\n",
      "Actual keywords:\n",
      "\n",
      "['aiida', 'siesta', 'dft']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['siesta', 'aiida', 'albgar']\n",
      "Correctly predicted keywords for aiida-siesta for top 3 predicted keywords:\n",
      "2/3\n",
      "\n",
      "\n",
      "Package name:  aio-framework\n",
      "Actual keywords:\n",
      "\n",
      "['sneaker', 'bot', 'development']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['captcha', 'product', 'task']\n",
      "Correctly predicted keywords for aio-framework for top 3 predicted keywords:\n",
      "0/3\n",
      "\n",
      "\n",
      "Package name:  aio-jsonrpc-2-0\n",
      "Actual keywords:\n",
      "\n",
      "['json', 'rpc', 'jsonrpc', 'json-rpc', '2.0']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['jsonrpc', 'params', 'json', 'aio', 'request']\n",
      "Correctly predicted keywords for aio-jsonrpc-2-0 for top 5 predicted keywords:\n",
      "2/5\n",
      "\n",
      "\n",
      "Package name:  aio-pipe\n",
      "Actual keywords:\n",
      "\n",
      "['posix', 'pipe', 'python', 'asyncio', 'cython']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aio', 'pipe', 'loop', 'pypi', 'https']\n",
      "Correctly predicted keywords for aio-pipe for top 5 predicted keywords:\n",
      "1/5\n",
      "\n",
      "\n",
      "Package name:  aioapp-amqp\n",
      "Actual keywords:\n",
      "\n",
      "['aioapp_amqp']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aioapp']\n",
      "Correctly predicted keywords for aioapp-amqp for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  aioauth2\n",
      "Actual keywords:\n",
      "\n",
      "['oauth', 'oauth2', 'async', 'asyncio']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aioauth2', 'oauth2', 'asynchronous', 'joestump']\n",
      "Correctly predicted keywords for aioauth2 for top 4 predicted keywords:\n",
      "1/4\n",
      "\n",
      "\n",
      "Package name:  aiobittrex\n",
      "Actual keywords:\n",
      "\n",
      "['async', 'bittrex']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['market', 'btc']\n",
      "Correctly predicted keywords for aiobittrex for top 2 predicted keywords:\n",
      "0/2\n",
      "\n",
      "\n",
      "Package name:  aioboto3\n",
      "Actual keywords:\n",
      "\n",
      "['aioboto3']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aiobotocore']\n",
      "Correctly predicted keywords for aioboto3 for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  aiodataloader\n",
      "Actual keywords:\n",
      "\n",
      "['concurrent', 'future', 'deferred', 'aiodataloader']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['dataloader', 'batch', 'cache', 'user']\n",
      "Correctly predicted keywords for aiodataloader for top 4 predicted keywords:\n",
      "0/4\n",
      "\n",
      "\n",
      "Package name:  aiofreepybox\n",
      "Actual keywords:\n",
      "\n",
      "['freebox', 'async']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['freebox', 'aiofreepybox']\n",
      "Correctly predicted keywords for aiofreepybox for top 2 predicted keywords:\n",
      "1/2\n",
      "\n",
      "\n",
      "Package name:  aiohttp-jrpc\n",
      "Actual keywords:\n",
      "\n",
      "['aiohttp', 'jsonrpc', 'rpc']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aiohttp', 'jrpc', 'middleware']\n",
      "Correctly predicted keywords for aiohttp-jrpc for top 3 predicted keywords:\n",
      "1/3\n",
      "\n",
      "\n",
      "Package name:  aiohttp-json-rpc\n",
      "Actual keywords:\n",
      "\n",
      "['aiohttp']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['rpc']\n",
      "Correctly predicted keywords for aiohttp-json-rpc for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  aiohttp-typed-views\n",
      "Actual keywords:\n",
      "\n",
      "['asyncio', 'aiohttp', 'typing', 'class', 'based', 'views']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['typed', 'aiohttp', 'gr1n', 'views', 'poetry', 'black']\n",
      "Correctly predicted keywords for aiohttp-typed-views for top 6 predicted keywords:\n",
      "2/6\n",
      "\n",
      "\n",
      "Package name:  aiolog\n",
      "Actual keywords:\n",
      "\n",
      "['logging']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aiolog']\n",
      "Correctly predicted keywords for aiolog for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  aiommy\n",
      "Actual keywords:\n",
      "\n",
      "['web', 'api']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aiommy', 'database']\n",
      "Correctly predicted keywords for aiommy for top 2 predicted keywords:\n",
      "0/2\n",
      "\n",
      "\n",
      "Package name:  aiopg8000\n",
      "Actual keywords:\n",
      "\n",
      "['postgresql', 'dbapi', 'asyncio']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['pg8000', 'postgresql', 'aiopg8000']\n",
      "Correctly predicted keywords for aiopg8000 for top 3 predicted keywords:\n",
      "1/3\n",
      "\n",
      "\n",
      "Package name:  aiopop3\n",
      "Actual keywords:\n",
      "\n",
      "['email']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['pop3']\n",
      "Correctly predicted keywords for aiopop3 for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  aioredlock\n",
      "Actual keywords:\n",
      "\n",
      "['redis', 'redlock', 'distributed', 'locks', 'asyncio']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['lock', 'redis', 'aioredlock', 'redlock', 'lockerror']\n",
      "Correctly predicted keywords for aioredlock for top 5 predicted keywords:\n",
      "2/5\n",
      "\n",
      "\n",
      "Package name:  aiosasl\n",
      "Actual keywords:\n",
      "\n",
      "['asyncio', 'sasl', 'library']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aiosasl', 'scram', 'sha']\n",
      "Correctly predicted keywords for aiosasl for top 3 predicted keywords:\n",
      "0/3\n",
      "\n",
      "\n",
      "Package name:  aioscript\n",
      "Actual keywords:\n",
      "\n",
      "['asyncio']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aioscript']\n",
      "Correctly predicted keywords for aioscript for top 1 predicted keywords:\n",
      "0/1\n",
      "\n",
      "\n",
      "Package name:  aiosocksy\n",
      "Actual keywords:\n",
      "\n",
      "['socks', 'proxy', 'aiohttp']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aiosocksy', 'romis2012', 'socks']\n",
      "Correctly predicted keywords for aiosocksy for top 3 predicted keywords:\n",
      "1/3\n",
      "\n",
      "\n",
      "Package name:  aiotorconnector\n",
      "Actual keywords:\n",
      "\n",
      "['aiotorconnector']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aiotorconnector']\n",
      "Correctly predicted keywords for aiotorconnector for top 1 predicted keywords:\n",
      "1/1\n",
      "\n",
      "\n",
      "Package name:  aiotrello\n",
      "Actual keywords:\n",
      "\n",
      "['async', 'trello']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['await', 'board']\n",
      "Correctly predicted keywords for aiotrello for top 2 predicted keywords:\n",
      "0/2\n",
      "\n",
      "\n",
      "Package name:  aiounittest\n",
      "Actual keywords:\n",
      "\n",
      "['asyncio', 'async', 'unittest', 'coroutine']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['async', 'aiounittest', 'image1', 'image0']\n",
      "Correctly predicted keywords for aiounittest for top 4 predicted keywords:\n",
      "1/4\n",
      "\n",
      "\n",
      "Package name:  aiovk\n",
      "Actual keywords:\n",
      "\n",
      "['vk.com', 'api', 'vk', 'wrappper', 'asyncio']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['session', 'tokensession', 'block', 'driver', 'await']\n",
      "Correctly predicted keywords for aiovk for top 5 predicted keywords:\n",
      "0/5\n",
      "\n",
      "\n",
      "Package name:  aioworkers\n",
      "Actual keywords:\n",
      "\n",
      "['aioworkers']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aioworkers']\n",
      "Correctly predicted keywords for aioworkers for top 1 predicted keywords:\n",
      "1/1\n",
      "\n",
      "\n",
      "Package name:  aioworkers-mongo\n",
      "Actual keywords:\n",
      "\n",
      "['aioworkers', 'mongo', 'motor']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aioworkers', 'mongo', 'https']\n",
      "Correctly predicted keywords for aioworkers-mongo for top 3 predicted keywords:\n",
      "2/3\n",
      "\n",
      "\n",
      "Package name:  aioxmpp\n",
      "Actual keywords:\n",
      "\n",
      "['asyncio', 'xmpp', 'library']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aioxmpp', 'xep', 'horazont']\n",
      "Correctly predicted keywords for aioxmpp for top 3 predicted keywords:\n",
      "0/3\n",
      "\n",
      "\n",
      "Package name:  aiqpy\n",
      "Actual keywords:\n",
      "\n",
      "['aiq8', 'appear', 'rest', 'api']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['aiqpy', 'platform', 'user', 'appeariq']\n",
      "Correctly predicted keywords for aiqpy for top 4 predicted keywords:\n",
      "0/4\n",
      "\n",
      "\n",
      "Package name:  air\n",
      "Actual keywords:\n",
      "\n",
      "['air']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['air']\n",
      "Correctly predicted keywords for air for top 1 predicted keywords:\n",
      "1/1\n",
      "\n",
      "\n",
      "Package name:  airbrakepy\n",
      "Actual keywords:\n",
      "\n",
      "['airbrake', 'python', 'logging']\n",
      "\n",
      "\n",
      "Predicted keywords:\n",
      "\n",
      "['airbrakepy', 'pulse', 'airbrake']\n",
      "Correctly predicted keywords for airbrakepy for top 3 predicted keywords:\n",
      "1/3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_kw_to_predict = 0\n",
    "for package_name in packages:\n",
    "    actual_keywords_nb = len([kw.lower() for kw in projects_with_keywords_dataset[package_name][1].split(\" \")])\n",
    "    if actual_keywords_nb >= max_kw_to_predict:\n",
    "        max_kw_to_predict = actual_keywords_nb\n",
    "        \n",
    "print(max_kw_to_predict)\n",
    "        \n",
    "proportion_of_correctly_predicted_keywords = {kw_number: [] for kw_number in range(5,max_kw_to_predict + 10,5)}\n",
    "\n",
    "\n",
    "for package_name in packages:\n",
    "    df_keywords = pd.DataFrame(tf_idf_keywords[package_indexes[package_name]].T.todense(), index=vectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "    df_keywords = df_keywords.sort_values(\"TF-IDF\", ascending=False)\n",
    "\n",
    "    actual_keywords = [kw.lower() for kw in projects_with_keywords_dataset[package_name][1].split(\" \")]\n",
    "    keywords_number_to_predict = len(actual_keywords)\n",
    "\n",
    "    print(\"Package name: \", package_name)\n",
    "    print(\"Actual keywords:\\n\")\n",
    "    print(actual_keywords)\n",
    "    print(\"\\n\")\n",
    "    print(\"Predicted keywords:\\n\")\n",
    "    print(list(df_keywords.head(keywords_number_to_predict).index))\n",
    "    print(f\"Correctly predicted keywords for {package_name} for top {keywords_number_to_predict} predicted keywords:\")\n",
    "    print(f\"{len(set(actual_keywords).intersection(set(list(df_keywords.head(keywords_number_to_predict).index))))}/{keywords_number_to_predict}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    proportion_of_correctly_predicted_keywords[5*round(keywords_number_to_predict/5) + 5].append(len(set(actual_keywords).intersection(set(list(df_keywords.head(keywords_number_to_predict).index))))/keywords_number_to_predict * 100)\n",
    "\n",
    "def mean(vals: List) -> float:\n",
    "    if len(vals) != 0:\n",
    "        return sum(vals)/len(vals)\n",
    "    return 0\n",
    "\n",
    "proportion_of_correctly_predicted_keywords = {k: mean(v) for k, v in proportion_of_correctly_predicted_keywords.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the proportion of keywords correctly predicted by TF-IDF for the analyzed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 16 artists>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(list(proportion_of_correctly_predicted_keywords.keys()), list(proportion_of_correctly_predicted_keywords.values()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "requirements": "{\"packages\":{\"collections\":\"*\",\"csv\":\"*\",\"json\":\"*\",\"nltk\":\"*\",\"os\":\"*\",\"pandas\":\"*\",\"pprint\":\"*\",\"random\":\"*\",\"sklearn\":\"*\",\"sys\":\"*\",\"typing\":\"*\"},\"requires\":{\"python_version\":\"3.8\"},\"sources\":[{\"name\":\"pypi\",\"url\":\"https://pypi.org/simple\",\"verify_ssl\":true}]}"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
